{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac32c538",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1766: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ae_ckpt\\model_encoder_encodedDim4_cluaterDim4.ckpt\n",
      "0, total loss = 10.055936813354492, reconstruct loss = 0.016296174377202988, cluster loss = 0.03852393850684166, calm loss = 4.052404880523682, pilot loss = 10.899455070495605, max interval = -9.369990348815918, \n",
      "Train ACC: 0.660377358490566, PTA: 0.7666015625, Test ACC: 0.625\n",
      "1, total loss = 10.001378059387207, reconstruct loss = 0.0169909056276083, cluster loss = 0.03950373828411102, calm loss = 4.034604072570801, pilot loss = 10.835138320922852, max interval = -9.332804679870605, \n",
      "Train ACC: 0.660377358490566, PTA: 0.755859375, Test ACC: 0.625\n",
      "2, total loss = 9.947166442871094, reconstruct loss = 0.01685982570052147, cluster loss = 0.04131529852747917, calm loss = 4.0169267654418945, pilot loss = 10.77128791809082, max interval = -9.295979499816895, \n",
      "Train ACC: 0.660377358490566, PTA: 0.751953125, Test ACC: 0.625\n",
      "3, total loss = 9.890018463134766, reconstruct loss = 0.01669946312904358, cluster loss = 0.039477571845054626, calm loss = 3.9993133544921875, pilot loss = 10.708381652832031, max interval = -9.259535789489746, \n",
      "Train ACC: 0.660377358490566, PTA: 0.7744140625, Test ACC: 0.625\n",
      "4, total loss = 9.833518028259277, reconstruct loss = 0.015126978978514671, cluster loss = 0.03873186185956001, calm loss = 3.981922149658203, pilot loss = 10.646474838256836, max interval = -9.223458290100098, \n",
      "Train ACC: 0.660377358490566, PTA: 0.7744140625, Test ACC: 0.625\n",
      "5, total loss = 9.78380298614502, reconstruct loss = 0.016768677160143852, cluster loss = 0.04041149467229843, calm loss = 3.9648330211639404, pilot loss = 10.585604667663574, max interval = -9.187660217285156, \n",
      "Train ACC: 0.660377358490566, PTA: 0.755859375, Test ACC: 0.6178571428571429\n",
      "6, total loss = 9.731008529663086, reconstruct loss = 0.017649251967668533, cluster loss = 0.03902888670563698, calm loss = 3.94769549369812, pilot loss = 10.525806427001953, max interval = -9.152263641357422, \n",
      "Train ACC: 0.660377358490566, PTA: 0.763671875, Test ACC: 0.6178571428571429\n",
      "7, total loss = 9.680330276489258, reconstruct loss = 0.01575450785458088, cluster loss = 0.041836027055978775, calm loss = 3.9305038452148438, pilot loss = 10.467063903808594, max interval = -9.11729621887207, \n",
      "Train ACC: 0.6509433962264151, PTA: 0.748046875, Test ACC: 0.6178571428571429\n",
      "8, total loss = 9.627470970153809, reconstruct loss = 0.016863664612174034, cluster loss = 0.038946304470300674, calm loss = 3.9132843017578125, pilot loss = 10.408426284790039, max interval = -9.081707000732422, \n",
      "Train ACC: 0.6509433962264151, PTA: 0.7490234375, Test ACC: 0.6142857142857143\n",
      "9, total loss = 9.576700210571289, reconstruct loss = 0.016396693885326385, cluster loss = 0.039141424000263214, calm loss = 3.896026611328125, pilot loss = 10.350841522216797, max interval = -9.046743392944336, \n",
      "Train ACC: 0.6509433962264151, PTA: 0.7666015625, Test ACC: 0.6107142857142858\n",
      "10, total loss = 9.528543472290039, reconstruct loss = 0.01780615746974945, cluster loss = 0.039317891001701355, calm loss = 3.8787548542022705, pilot loss = 10.29449462890625, max interval = -9.01244831085205, \n",
      "Train ACC: 0.6509433962264151, PTA: 0.7490234375, Test ACC: 0.6107142857142858\n",
      "11, total loss = 9.478073120117188, reconstruct loss = 0.016980009153485298, cluster loss = 0.03888474777340889, calm loss = 3.861361026763916, pilot loss = 10.239197731018066, max interval = -8.97872257232666, \n",
      "Train ACC: 0.6415094339622641, PTA: 0.7578125, Test ACC: 0.6071428571428571\n",
      "12, total loss = 9.430562973022461, reconstruct loss = 0.016092879697680473, cluster loss = 0.04084350913763046, calm loss = 3.8439624309539795, pilot loss = 10.184903144836426, max interval = -8.94552230834961, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7568359375, Test ACC: 0.6035714285714285\n",
      "13, total loss = 9.384812355041504, reconstruct loss = 0.018873173743486404, cluster loss = 0.04026695713400841, calm loss = 3.826580762863159, pilot loss = 10.131514549255371, max interval = -8.912745475769043, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7578125, Test ACC: 0.6035714285714285\n",
      "14, total loss = 9.334941864013672, reconstruct loss = 0.017336150631308556, cluster loss = 0.03923708200454712, calm loss = 3.809152126312256, pilot loss = 10.079418182373047, max interval = -8.880818367004395, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7783203125, Test ACC: 0.6035714285714285\n",
      "15, total loss = 9.290037155151367, reconstruct loss = 0.01744510419666767, cluster loss = 0.04094541072845459, calm loss = 3.791675090789795, pilot loss = 10.028294563293457, max interval = -8.849386215209961, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7353515625, Test ACC: 0.6\n",
      "16, total loss = 9.242998123168945, reconstruct loss = 0.018497923389077187, cluster loss = 0.03912907838821411, calm loss = 3.7740237712860107, pilot loss = 9.978086471557617, max interval = -8.818371772766113, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7578125, Test ACC: 0.6\n",
      "17, total loss = 9.197309494018555, reconstruct loss = 0.0176136065274477, cluster loss = 0.040135424584150314, calm loss = 3.756246566772461, pilot loss = 9.928762435913086, max interval = -8.7877779006958, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.748046875, Test ACC: 0.6\n",
      "18, total loss = 9.157061576843262, reconstruct loss = 0.01947629265487194, cluster loss = 0.043302979320287704, calm loss = 3.7384095191955566, pilot loss = 9.880292892456055, max interval = -8.757561683654785, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7275390625, Test ACC: 0.6\n",
      "19, total loss = 9.107208251953125, reconstruct loss = 0.01739458367228508, cluster loss = 0.04022670164704323, calm loss = 3.7204971313476562, pilot loss = 9.83299732208252, max interval = -8.728079795837402, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7587890625, Test ACC: 0.5964285714285714\n",
      "20, total loss = 9.065189361572266, reconstruct loss = 0.01810750924050808, cluster loss = 0.041719965636730194, calm loss = 3.702498197555542, pilot loss = 9.786537170410156, max interval = -8.69900131225586, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.75390625, Test ACC: 0.5928571428571429\n",
      "21, total loss = 9.021636009216309, reconstruct loss = 0.018254507333040237, cluster loss = 0.04196207970380783, calm loss = 3.6843605041503906, pilot loss = 9.740744590759277, max interval = -8.670271873474121, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.7421875, Test ACC: 0.5928571428571429\n",
      "22, total loss = 8.977678298950195, reconstruct loss = 0.01910758577287197, cluster loss = 0.04068082943558693, calm loss = 3.666175365447998, pilot loss = 9.695701599121094, max interval = -8.64195728302002, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.75390625, Test ACC: 0.5928571428571429\n",
      "23, total loss = 8.935272216796875, reconstruct loss = 0.018180904909968376, cluster loss = 0.04225458949804306, calm loss = 3.647970676422119, pilot loss = 9.651481628417969, max interval = -8.614110946655273, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7314453125, Test ACC: 0.5892857142857143\n",
      "24, total loss = 8.893182754516602, reconstruct loss = 0.018599193543195724, cluster loss = 0.04235195368528366, calm loss = 3.6298117637634277, pilot loss = 9.607844352722168, max interval = -8.58652114868164, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.73046875, Test ACC: 0.5821428571428572\n",
      "25, total loss = 8.849059104919434, reconstruct loss = 0.01873656176030636, cluster loss = 0.040303029119968414, calm loss = 3.6116511821746826, pilot loss = 9.564801216125488, max interval = -8.559219360351562, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7626953125, Test ACC: 0.5821428571428572\n",
      "26, total loss = 8.805816650390625, reconstruct loss = 0.018348058685660362, cluster loss = 0.03934354707598686, calm loss = 3.593453884124756, pilot loss = 9.522300720214844, max interval = -8.532187461853027, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7685546875, Test ACC: 0.5821428571428572\n",
      "27, total loss = 8.766424179077148, reconstruct loss = 0.020781299099326134, cluster loss = 0.039089128375053406, calm loss = 3.5752227306365967, pilot loss = 9.480350494384766, max interval = -8.5054292678833, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.75390625, Test ACC: 0.5821428571428572\n",
      "28, total loss = 8.72611141204834, reconstruct loss = 0.01901472546160221, cluster loss = 0.04178044945001602, calm loss = 3.556969404220581, pilot loss = 9.43895149230957, max interval = -8.478951454162598, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7373046875, Test ACC: 0.5821428571428572\n",
      "29, total loss = 8.685295104980469, reconstruct loss = 0.01973024196922779, cluster loss = 0.041205994784832, calm loss = 3.538700580596924, pilot loss = 9.39804744720459, max interval = -8.452759742736816, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7509765625, Test ACC: 0.5821428571428572\n",
      "30, total loss = 8.642035484313965, reconstruct loss = 0.017959317192435265, cluster loss = 0.04035945236682892, calm loss = 3.520428419113159, pilot loss = 9.357645034790039, max interval = -8.42682933807373, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7578125, Test ACC: 0.575\n",
      "31, total loss = 8.606138229370117, reconstruct loss = 0.02006266452372074, cluster loss = 0.042714741080999374, calm loss = 3.5021564960479736, pilot loss = 9.317514419555664, max interval = -8.40087604522705, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7265625, Test ACC: 0.575\n",
      "32, total loss = 8.563090324401855, reconstruct loss = 0.01892903819680214, cluster loss = 0.040880557149648666, calm loss = 3.4838881492614746, pilot loss = 9.277565956115723, max interval = -8.374798774719238, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7421875, Test ACC: 0.575\n",
      "33, total loss = 8.523090362548828, reconstruct loss = 0.01842663809657097, cluster loss = 0.04123755544424057, calm loss = 3.4656167030334473, pilot loss = 9.238090515136719, max interval = -8.349066734313965, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.7470703125, Test ACC: 0.575\n",
      "34, total loss = 8.487262725830078, reconstruct loss = 0.019892876967787743, cluster loss = 0.04359377175569534, calm loss = 3.4473533630371094, pilot loss = 9.199333190917969, max interval = -8.324085235595703, \n",
      "Train ACC: 0.6132075471698113, PTA: 0.7197265625, Test ACC: 0.575\n",
      "35, total loss = 8.447253227233887, reconstruct loss = 0.020565640181303024, cluster loss = 0.04232672601938248, calm loss = 3.429119825363159, pilot loss = 9.161124229431152, max interval = -8.299591064453125, \n",
      "Train ACC: 0.6132075471698113, PTA: 0.736328125, Test ACC: 0.575\n",
      "36, total loss = 8.40865421295166, reconstruct loss = 0.020782465115189552, cluster loss = 0.042693089693784714, calm loss = 3.4109129905700684, pilot loss = 9.123356819152832, max interval = -8.275436401367188, \n",
      "Train ACC: 0.6132075471698113, PTA: 0.7216796875, Test ACC: 0.5714285714285714\n",
      "37, total loss = 8.37044906616211, reconstruct loss = 0.02141895331442356, cluster loss = 0.04114392772316933, calm loss = 3.3928635120391846, pilot loss = 9.087559700012207, max interval = -8.251619338989258, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.732421875, Test ACC: 0.5714285714285714\n",
      "38, total loss = 8.330461502075195, reconstruct loss = 0.019839633256196976, cluster loss = 0.0405430942773819, calm loss = 3.3752357959747314, pilot loss = 9.050546646118164, max interval = -8.22740650177002, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.7451171875, Test ACC: 0.5678571428571428\n",
      "39, total loss = 8.293757438659668, reconstruct loss = 0.01930614747107029, cluster loss = 0.043102022260427475, calm loss = 3.3575828075408936, pilot loss = 9.01246452331543, max interval = -8.202946662902832, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.7177734375, Test ACC: 0.5642857142857143\n",
      "40, total loss = 8.257023811340332, reconstruct loss = 0.021304350346326828, cluster loss = 0.04163534194231033, calm loss = 3.339911699295044, pilot loss = 8.97573184967041, max interval = -8.178296089172363, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.74609375, Test ACC: 0.5607142857142857\n",
      "41, total loss = 8.219225883483887, reconstruct loss = 0.020030155777931213, cluster loss = 0.042032886296510696, calm loss = 3.322254180908203, pilot loss = 8.939597129821777, max interval = -8.154029846191406, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.736328125, Test ACC: 0.5571428571428572\n",
      "42, total loss = 8.182238578796387, reconstruct loss = 0.02050579898059368, cluster loss = 0.041426610201597214, calm loss = 3.3046417236328125, pilot loss = 8.90369701385498, max interval = -8.130070686340332, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.7265625, Test ACC: 0.5571428571428572\n",
      "43, total loss = 8.148248672485352, reconstruct loss = 0.021194616332650185, cluster loss = 0.042776525020599365, calm loss = 3.2876522541046143, pilot loss = 8.868104934692383, max interval = -8.106258392333984, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7275390625, Test ACC: 0.5571428571428572\n",
      "44, total loss = 8.111224174499512, reconstruct loss = 0.020726950839161873, cluster loss = 0.04108842834830284, calm loss = 3.27156400680542, pilot loss = 8.832806587219238, max interval = -8.08249568939209, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7265625, Test ACC: 0.5571428571428572\n",
      "45, total loss = 8.077654838562012, reconstruct loss = 0.02112751081585884, cluster loss = 0.04179965332150459, calm loss = 3.255573272705078, pilot loss = 8.797818183898926, max interval = -8.059048652648926, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7275390625, Test ACC: 0.5571428571428572\n",
      "46, total loss = 8.041839599609375, reconstruct loss = 0.02061951346695423, cluster loss = 0.040998879820108414, calm loss = 3.2396721839904785, pilot loss = 8.763107299804688, max interval = -8.035877227783203, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.73046875, Test ACC: 0.5535714285714286\n",
      "47, total loss = 8.009490013122559, reconstruct loss = 0.02142469957470894, cluster loss = 0.04221200942993164, calm loss = 3.223841428756714, pilot loss = 8.728666305541992, max interval = -8.012991905212402, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7001953125, Test ACC: 0.5535714285714286\n",
      "48, total loss = 7.9756622314453125, reconstruct loss = 0.021112827584147453, cluster loss = 0.04289177805185318, calm loss = 3.2081050872802734, pilot loss = 8.694486618041992, max interval = -7.99036979675293, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7158203125, Test ACC: 0.5535714285714286\n",
      "49, total loss = 7.940211296081543, reconstruct loss = 0.021006660535931587, cluster loss = 0.04160889983177185, calm loss = 3.19244122505188, pilot loss = 8.660538673400879, max interval = -7.967989921569824, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7392578125, Test ACC: 0.55\n",
      "50, total loss = 7.906312942504883, reconstruct loss = 0.020813113078475, cluster loss = 0.04181361198425293, calm loss = 3.1768627166748047, pilot loss = 8.626803398132324, max interval = -7.94581937789917, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7392578125, Test ACC: 0.5464285714285714\n",
      "51, total loss = 7.873846054077148, reconstruct loss = 0.022480957210063934, cluster loss = 0.04143618792295456, calm loss = 3.161367177963257, pilot loss = 8.593253135681152, max interval = -7.923812389373779, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.705078125, Test ACC: 0.5464285714285714\n",
      "52, total loss = 7.839330673217773, reconstruct loss = 0.02105739153921604, cluster loss = 0.04192470759153366, calm loss = 3.145974636077881, pilot loss = 8.559953689575195, max interval = -7.902059078216553, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.708984375, Test ACC: 0.5464285714285714\n",
      "53, total loss = 7.80639123916626, reconstruct loss = 0.02240539900958538, cluster loss = 0.04103928059339523, calm loss = 3.1306748390197754, pilot loss = 8.526936531066895, max interval = -7.880583763122559, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.724609375, Test ACC: 0.5464285714285714\n",
      "54, total loss = 7.774435997009277, reconstruct loss = 0.023400673642754555, cluster loss = 0.04133882373571396, calm loss = 3.1154873371124268, pilot loss = 8.49405574798584, max interval = -7.859246253967285, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7197265625, Test ACC: 0.5464285714285714\n",
      "55, total loss = 7.740665435791016, reconstruct loss = 0.022289669141173363, cluster loss = 0.04155340418219566, calm loss = 3.1004011631011963, pilot loss = 8.461654663085938, max interval = -7.838202953338623, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.732421875, Test ACC: 0.5464285714285714\n",
      "56, total loss = 7.709744930267334, reconstruct loss = 0.022763986140489578, cluster loss = 0.04286666586995125, calm loss = 3.085432529449463, pilot loss = 8.429487228393555, max interval = -7.81742525100708, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.705078125, Test ACC: 0.5428571428571428\n",
      "57, total loss = 7.675546646118164, reconstruct loss = 0.022676005959510803, cluster loss = 0.04097892343997955, calm loss = 3.0708041191101074, pilot loss = 8.397379875183105, max interval = -7.796523094177246, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.72265625, Test ACC: 0.5392857142857143\n",
      "58, total loss = 7.643055438995361, reconstruct loss = 0.02244836650788784, cluster loss = 0.040730491280555725, calm loss = 3.056302547454834, pilot loss = 8.365460395812988, max interval = -7.7757720947265625, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.7275390625, Test ACC: 0.5357142857142857\n",
      "59, total loss = 7.614213943481445, reconstruct loss = 0.02307257428765297, cluster loss = 0.04311668872833252, calm loss = 3.041905641555786, pilot loss = 8.333672523498535, max interval = -7.755125999450684, \n",
      "Train ACC: 0.5849056603773585, PTA: 0.708984375, Test ACC: 0.5357142857142857\n",
      "60, total loss = 7.582472801208496, reconstruct loss = 0.02326918952167034, cluster loss = 0.04286012798547745, calm loss = 3.027614116668701, pilot loss = 8.302068710327148, max interval = -7.734651565551758, \n",
      "Train ACC: 0.5849056603773585, PTA: 0.7197265625, Test ACC: 0.5321428571428571\n",
      "61, total loss = 7.549452781677246, reconstruct loss = 0.023483386263251305, cluster loss = 0.04116202890872955, calm loss = 3.0134286880493164, pilot loss = 8.27066421508789, max interval = -7.714402675628662, \n",
      "Train ACC: 0.5849056603773585, PTA: 0.728515625, Test ACC: 0.5285714285714286\n",
      "62, total loss = 7.517745494842529, reconstruct loss = 0.023293698206543922, cluster loss = 0.04090921953320503, calm loss = 2.999346971511841, pilot loss = 8.239566802978516, max interval = -7.694352149963379, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.720703125, Test ACC: 0.5285714285714286\n",
      "63, total loss = 7.4888997077941895, reconstruct loss = 0.025198180228471756, cluster loss = 0.04122444987297058, calm loss = 2.985342502593994, pilot loss = 8.208696365356445, max interval = -7.674450874328613, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.7197265625, Test ACC: 0.5321428571428571\n",
      "64, total loss = 7.4573893547058105, reconstruct loss = 0.023366760462522507, cluster loss = 0.04231932759284973, calm loss = 2.9714207649230957, pilot loss = 8.178121566772461, max interval = -7.6546735763549805, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.7197265625, Test ACC: 0.5321428571428571\n",
      "65, total loss = 7.429164409637451, reconstruct loss = 0.02395153045654297, cluster loss = 0.043842144310474396, calm loss = 2.9575393199920654, pilot loss = 8.147994041442871, max interval = -7.6349616050720215, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.708984375, Test ACC: 0.5285714285714286\n",
      "66, total loss = 7.396519660949707, reconstruct loss = 0.02424536645412445, cluster loss = 0.041129838675260544, calm loss = 2.9437193870544434, pilot loss = 8.117987632751465, max interval = -7.615357875823975, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.751953125, Test ACC: 0.5285714285714286\n",
      "67, total loss = 7.367600917816162, reconstruct loss = 0.024172775447368622, cluster loss = 0.042300689965486526, calm loss = 2.9299697875976562, pilot loss = 8.088162422180176, max interval = -7.595813274383545, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.703125, Test ACC: 0.525\n",
      "68, total loss = 7.339104652404785, reconstruct loss = 0.024927301332354546, cluster loss = 0.04290631785988808, calm loss = 2.9163198471069336, pilot loss = 8.058496475219727, max interval = -7.576410293579102, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.6982421875, Test ACC: 0.525\n",
      "69, total loss = 7.308257102966309, reconstruct loss = 0.023586628958582878, cluster loss = 0.04315304383635521, calm loss = 2.902742862701416, pilot loss = 8.028999328613281, max interval = -7.55720329284668, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.7021484375, Test ACC: 0.525\n",
      "70, total loss = 7.2773847579956055, reconstruct loss = 0.023251960054039955, cluster loss = 0.04224076867103577, calm loss = 2.889242172241211, pilot loss = 7.999690055847168, max interval = -7.538190841674805, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.6982421875, Test ACC: 0.525\n",
      "71, total loss = 7.249459266662598, reconstruct loss = 0.024287084117531776, cluster loss = 0.04265660420060158, calm loss = 2.875884532928467, pilot loss = 7.970595359802246, max interval = -7.519332408905029, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.7236328125, Test ACC: 0.5214285714285715\n",
      "72, total loss = 7.2183837890625, reconstruct loss = 0.024465830996632576, cluster loss = 0.040603168308734894, calm loss = 2.8626112937927246, pilot loss = 7.941695213317871, max interval = -7.500619888305664, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.716796875, Test ACC: 0.5178571428571429\n",
      "73, total loss = 7.1905198097229, reconstruct loss = 0.024404678493738174, cluster loss = 0.04194064810872078, calm loss = 2.849381923675537, pilot loss = 7.912912845611572, max interval = -7.48205041885376, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.6884765625, Test ACC: 0.5178571428571429\n",
      "74, total loss = 7.162303447723389, reconstruct loss = 0.025357943028211594, cluster loss = 0.04180280491709709, calm loss = 2.8362226486206055, pilot loss = 7.884292125701904, max interval = -7.463658332824707, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.701171875, Test ACC: 0.5178571428571429\n",
      "75, total loss = 7.133135795593262, reconstruct loss = 0.025778459385037422, cluster loss = 0.041105467826128006, calm loss = 2.8231568336486816, pilot loss = 7.855801105499268, max interval = -7.445381164550781, \n",
      "Train ACC: 0.5566037735849056, PTA: 0.7060546875, Test ACC: 0.5178571428571429\n",
      "76, total loss = 7.1033854484558105, reconstruct loss = 0.024731408804655075, cluster loss = 0.04115934669971466, calm loss = 2.8101727962493896, pilot loss = 7.827451705932617, max interval = -7.4272308349609375, \n",
      "Train ACC: 0.5566037735849056, PTA: 0.701171875, Test ACC: 0.5142857142857142\n",
      "77, total loss = 7.075875282287598, reconstruct loss = 0.02562437392771244, cluster loss = 0.04120476543903351, calm loss = 2.7972710132598877, pilot loss = 7.799440383911133, max interval = -7.409239768981934, \n",
      "Train ACC: 0.5566037735849056, PTA: 0.716796875, Test ACC: 0.5107142857142857\n",
      "78, total loss = 7.047107696533203, reconstruct loss = 0.025362681597471237, cluster loss = 0.041045404970645905, calm loss = 2.7844796180725098, pilot loss = 7.771519660949707, max interval = -7.391390323638916, \n",
      "Train ACC: 0.5566037735849056, PTA: 0.724609375, Test ACC: 0.5107142857142857\n",
      "79, total loss = 7.020416259765625, reconstruct loss = 0.02610057406127453, cluster loss = 0.041895635426044464, calm loss = 2.7718076705932617, pilot loss = 7.743669509887695, max interval = -7.373712539672852, \n",
      "Train ACC: 0.5471698113207547, PTA: 0.71484375, Test ACC: 0.5107142857142857\n",
      "80, total loss = 6.9914703369140625, reconstruct loss = 0.024612005800008774, cluster loss = 0.04265313595533371, calm loss = 2.759235382080078, pilot loss = 7.715897083282471, max interval = -7.356196880340576, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.7041015625, Test ACC: 0.5071428571428571\n",
      "81, total loss = 6.962944507598877, reconstruct loss = 0.025825917720794678, cluster loss = 0.04107683524489403, calm loss = 2.746764898300171, pilot loss = 7.688200950622559, max interval = -7.338860511779785, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.712890625, Test ACC: 0.5071428571428571\n",
      "82, total loss = 6.9324116706848145, reconstruct loss = 0.025231972336769104, cluster loss = 0.03921160474419594, calm loss = 2.734412431716919, pilot loss = 7.66057825088501, max interval = -7.321669578552246, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.7314453125, Test ACC: 0.5035714285714286\n",
      "83, total loss = 6.906650066375732, reconstruct loss = 0.025307824835181236, cluster loss = 0.041284456849098206, calm loss = 2.7221615314483643, pilot loss = 7.633129596710205, max interval = -7.304637908935547, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.7109375, Test ACC: 0.5\n",
      "84, total loss = 6.8797078132629395, reconstruct loss = 0.02532069943845272, cluster loss = 0.04208161681890488, calm loss = 2.7099788188934326, pilot loss = 7.605802536010742, max interval = -7.287649631500244, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.6826171875, Test ACC: 0.5\n",
      "85, total loss = 6.853897571563721, reconstruct loss = 0.027026960626244545, cluster loss = 0.0422489196062088, calm loss = 2.6978862285614014, pilot loss = 7.578492164611816, max interval = -7.270716667175293, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.71875, Test ACC: 0.5\n",
      "86, total loss = 6.823237895965576, reconstruct loss = 0.025152213871479034, cluster loss = 0.041085533797740936, calm loss = 2.685873031616211, pilot loss = 7.551255702972412, max interval = -7.253911972045898, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.7314453125, Test ACC: 0.49642857142857144\n",
      "87, total loss = 6.796877384185791, reconstruct loss = 0.026899930089712143, cluster loss = 0.04054271802306175, calm loss = 2.673912525177002, pilot loss = 7.524062633514404, max interval = -7.237162113189697, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.69140625, Test ACC: 0.49642857142857144\n",
      "88, total loss = 6.770354270935059, reconstruct loss = 0.026644069701433182, cluster loss = 0.0417008176445961, calm loss = 2.662006139755249, pilot loss = 7.497006893157959, max interval = -7.220487594604492, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.6884765625, Test ACC: 0.4928571428571429\n",
      "89, total loss = 6.743669509887695, reconstruct loss = 0.025694668292999268, cluster loss = 0.043258555233478546, calm loss = 2.6501688957214355, pilot loss = 7.470107555389404, max interval = -7.203945636749268, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.67578125, Test ACC: 0.48928571428571427\n",
      "90, total loss = 6.718789577484131, reconstruct loss = 0.027764132246375084, cluster loss = 0.04353567957878113, calm loss = 2.638390302658081, pilot loss = 7.443325996398926, max interval = -7.187558174133301, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.69140625, Test ACC: 0.4857142857142857\n",
      "91, total loss = 6.6883158683776855, reconstruct loss = 0.027231717482209206, cluster loss = 0.04072997346520424, calm loss = 2.6266674995422363, pilot loss = 7.41666316986084, max interval = -7.171290397644043, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.7158203125, Test ACC: 0.48214285714285715\n",
      "92, total loss = 6.660331726074219, reconstruct loss = 0.02586492709815502, cluster loss = 0.041382599622011185, calm loss = 2.6149957180023193, pilot loss = 7.389962673187256, max interval = -7.155232906341553, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.705078125, Test ACC: 0.4857142857142857\n",
      "93, total loss = 6.634955883026123, reconstruct loss = 0.02573608234524727, cluster loss = 0.043364811688661575, calm loss = 2.6033644676208496, pilot loss = 7.363339900970459, max interval = -7.139286041259766, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.6904296875, Test ACC: 0.4857142857142857\n",
      "94, total loss = 6.608325004577637, reconstruct loss = 0.027737494558095932, cluster loss = 0.0419449619948864, calm loss = 2.5917770862579346, pilot loss = 7.336841583251953, max interval = -7.123555660247803, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.685546875, Test ACC: 0.4857142857142857\n",
      "95, total loss = 6.5790581703186035, reconstruct loss = 0.027194790542125702, cluster loss = 0.040457963943481445, calm loss = 2.5801901817321777, pilot loss = 7.310435771942139, max interval = -7.107990741729736, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.70703125, Test ACC: 0.4857142857142857\n",
      "96, total loss = 6.552044868469238, reconstruct loss = 0.02629963867366314, cluster loss = 0.04154740646481514, calm loss = 2.56864595413208, pilot loss = 7.284112453460693, max interval = -7.092564105987549, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.7080078125, Test ACC: 0.4857142857142857\n",
      "97, total loss = 6.526321887969971, reconstruct loss = 0.02860901691019535, cluster loss = 0.04069021716713905, calm loss = 2.5571417808532715, pilot loss = 7.257917881011963, max interval = -7.077331066131592, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.7021484375, Test ACC: 0.4857142857142857\n",
      "98, total loss = 6.500199794769287, reconstruct loss = 0.028834844008088112, cluster loss = 0.04144439101219177, calm loss = 2.545732021331787, pilot loss = 7.2318339347839355, max interval = -7.06228494644165, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.701171875, Test ACC: 0.4857142857142857\n",
      "99, total loss = 6.473572254180908, reconstruct loss = 0.028397077694535255, cluster loss = 0.04232732951641083, calm loss = 2.5343964099884033, pilot loss = 7.205842971801758, max interval = -7.047435283660889, \n",
      "Train ACC: 0.5188679245283019, PTA: 0.689453125, Test ACC: 0.48214285714285715\n",
      "100, total loss = 6.447067737579346, reconstruct loss = 0.027416398748755455, cluster loss = 0.043747879564762115, calm loss = 2.5231175422668457, pilot loss = 7.180023670196533, max interval = -7.032728672027588, \n",
      "Train ACC: 0.5094339622641509, PTA: 0.6484375, Test ACC: 0.48214285714285715\n",
      "101, total loss = 6.420408725738525, reconstruct loss = 0.028235377743840218, cluster loss = 0.04309915751218796, calm loss = 2.5119128227233887, pilot loss = 7.154333591461182, max interval = -7.018147945404053, \n",
      "Train ACC: 0.5, PTA: 0.3125, Test ACC: 0.5178571428571429\n",
      "102, total loss = 6.395430564880371, reconstruct loss = 0.030495373532176018, cluster loss = 0.042666055262088776, calm loss = 2.500728130340576, pilot loss = 7.12874174118042, max interval = -7.003698825836182, \n",
      "Train ACC: 0.5, PTA: 0.3310546875, Test ACC: 0.5178571428571429\n",
      "103, total loss = 6.366971969604492, reconstruct loss = 0.02939886972308159, cluster loss = 0.042303282767534256, calm loss = 2.4895102977752686, pilot loss = 7.103180885314941, max interval = -6.989526748657227, \n",
      "Train ACC: 0.5, PTA: 0.2958984375, Test ACC: 0.5178571428571429\n",
      "104, total loss = 6.340381622314453, reconstruct loss = 0.028889693319797516, cluster loss = 0.04319285601377487, calm loss = 2.4783382415771484, pilot loss = 7.0778021812438965, max interval = -6.975638389587402, \n",
      "Train ACC: 0.5, PTA: 0.322265625, Test ACC: 0.525\n",
      "105, total loss = 6.314699172973633, reconstruct loss = 0.02944120764732361, cluster loss = 0.04383501783013344, calm loss = 2.467219591140747, pilot loss = 7.052611827850342, max interval = -6.9619598388671875, \n",
      "Train ACC: 0.5, PTA: 0.3212890625, Test ACC: 0.5285714285714286\n",
      "106, total loss = 6.287650108337402, reconstruct loss = 0.030172469094395638, cluster loss = 0.042905569076538086, calm loss = 2.45613431930542, pilot loss = 7.027518272399902, max interval = -6.948431015014648, \n",
      "Train ACC: 0.5, PTA: 0.318359375, Test ACC: 0.5321428571428571\n",
      "107, total loss = 6.260134696960449, reconstruct loss = 0.027950983494520187, cluster loss = 0.044398050755262375, calm loss = 2.445082426071167, pilot loss = 7.002604007720947, max interval = -6.935113906860352, \n",
      "Train ACC: 0.5, PTA: 0.31640625, Test ACC: 0.5357142857142857\n",
      "108, total loss = 6.233283996582031, reconstruct loss = 0.02965063415467739, cluster loss = 0.04260508343577385, calm loss = 2.4340693950653076, pilot loss = 6.977818965911865, max interval = -6.921994209289551, \n",
      "Train ACC: 0.5, PTA: 0.314453125, Test ACC: 0.5392857142857143\n",
      "109, total loss = 6.209982395172119, reconstruct loss = 0.03169441595673561, cluster loss = 0.04397514462471008, calm loss = 2.4230995178222656, pilot loss = 6.953195095062256, max interval = -6.909107208251953, \n",
      "Train ACC: 0.5, PTA: 0.34375, Test ACC: 0.5392857142857143\n",
      "110, total loss = 6.181496620178223, reconstruct loss = 0.03286483883857727, cluster loss = 0.040960896760225296, calm loss = 2.4121663570404053, pilot loss = 6.928789138793945, max interval = -6.89647912979126, \n",
      "Train ACC: 0.5094339622641509, PTA: 0.318359375, Test ACC: 0.5392857142857143\n",
      "111, total loss = 6.153077602386475, reconstruct loss = 0.029876409098505974, cluster loss = 0.0421668216586113, calm loss = 2.4012560844421387, pilot loss = 6.904560565948486, max interval = -6.884128093719482, \n",
      "Train ACC: 0.5094339622641509, PTA: 0.306640625, Test ACC: 0.5392857142857143\n",
      "112, total loss = 6.128110885620117, reconstruct loss = 0.0308062806725502, cluster loss = 0.04288044571876526, calm loss = 2.3903820514678955, pilot loss = 6.880499362945557, max interval = -6.872031211853027, \n",
      "Train ACC: 0.5094339622641509, PTA: 0.333984375, Test ACC: 0.5428571428571428\n",
      "113, total loss = 6.1012163162231445, reconstruct loss = 0.03185058385133743, cluster loss = 0.04158686846494675, calm loss = 2.379457950592041, pilot loss = 6.8565850257873535, max interval = -6.8601226806640625, \n",
      "Train ACC: 0.5094339622641509, PTA: 0.326171875, Test ACC: 0.5464285714285714\n",
      "114, total loss = 6.074150085449219, reconstruct loss = 0.03054904378950596, cluster loss = 0.04290315508842468, calm loss = 2.3680877685546875, pilot loss = 6.832815647125244, max interval = -6.848405361175537, \n",
      "Train ACC: 0.5094339622641509, PTA: 0.33984375, Test ACC: 0.5464285714285714\n",
      "115, total loss = 6.046248912811279, reconstruct loss = 0.03067738749086857, cluster loss = 0.04196132346987724, calm loss = 2.356693983078003, pilot loss = 6.80928373336792, max interval = -6.837004661560059, \n",
      "Train ACC: 0.5188679245283019, PTA: 0.29296875, Test ACC: 0.55\n",
      "116, total loss = 6.020535469055176, reconstruct loss = 0.030621938407421112, cluster loss = 0.04346953332424164, calm loss = 2.3452632427215576, pilot loss = 6.7858805656433105, max interval = -6.825847625732422, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.34765625, Test ACC: 0.5535714285714286\n",
      "117, total loss = 5.9945807456970215, reconstruct loss = 0.03187715262174606, cluster loss = 0.04341006651520729, calm loss = 2.3338210582733154, pilot loss = 6.762683868408203, max interval = -6.814946174621582, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.3369140625, Test ACC: 0.5535714285714286\n",
      "118, total loss = 5.967222213745117, reconstruct loss = 0.030876200646162033, cluster loss = 0.044185228645801544, calm loss = 2.322359561920166, pilot loss = 6.739628791809082, max interval = -6.80419397354126, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.3330078125, Test ACC: 0.5571428571428572\n",
      "119, total loss = 5.939820766448975, reconstruct loss = 0.031697846949100494, cluster loss = 0.04313187301158905, calm loss = 2.3108909130096436, pilot loss = 6.7166748046875, max interval = -6.793629169464111, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.3310546875, Test ACC: 0.5607142857142857\n",
      "120, total loss = 5.912343978881836, reconstruct loss = 0.03133978694677353, cluster loss = 0.04324633255600929, calm loss = 2.299417734146118, pilot loss = 6.693813800811768, max interval = -6.783282279968262, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.310546875, Test ACC: 0.5607142857142857\n",
      "121, total loss = 5.885361671447754, reconstruct loss = 0.031167378649115562, cluster loss = 0.0433921255171299, calm loss = 2.2879440784454346, pilot loss = 6.671391487121582, max interval = -6.773165702819824, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.32421875, Test ACC: 0.5678571428571428\n",
      "122, total loss = 5.857512474060059, reconstruct loss = 0.032918304204940796, cluster loss = 0.04083717241883278, calm loss = 2.2764790058135986, pilot loss = 6.649125099182129, max interval = -6.76340913772583, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.3212890625, Test ACC: 0.5714285714285714\n",
      "123, total loss = 5.831414699554443, reconstruct loss = 0.032393679022789, cluster loss = 0.04239165782928467, calm loss = 2.265026092529297, pilot loss = 6.626923561096191, max interval = -6.753882884979248, \n",
      "Train ACC: 0.5283018867924528, PTA: 0.3212890625, Test ACC: 0.575\n",
      "124, total loss = 5.8046555519104, reconstruct loss = 0.03382668271660805, cluster loss = 0.04136703163385391, calm loss = 2.253612995147705, pilot loss = 6.60487174987793, max interval = -6.744683742523193, \n",
      "Train ACC: 0.5377358490566038, PTA: 0.3232421875, Test ACC: 0.575\n",
      "125, total loss = 5.778427600860596, reconstruct loss = 0.03286280110478401, cluster loss = 0.04328465834259987, calm loss = 2.2422242164611816, pilot loss = 6.582991600036621, max interval = -6.735786437988281, \n",
      "Train ACC: 0.5471698113207547, PTA: 0.33203125, Test ACC: 0.5785714285714286\n",
      "126, total loss = 5.749870777130127, reconstruct loss = 0.03164297342300415, cluster loss = 0.04310467839241028, calm loss = 2.230863332748413, pilot loss = 6.561277389526367, max interval = -6.727128505706787, \n",
      "Train ACC: 0.5566037735849056, PTA: 0.3544921875, Test ACC: 0.5857142857142857\n",
      "127, total loss = 5.724485874176025, reconstruct loss = 0.0335712730884552, cluster loss = 0.042940545827150345, calm loss = 2.2195582389831543, pilot loss = 6.539688587188721, max interval = -6.718719482421875, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.3359375, Test ACC: 0.5857142857142857\n",
      "128, total loss = 5.700098991394043, reconstruct loss = 0.035144317895174026, cluster loss = 0.044087935239076614, calm loss = 2.208322763442993, pilot loss = 6.518304824829102, max interval = -6.710644245147705, \n",
      "Train ACC: 0.5660377358490566, PTA: 0.357421875, Test ACC: 0.5892857142857143\n",
      "129, total loss = 5.671176433563232, reconstruct loss = 0.033261507749557495, cluster loss = 0.044173311442136765, calm loss = 2.1971850395202637, pilot loss = 6.496964931488037, max interval = -6.702798366546631, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.3427734375, Test ACC: 0.5892857142857143\n",
      "130, total loss = 5.64601469039917, reconstruct loss = 0.03462963551282883, cluster loss = 0.04484417289495468, calm loss = 2.186145782470703, pilot loss = 6.475636959075928, max interval = -6.695216655731201, \n",
      "Train ACC: 0.5754716981132075, PTA: 0.3525390625, Test ACC: 0.5928571428571429\n",
      "131, total loss = 5.62087869644165, reconstruct loss = 0.037424296140670776, cluster loss = 0.044157542288303375, calm loss = 2.1752073764801025, pilot loss = 6.4543585777282715, max interval = -6.687912940979004, \n",
      "Train ACC: 0.5849056603773585, PTA: 0.3583984375, Test ACC: 0.5928571428571429\n",
      "132, total loss = 5.590187072753906, reconstruct loss = 0.035560350865125656, cluster loss = 0.04235861077904701, calm loss = 2.164454221725464, pilot loss = 6.4331841468811035, max interval = -6.6807146072387695, \n",
      "Train ACC: 0.5849056603773585, PTA: 0.349609375, Test ACC: 0.5928571428571429\n",
      "133, total loss = 5.563282489776611, reconstruct loss = 0.03402473032474518, cluster loss = 0.04400431364774704, calm loss = 2.153754711151123, pilot loss = 6.412220001220703, max interval = -6.67387580871582, \n",
      "Train ACC: 0.5849056603773585, PTA: 0.3515625, Test ACC: 0.5964285714285714\n",
      "134, total loss = 5.539656639099121, reconstruct loss = 0.0371805839240551, cluster loss = 0.04423170164227486, calm loss = 2.1431174278259277, pilot loss = 6.391416549682617, max interval = -6.667346000671387, \n",
      "Train ACC: 0.5943396226415094, PTA: 0.3701171875, Test ACC: 0.5964285714285714\n",
      "135, total loss = 5.513439178466797, reconstruct loss = 0.03812957555055618, cluster loss = 0.04403026029467583, calm loss = 2.132556676864624, pilot loss = 6.370755195617676, max interval = -6.661068439483643, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.3447265625, Test ACC: 0.6035714285714285\n",
      "136, total loss = 5.485440254211426, reconstruct loss = 0.036538172513246536, cluster loss = 0.04445125162601471, calm loss = 2.1220993995666504, pilot loss = 6.350203990936279, max interval = -6.654902458190918, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.3515625, Test ACC: 0.6071428571428571\n",
      "137, total loss = 5.459748268127441, reconstruct loss = 0.03685517609119415, cluster loss = 0.04535071551799774, calm loss = 2.1116862297058105, pilot loss = 6.329639434814453, max interval = -6.648892879486084, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.359375, Test ACC: 0.6035714285714285\n",
      "138, total loss = 5.428825378417969, reconstruct loss = 0.036946069449186325, cluster loss = 0.04223330318927765, calm loss = 2.101050853729248, pilot loss = 6.308647155761719, max interval = -6.643368244171143, \n",
      "Train ACC: 0.6037735849056604, PTA: 0.357421875, Test ACC: 0.6035714285714285\n",
      "139, total loss = 5.405327796936035, reconstruct loss = 0.03902609273791313, cluster loss = 0.04474847763776779, calm loss = 2.090219020843506, pilot loss = 6.287967205047607, max interval = -6.638289928436279, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.3662109375, Test ACC: 0.6107142857142858\n",
      "140, total loss = 5.374363899230957, reconstruct loss = 0.03645814582705498, cluster loss = 0.04472343623638153, calm loss = 2.079235315322876, pilot loss = 6.267462253570557, max interval = -6.63364315032959, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.3779296875, Test ACC: 0.6107142857142858\n",
      "141, total loss = 5.346883296966553, reconstruct loss = 0.038679320365190506, cluster loss = 0.043810367584228516, calm loss = 2.0681121349334717, pilot loss = 6.246983528137207, max interval = -6.629430770874023, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.3369140625, Test ACC: 0.6107142857142858\n",
      "142, total loss = 5.3208394050598145, reconstruct loss = 0.040832094848155975, cluster loss = 0.04461454227566719, calm loss = 2.056946277618408, pilot loss = 6.2266364097595215, max interval = -6.625652313232422, \n",
      "Train ACC: 0.6226415094339622, PTA: 0.3623046875, Test ACC: 0.6107142857142858\n",
      "143, total loss = 5.292046546936035, reconstruct loss = 0.04065023362636566, cluster loss = 0.04480259120464325, calm loss = 2.046030044555664, pilot loss = 6.206497669219971, max interval = -6.622237682342529, \n",
      "Train ACC: 0.6320754716981132, PTA: 0.3427734375, Test ACC: 0.6142857142857143\n",
      "144, total loss = 5.258605003356934, reconstruct loss = 0.03731239214539528, cluster loss = 0.04361189156770706, calm loss = 2.0350844860076904, pilot loss = 6.186433792114258, max interval = -6.619054317474365, \n",
      "Train ACC: 0.6415094339622641, PTA: 0.3330078125, Test ACC: 0.6178571428571429\n",
      "145, total loss = 5.233467102050781, reconstruct loss = 0.03907766193151474, cluster loss = 0.045505013316869736, calm loss = 2.024226665496826, pilot loss = 6.166593551635742, max interval = -6.616147518157959, \n",
      "Train ACC: 0.6509433962264151, PTA: 0.3447265625, Test ACC: 0.6178571428571429\n",
      "146, total loss = 5.206160545349121, reconstruct loss = 0.041224297136068344, cluster loss = 0.04490848630666733, calm loss = 2.0132765769958496, pilot loss = 6.147024631500244, max interval = -6.613584041595459, \n",
      "Train ACC: 0.6509433962264151, PTA: 0.34375, Test ACC: 0.6178571428571429\n",
      "147, total loss = 5.177196502685547, reconstruct loss = 0.04013553261756897, cluster loss = 0.04594242572784424, calm loss = 2.002335786819458, pilot loss = 6.1277546882629395, max interval = -6.611535549163818, \n",
      "Train ACC: 0.660377358490566, PTA: 0.3544921875, Test ACC: 0.6214285714285714\n",
      "148, total loss = 5.149389266967773, reconstruct loss = 0.04179919883608818, cluster loss = 0.04531659558415413, calm loss = 1.9913917779922485, pilot loss = 6.108738899230957, max interval = -6.609755516052246, \n",
      "Train ACC: 0.660377358490566, PTA: 0.34375, Test ACC: 0.6214285714285714\n",
      "149, total loss = 5.119390487670898, reconstruct loss = 0.03997144103050232, cluster loss = 0.045682795345783234, calm loss = 1.980765700340271, pilot loss = 6.090198516845703, max interval = -6.608667850494385, \n",
      "Train ACC: 0.660377358490566, PTA: 0.3642578125, Test ACC: 0.6285714285714286\n",
      "150, total loss = 5.090065002441406, reconstruct loss = 0.03992501646280289, cluster loss = 0.04474348947405815, calm loss = 1.9702688455581665, pilot loss = 6.072001934051514, max interval = -6.607977390289307, \n",
      "Train ACC: 0.660377358490566, PTA: 0.341796875, Test ACC: 0.6321428571428571\n",
      "151, total loss = 5.066303253173828, reconstruct loss = 0.043279003351926804, cluster loss = 0.04545842856168747, calm loss = 1.9598395824432373, pilot loss = 6.054066181182861, max interval = -6.60702657699585, \n",
      "Train ACC: 0.660377358490566, PTA: 0.36328125, Test ACC: 0.6357142857142857\n",
      "152, total loss = 5.036860942840576, reconstruct loss = 0.04179300367832184, cluster loss = 0.045594073832035065, calm loss = 1.9493402242660522, pilot loss = 6.036215782165527, max interval = -6.606471061706543, \n",
      "Train ACC: 0.660377358490566, PTA: 0.3603515625, Test ACC: 0.6321428571428571\n",
      "153, total loss = 5.0108819007873535, reconstruct loss = 0.04323657602071762, cluster loss = 0.04626554995775223, calm loss = 1.938768744468689, pilot loss = 6.018666744232178, max interval = -6.60624885559082, \n",
      "Train ACC: 0.6698113207547169, PTA: 0.3701171875, Test ACC: 0.6321428571428571\n",
      "154, total loss = 4.987086296081543, reconstruct loss = 0.04587253928184509, cluster loss = 0.047876905649900436, calm loss = 1.9281352758407593, pilot loss = 6.001276969909668, max interval = -6.606090545654297, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3681640625, Test ACC: 0.6357142857142857\n",
      "155, total loss = 4.961817741394043, reconstruct loss = 0.04805932939052582, cluster loss = 0.048317763954401016, calm loss = 1.9174559116363525, pilot loss = 5.984241008758545, max interval = -6.606163024902344, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3857421875, Test ACC: 0.6321428571428571\n",
      "156, total loss = 4.929157733917236, reconstruct loss = 0.04364878311753273, cluster loss = 0.04789836332201958, calm loss = 1.9067283868789673, pilot loss = 5.967653274536133, max interval = -6.606714248657227, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.353515625, Test ACC: 0.6392857142857142\n",
      "157, total loss = 4.902092456817627, reconstruct loss = 0.04422692954540253, cluster loss = 0.04801599308848381, calm loss = 1.895978569984436, pilot loss = 5.951360702514648, max interval = -6.607557773590088, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.353515625, Test ACC: 0.6428571428571429\n",
      "158, total loss = 4.873530387878418, reconstruct loss = 0.04201185703277588, cluster loss = 0.04932626709342003, calm loss = 1.88521409034729, pilot loss = 5.935181617736816, max interval = -6.608394145965576, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3642578125, Test ACC: 0.6428571428571429\n",
      "159, total loss = 4.851039409637451, reconstruct loss = 0.04874882102012634, cluster loss = 0.047699443995952606, calm loss = 1.8744688034057617, pilot loss = 5.919309616088867, max interval = -6.609617233276367, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.37890625, Test ACC: 0.65\n",
      "160, total loss = 4.815906047821045, reconstruct loss = 0.04113422706723213, cluster loss = 0.047695472836494446, calm loss = 1.8637421131134033, pilot loss = 5.903748512268066, max interval = -6.611186981201172, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3759765625, Test ACC: 0.6535714285714286\n",
      "161, total loss = 4.792843341827393, reconstruct loss = 0.04461443051695824, cluster loss = 0.048572152853012085, calm loss = 1.8530128002166748, pilot loss = 5.888484001159668, max interval = -6.613041400909424, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3720703125, Test ACC: 0.6535714285714286\n",
      "162, total loss = 4.765402317047119, reconstruct loss = 0.04476279392838478, cluster loss = 0.048709936439991, calm loss = 1.842310905456543, pilot loss = 5.873005390167236, max interval = -6.615069389343262, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3701171875, Test ACC: 0.6571428571428571\n",
      "163, total loss = 4.742497444152832, reconstruct loss = 0.04959165304899216, cluster loss = 0.04873138666152954, calm loss = 1.8317428827285767, pilot loss = 5.857579708099365, max interval = -6.617403984069824, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.353515625, Test ACC: 0.6607142857142857\n",
      "164, total loss = 4.711599349975586, reconstruct loss = 0.04822078347206116, cluster loss = 0.04692765325307846, calm loss = 1.8212110996246338, pilot loss = 5.842438220977783, max interval = -6.620151042938232, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.36328125, Test ACC: 0.6607142857142857\n",
      "165, total loss = 4.685554504394531, reconstruct loss = 0.04715612530708313, cluster loss = 0.049639150500297546, calm loss = 1.8107188940048218, pilot loss = 5.827499866485596, max interval = -6.623202800750732, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3505859375, Test ACC: 0.6678571428571428\n",
      "166, total loss = 4.657859802246094, reconstruct loss = 0.04881637543439865, cluster loss = 0.04796867445111275, calm loss = 1.8002389669418335, pilot loss = 5.812833309173584, max interval = -6.626650333404541, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3701171875, Test ACC: 0.6714285714285714\n",
      "167, total loss = 4.631587028503418, reconstruct loss = 0.048389874398708344, cluster loss = 0.04993152990937233, calm loss = 1.7897045612335205, pilot loss = 5.798407077789307, max interval = -6.630541801452637, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3818359375, Test ACC: 0.6714285714285714\n",
      "168, total loss = 4.606876373291016, reconstruct loss = 0.05213343724608421, cluster loss = 0.04927540943026543, calm loss = 1.7792003154754639, pilot loss = 5.784176349639893, max interval = -6.634740829467773, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.380859375, Test ACC: 0.675\n",
      "169, total loss = 4.578413963317871, reconstruct loss = 0.0506678931415081, cluster loss = 0.05002869293093681, calm loss = 1.768752098083496, pilot loss = 5.770148277282715, max interval = -6.639242172241211, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3740234375, Test ACC: 0.675\n",
      "170, total loss = 4.5557990074157715, reconstruct loss = 0.053588028997182846, cluster loss = 0.05213169753551483, calm loss = 1.7583911418914795, pilot loss = 5.756231307983398, max interval = -6.643868446350098, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.41796875, Test ACC: 0.6785714285714286\n",
      "171, total loss = 4.525012016296387, reconstruct loss = 0.05047550052404404, cluster loss = 0.05200383439660072, calm loss = 1.7481014728546143, pilot loss = 5.742498874664307, max interval = -6.648730278015137, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3740234375, Test ACC: 0.6785714285714286\n",
      "172, total loss = 4.499282360076904, reconstruct loss = 0.05175931379199028, cluster loss = 0.05247049033641815, calm loss = 1.737863540649414, pilot loss = 5.729087829589844, max interval = -6.654029846191406, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.40625, Test ACC: 0.6821428571428572\n",
      "173, total loss = 4.46877384185791, reconstruct loss = 0.05155809596180916, cluster loss = 0.04957292601466179, calm loss = 1.7276875972747803, pilot loss = 5.715837478637695, max interval = -6.659548282623291, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.373046875, Test ACC: 0.6857142857142857\n",
      "174, total loss = 4.440578460693359, reconstruct loss = 0.05027247592806816, cluster loss = 0.05003829300403595, calm loss = 1.7176294326782227, pilot loss = 5.702712535858154, max interval = -6.665366172790527, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.37890625, Test ACC: 0.6857142857142857\n",
      "175, total loss = 4.418394088745117, reconstruct loss = 0.05454430729150772, cluster loss = 0.050928499549627304, calm loss = 1.7076908349990845, pilot loss = 5.689472675323486, max interval = -6.671149253845215, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.396484375, Test ACC: 0.6928571428571428\n",
      "176, total loss = 4.389164447784424, reconstruct loss = 0.05177175998687744, cluster loss = 0.05169854313135147, calm loss = 1.6977910995483398, pilot loss = 5.67644739151001, max interval = -6.677125453948975, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3916015625, Test ACC: 0.6892857142857143\n",
      "177, total loss = 4.361151695251465, reconstruct loss = 0.05144451931118965, cluster loss = 0.05117698386311531, calm loss = 1.687921166419983, pilot loss = 5.66369104385376, max interval = -6.683438777923584, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.37109375, Test ACC: 0.6892857142857143\n",
      "178, total loss = 4.337198734283447, reconstruct loss = 0.0530218668282032, cluster loss = 0.05276087671518326, calm loss = 1.6780636310577393, pilot loss = 5.651150703430176, max interval = -6.690007209777832, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3916015625, Test ACC: 0.6892857142857143\n",
      "179, total loss = 4.310244560241699, reconstruct loss = 0.054306354373693466, cluster loss = 0.05151616036891937, calm loss = 1.6682837009429932, pilot loss = 5.638760566711426, max interval = -6.69672966003418, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3984375, Test ACC: 0.6928571428571428\n",
      "180, total loss = 4.284586429595947, reconstruct loss = 0.05502571538090706, cluster loss = 0.051811639219522476, calm loss = 1.6585153341293335, pilot loss = 5.626767635345459, max interval = -6.703579425811768, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.380859375, Test ACC: 0.6928571428571428\n",
      "181, total loss = 4.260143280029297, reconstruct loss = 0.056368082761764526, cluster loss = 0.05235525220632553, calm loss = 1.6487820148468018, pilot loss = 5.615057945251465, max interval = -6.710391998291016, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.396484375, Test ACC: 0.6928571428571428\n",
      "182, total loss = 4.234339237213135, reconstruct loss = 0.056841835379600525, cluster loss = 0.05241920053958893, calm loss = 1.6390807628631592, pilot loss = 5.603387355804443, max interval = -6.717325687408447, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.40625, Test ACC: 0.6964285714285714\n",
      "183, total loss = 4.208169937133789, reconstruct loss = 0.057329922914505005, cluster loss = 0.05209412798285484, calm loss = 1.6293922662734985, pilot loss = 5.591927528381348, max interval = -6.724565029144287, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3779296875, Test ACC: 0.7\n",
      "184, total loss = 4.184303283691406, reconstruct loss = 0.058994654566049576, cluster loss = 0.05283864960074425, calm loss = 1.6197561025619507, pilot loss = 5.580694675445557, max interval = -6.7321248054504395, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3828125, Test ACC: 0.7\n",
      "185, total loss = 4.1547441482543945, reconstruct loss = 0.055961307138204575, cluster loss = 0.05226035416126251, calm loss = 1.6103675365447998, pilot loss = 5.56947135925293, max interval = -6.73958158493042, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3671875, Test ACC: 0.7\n",
      "186, total loss = 4.132904529571533, reconstruct loss = 0.05930163711309433, cluster loss = 0.052667152136564255, calm loss = 1.6012557744979858, pilot loss = 5.55831241607666, max interval = -6.747014045715332, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.388671875, Test ACC: 0.6964285714285714\n",
      "187, total loss = 4.107927322387695, reconstruct loss = 0.058669235557317734, cluster loss = 0.05361781269311905, calm loss = 1.592307686805725, pilot loss = 5.5470709800720215, max interval = -6.75414514541626, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.384765625, Test ACC: 0.7\n",
      "188, total loss = 4.083125114440918, reconstruct loss = 0.06089029461145401, cluster loss = 0.051898885518312454, calm loss = 1.5833747386932373, pilot loss = 5.535764217376709, max interval = -6.761219024658203, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3896484375, Test ACC: 0.7\n",
      "189, total loss = 4.053045272827148, reconstruct loss = 0.053697116672992706, cluster loss = 0.05393949896097183, calm loss = 1.5746830701828003, pilot loss = 5.524272441864014, max interval = -6.767836093902588, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3837890625, Test ACC: 0.7\n",
      "190, total loss = 4.028837203979492, reconstruct loss = 0.05391571298241615, cluster loss = 0.05463085323572159, calm loss = 1.5660979747772217, pilot loss = 5.512420654296875, max interval = -6.774363040924072, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.39453125, Test ACC: 0.7\n",
      "191, total loss = 4.006999969482422, reconstruct loss = 0.0575597882270813, cluster loss = 0.054245300590991974, calm loss = 1.5576236248016357, pilot loss = 5.500388145446777, max interval = -6.780757904052734, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3828125, Test ACC: 0.7\n",
      "192, total loss = 3.9810080528259277, reconstruct loss = 0.05824645236134529, cluster loss = 0.052508048713207245, calm loss = 1.549282193183899, pilot loss = 5.488311290740967, max interval = -6.7870588302612305, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.365234375, Test ACC: 0.7\n",
      "193, total loss = 3.96004056930542, reconstruct loss = 0.06009029224514961, cluster loss = 0.05466831102967262, calm loss = 1.5409481525421143, pilot loss = 5.4761786460876465, max interval = -6.793335437774658, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3896484375, Test ACC: 0.7\n",
      "194, total loss = 3.943275213241577, reconstruct loss = 0.06701890379190445, cluster loss = 0.05597295984625816, calm loss = 1.532558798789978, pilot loss = 5.464008808135986, max interval = -6.79951810836792, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.4267578125, Test ACC: 0.6964285714285714\n",
      "195, total loss = 3.911752700805664, reconstruct loss = 0.061411261558532715, cluster loss = 0.05505894124507904, calm loss = 1.5241515636444092, pilot loss = 5.451907634735107, max interval = -6.8057756423950195, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3798828125, Test ACC: 0.6964285714285714\n",
      "196, total loss = 3.8937811851501465, reconstruct loss = 0.06818258762359619, cluster loss = 0.055123984813690186, calm loss = 1.5158684253692627, pilot loss = 5.439768314361572, max interval = -6.811882019042969, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.4013671875, Test ACC: 0.6964285714285714\n",
      "197, total loss = 3.8598244190216064, reconstruct loss = 0.06002593785524368, cluster loss = 0.05401596799492836, calm loss = 1.5077182054519653, pilot loss = 5.427675247192383, max interval = -6.818079471588135, \n",
      "Train ACC: 0.6792452830188679, PTA: 0.3818359375, Test ACC: 0.6964285714285714\n",
      "198, total loss = 3.8375535011291504, reconstruct loss = 0.06196604296565056, cluster loss = 0.05468238517642021, calm loss = 1.4995123147964478, pilot loss = 5.415421485900879, max interval = -6.824233531951904, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.376953125, Test ACC: 0.7\n",
      "199, total loss = 3.8140082359313965, reconstruct loss = 0.06303776055574417, cluster loss = 0.05493852123618126, calm loss = 1.4913606643676758, pilot loss = 5.403203010559082, max interval = -6.830510139465332, \n",
      "Train ACC: 0.6886792452830188, PTA: 0.3974609375, Test ACC: 0.7\n",
      "200, total loss = 3.7933616638183594, reconstruct loss = 0.06620782613754272, cluster loss = 0.05590847134590149, calm loss = 1.483298659324646, pilot loss = 5.391174793243408, max interval = -6.837062835693359, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.404296875, Test ACC: 0.7\n",
      "201, total loss = 3.7694950103759766, reconstruct loss = 0.06610073894262314, cluster loss = 0.05666764825582504, calm loss = 1.4753423929214478, pilot loss = 5.379454612731934, max interval = -6.84382438659668, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3701171875, Test ACC: 0.7\n",
      "202, total loss = 3.7479820251464844, reconstruct loss = 0.06847850233316422, cluster loss = 0.057148367166519165, calm loss = 1.4674856662750244, pilot loss = 5.368168830871582, max interval = -6.851139068603516, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.396484375, Test ACC: 0.7\n",
      "203, total loss = 3.7234435081481934, reconstruct loss = 0.06788010895252228, cluster loss = 0.05743493139743805, calm loss = 1.4596952199935913, pilot loss = 5.357369899749756, max interval = -6.859036445617676, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.408203125, Test ACC: 0.7\n",
      "204, total loss = 3.699326992034912, reconstruct loss = 0.06906203925609589, cluster loss = 0.056282784789800644, calm loss = 1.4519599676132202, pilot loss = 5.346896648406982, max interval = -6.867363452911377, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.40625, Test ACC: 0.7\n",
      "205, total loss = 3.6703710556030273, reconstruct loss = 0.06397467106580734, cluster loss = 0.05639973282814026, calm loss = 1.444357991218567, pilot loss = 5.336659908294678, max interval = -6.87598991394043, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3740234375, Test ACC: 0.7\n",
      "206, total loss = 3.6523585319519043, reconstruct loss = 0.06942073255777359, cluster loss = 0.056838247925043106, calm loss = 1.436849594116211, pilot loss = 5.326622009277344, max interval = -6.8849077224731445, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.384765625, Test ACC: 0.7035714285714286\n",
      "207, total loss = 3.6211631298065186, reconstruct loss = 0.06429819017648697, cluster loss = 0.054394058883190155, calm loss = 1.4294787645339966, pilot loss = 5.316829681396484, max interval = -6.893991470336914, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3544921875, Test ACC: 0.7035714285714286\n",
      "208, total loss = 3.6053805351257324, reconstruct loss = 0.07041104882955551, cluster loss = 0.055974505841732025, calm loss = 1.4222686290740967, pilot loss = 5.307326316833496, max interval = -6.903498649597168, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.380859375, Test ACC: 0.7035714285714286\n",
      "209, total loss = 3.578855037689209, reconstruct loss = 0.06699106097221375, cluster loss = 0.05624198168516159, calm loss = 1.4152189493179321, pilot loss = 5.298085689544678, max interval = -6.9134626388549805, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3818359375, Test ACC: 0.7035714285714286\n",
      "210, total loss = 3.555013656616211, reconstruct loss = 0.06787917017936707, cluster loss = 0.0546858012676239, calm loss = 1.4081732034683228, pilot loss = 5.289124488830566, max interval = -6.923547744750977, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.384765625, Test ACC: 0.7035714285714286\n",
      "211, total loss = 3.544389486312866, reconstruct loss = 0.07833082973957062, cluster loss = 0.05645636469125748, calm loss = 1.401190161705017, pilot loss = 5.280501365661621, max interval = -6.933739185333252, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.416015625, Test ACC: 0.7035714285714286\n",
      "212, total loss = 3.518991708755493, reconstruct loss = 0.0742015391588211, cluster loss = 0.05775299295783043, calm loss = 1.3944528102874756, pilot loss = 5.272035598754883, max interval = -6.9441046714782715, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.396484375, Test ACC: 0.7071428571428572\n",
      "213, total loss = 3.490241050720215, reconstruct loss = 0.06959918141365051, cluster loss = 0.056124866008758545, calm loss = 1.38779616355896, pilot loss = 5.263484954833984, max interval = -6.954401969909668, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4072265625, Test ACC: 0.7071428571428572\n",
      "214, total loss = 3.470118522644043, reconstruct loss = 0.07194875925779343, cluster loss = 0.056105632334947586, calm loss = 1.381279706954956, pilot loss = 5.255011558532715, max interval = -6.964913845062256, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.388671875, Test ACC: 0.7071428571428572\n",
      "215, total loss = 3.450601577758789, reconstruct loss = 0.07230135798454285, cluster loss = 0.05864444375038147, calm loss = 1.3748390674591064, pilot loss = 5.2467041015625, max interval = -6.975707054138184, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4130859375, Test ACC: 0.7071428571428572\n",
      "216, total loss = 3.4346163272857666, reconstruct loss = 0.07781071960926056, cluster loss = 0.05932135134935379, calm loss = 1.368577241897583, pilot loss = 5.238351345062256, max interval = -6.986352443695068, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4111328125, Test ACC: 0.7035714285714286\n",
      "217, total loss = 3.4030842781066895, reconstruct loss = 0.06979259103536606, cluster loss = 0.05800041928887367, calm loss = 1.3622623682022095, pilot loss = 5.230203151702881, max interval = -6.997246742248535, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.41015625, Test ACC: 0.7035714285714286\n",
      "218, total loss = 3.3849897384643555, reconstruct loss = 0.07491147518157959, cluster loss = 0.05698973685503006, calm loss = 1.3559058904647827, pilot loss = 5.222339153289795, max interval = -7.008502006530762, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.41015625, Test ACC: 0.7\n",
      "219, total loss = 3.3575429916381836, reconstruct loss = 0.06853803247213364, cluster loss = 0.05816664174199104, calm loss = 1.3494865894317627, pilot loss = 5.214749336242676, max interval = -7.020127296447754, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4052734375, Test ACC: 0.7035714285714286\n",
      "220, total loss = 3.345977783203125, reconstruct loss = 0.07964985072612762, cluster loss = 0.05754181742668152, calm loss = 1.343165636062622, pilot loss = 5.207311153411865, max interval = -7.031826496124268, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3857421875, Test ACC: 0.7071428571428572\n",
      "221, total loss = 3.314215660095215, reconstruct loss = 0.07064894586801529, cluster loss = 0.056799136102199554, calm loss = 1.3367542028427124, pilot loss = 5.199901580810547, max interval = -7.043388366699219, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.38671875, Test ACC: 0.7071428571428572\n",
      "222, total loss = 3.309014320373535, reconstruct loss = 0.08594042807817459, cluster loss = 0.05816107988357544, calm loss = 1.3303346633911133, pilot loss = 5.1924333572387695, max interval = -7.05462121963501, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3935546875, Test ACC: 0.7035714285714286\n",
      "223, total loss = 3.280055046081543, reconstruct loss = 0.07828375697135925, cluster loss = 0.05834291875362396, calm loss = 1.3240280151367188, pilot loss = 5.185105800628662, max interval = -7.065687656402588, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3837890625, Test ACC: 0.7071428571428572\n",
      "224, total loss = 3.2662906646728516, reconstruct loss = 0.08669573068618774, cluster loss = 0.057475507259368896, calm loss = 1.317708969116211, pilot loss = 5.178095817565918, max interval = -7.076939582824707, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4072265625, Test ACC: 0.7071428571428572\n",
      "225, total loss = 3.2373344898223877, reconstruct loss = 0.07907307893037796, cluster loss = 0.05687429755926132, calm loss = 1.31166410446167, pilot loss = 5.171432971954346, max interval = -7.088255882263184, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3896484375, Test ACC: 0.7107142857142857\n",
      "226, total loss = 3.2248806953430176, reconstruct loss = 0.08816249668598175, cluster loss = 0.05641438812017441, calm loss = 1.30513596534729, pilot loss = 5.164975166320801, max interval = -7.099677085876465, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3701171875, Test ACC: 0.7142857142857143\n",
      "227, total loss = 3.2001616954803467, reconstruct loss = 0.0828246921300888, cluster loss = 0.05824427306652069, calm loss = 1.2983295917510986, pilot loss = 5.158710479736328, max interval = -7.111160755157471, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3955078125, Test ACC: 0.7142857142857143\n",
      "228, total loss = 3.1795568466186523, reconstruct loss = 0.08317545801401138, cluster loss = 0.0580466091632843, calm loss = 1.2916401624679565, pilot loss = 5.152545928955078, max interval = -7.1223063468933105, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4033203125, Test ACC: 0.7142857142857143\n",
      "229, total loss = 3.1613667011260986, reconstruct loss = 0.08491847664117813, cluster loss = 0.05827955901622772, calm loss = 1.2854180335998535, pilot loss = 5.146188259124756, max interval = -7.132997989654541, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.396484375, Test ACC: 0.7142857142857143\n",
      "230, total loss = 3.139707565307617, reconstruct loss = 0.0857616737484932, cluster loss = 0.055901654064655304, calm loss = 1.2793680429458618, pilot loss = 5.139618396759033, max interval = -7.143573760986328, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.38671875, Test ACC: 0.7142857142857143\n",
      "231, total loss = 3.1267499923706055, reconstruct loss = 0.09068344533443451, cluster loss = 0.05811205506324768, calm loss = 1.2733967304229736, pilot loss = 5.132885456085205, max interval = -7.15397834777832, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.40625, Test ACC: 0.7142857142857143\n",
      "232, total loss = 3.110278606414795, reconstruct loss = 0.09597697108983994, cluster loss = 0.05609889701008797, calm loss = 1.2676512002944946, pilot loss = 5.125993728637695, max interval = -7.163997650146484, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.408203125, Test ACC: 0.7142857142857143\n",
      "233, total loss = 3.0759384632110596, reconstruct loss = 0.07998820394277573, cluster loss = 0.05760028213262558, calm loss = 1.261688470840454, pilot loss = 5.118821144104004, max interval = -7.173449993133545, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.390625, Test ACC: 0.7142857142857143\n",
      "234, total loss = 3.065258264541626, reconstruct loss = 0.08872634172439575, cluster loss = 0.05820024758577347, calm loss = 1.2555310726165771, pilot loss = 5.111425876617432, max interval = -7.182542324066162, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4013671875, Test ACC: 0.7178571428571429\n",
      "235, total loss = 3.0487828254699707, reconstruct loss = 0.09260253608226776, cluster loss = 0.057502519339323044, calm loss = 1.24955153465271, pilot loss = 5.103837013244629, max interval = -7.191091537475586, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4033203125, Test ACC: 0.7178571428571429\n",
      "236, total loss = 3.0152535438537598, reconstruct loss = 0.07754063606262207, cluster loss = 0.05869143456220627, calm loss = 1.2436819076538086, pilot loss = 5.096266269683838, max interval = -7.199828147888184, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3974609375, Test ACC: 0.7178571428571429\n",
      "237, total loss = 3.003194808959961, reconstruct loss = 0.08548668771982193, cluster loss = 0.058398425579071045, calm loss = 1.2378833293914795, pilot loss = 5.088803768157959, max interval = -7.208900451660156, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.388671875, Test ACC: 0.7178571428571429\n",
      "238, total loss = 2.979530096054077, reconstruct loss = 0.08163753151893616, cluster loss = 0.05817295238375664, calm loss = 1.2322266101837158, pilot loss = 5.08148193359375, max interval = -7.218201637268066, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.41015625, Test ACC: 0.7178571428571429\n",
      "239, total loss = 2.968933582305908, reconstruct loss = 0.0904812291264534, cluster loss = 0.057997509837150574, calm loss = 1.2268245220184326, pilot loss = 5.0742716789245605, max interval = -7.227562427520752, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3974609375, Test ACC: 0.7178571428571429\n",
      "240, total loss = 2.95426869392395, reconstruct loss = 0.09533422440290451, cluster loss = 0.057779960334300995, calm loss = 1.2213327884674072, pilot loss = 5.067005157470703, max interval = -7.236764907836914, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3916015625, Test ACC: 0.7178571428571429\n",
      "241, total loss = 2.932938814163208, reconstruct loss = 0.09324014186859131, cluster loss = 0.057407863438129425, calm loss = 1.2158699035644531, pilot loss = 5.060214042663574, max interval = -7.246064186096191, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.373046875, Test ACC: 0.7178571428571429\n",
      "242, total loss = 2.9148261547088623, reconstruct loss = 0.09486074000597, cluster loss = 0.0563344769179821, calm loss = 1.2104989290237427, pilot loss = 5.0540900230407715, max interval = -7.256155490875244, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.376953125, Test ACC: 0.7178571428571429\n",
      "243, total loss = 2.8882014751434326, reconstruct loss = 0.08641431480646133, cluster loss = 0.056581608951091766, calm loss = 1.2051477432250977, pilot loss = 5.0485615730285645, max interval = -7.266793251037598, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4111328125, Test ACC: 0.7178571428571429\n",
      "244, total loss = 2.8737311363220215, reconstruct loss = 0.08945757150650024, cluster loss = 0.05762709304690361, calm loss = 1.1996276378631592, pilot loss = 5.043340682983398, max interval = -7.2778191566467285, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4013671875, Test ACC: 0.7178571428571429\n",
      "245, total loss = 2.853316307067871, reconstruct loss = 0.08886700868606567, cluster loss = 0.056346990168094635, calm loss = 1.1940085887908936, pilot loss = 5.0385260581970215, max interval = -7.2892632484436035, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3740234375, Test ACC: 0.7178571428571429\n",
      "246, total loss = 2.8390555381774902, reconstruct loss = 0.09289257228374481, cluster loss = 0.05662933364510536, calm loss = 1.1881343126296997, pilot loss = 5.033977508544922, max interval = -7.300756931304932, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3984375, Test ACC: 0.7178571428571429\n",
      "247, total loss = 2.8245725631713867, reconstruct loss = 0.09618698060512543, cluster loss = 0.057430703192949295, calm loss = 1.1820732355117798, pilot loss = 5.029689788818359, max interval = -7.312371730804443, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4072265625, Test ACC: 0.7214285714285714\n",
      "248, total loss = 2.8031063079833984, reconstruct loss = 0.09459427744150162, cluster loss = 0.05593056604266167, calm loss = 1.176068902015686, pilot loss = 5.025676250457764, max interval = -7.324165344238281, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.376953125, Test ACC: 0.7285714285714285\n",
      "249, total loss = 2.7806825637817383, reconstruct loss = 0.08836520463228226, cluster loss = 0.057614460587501526, calm loss = 1.170440435409546, pilot loss = 5.02159309387207, max interval = -7.335690975189209, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3818359375, Test ACC: 0.7285714285714285\n",
      "250, total loss = 2.7672135829925537, reconstruct loss = 0.09248349070549011, cluster loss = 0.05787402391433716, calm loss = 1.1649551391601562, pilot loss = 5.017381191253662, max interval = -7.34719181060791, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4228515625, Test ACC: 0.7285714285714285\n",
      "251, total loss = 2.7469277381896973, reconstruct loss = 0.09192723780870438, cluster loss = 0.05604393407702446, calm loss = 1.1595404148101807, pilot loss = 5.0130486488342285, max interval = -7.358695983886719, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.361328125, Test ACC: 0.7285714285714285\n",
      "252, total loss = 2.74194598197937, reconstruct loss = 0.10413838922977448, cluster loss = 0.0567251518368721, calm loss = 1.1541751623153687, pilot loss = 5.008574485778809, max interval = -7.37003231048584, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4052734375, Test ACC: 0.7321428571428571\n",
      "253, total loss = 2.722317695617676, reconstruct loss = 0.10140644758939743, cluster loss = 0.05734658241271973, calm loss = 1.1490182876586914, pilot loss = 5.004022598266602, max interval = -7.381046772003174, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4384765625, Test ACC: 0.7321428571428571\n",
      "254, total loss = 2.7059807777404785, reconstruct loss = 0.10399430990219116, cluster loss = 0.055754851549863815, calm loss = 1.1437389850616455, pilot loss = 4.99982213973999, max interval = -7.392126083374023, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4013671875, Test ACC: 0.7321428571428571\n",
      "255, total loss = 2.6730971336364746, reconstruct loss = 0.08786313980817795, cluster loss = 0.05643756687641144, calm loss = 1.1380565166473389, pilot loss = 4.995980739593506, max interval = -7.403287410736084, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3828125, Test ACC: 0.7321428571428571\n",
      "256, total loss = 2.660952568054199, reconstruct loss = 0.09043250977993011, cluster loss = 0.059024788439273834, calm loss = 1.1323086023330688, pilot loss = 4.992345333099365, max interval = -7.414456844329834, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4189453125, Test ACC: 0.7321428571428571\n",
      "257, total loss = 2.6543679237365723, reconstruct loss = 0.10241734236478806, cluster loss = 0.05766354873776436, calm loss = 1.1265424489974976, pilot loss = 4.988927364349365, max interval = -7.425778865814209, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.419921875, Test ACC: 0.7321428571428571\n",
      "258, total loss = 2.6310036182403564, reconstruct loss = 0.0962337851524353, cluster loss = 0.05751049518585205, calm loss = 1.1208162307739258, pilot loss = 4.985865116119385, max interval = -7.437408924102783, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3935546875, Test ACC: 0.7321428571428571\n",
      "259, total loss = 2.6134395599365234, reconstruct loss = 0.09744028747081757, cluster loss = 0.05567771568894386, calm loss = 1.115123987197876, pilot loss = 4.983087539672852, max interval = -7.449366092681885, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.392578125, Test ACC: 0.7357142857142858\n",
      "260, total loss = 2.5942203998565674, reconstruct loss = 0.09480772167444229, cluster loss = 0.05598476901650429, calm loss = 1.1095900535583496, pilot loss = 4.980020999908447, max interval = -7.4610748291015625, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3818359375, Test ACC: 0.7357142857142858\n",
      "261, total loss = 2.5780816078186035, reconstruct loss = 0.09691965579986572, cluster loss = 0.05492835119366646, calm loss = 1.1040809154510498, pilot loss = 4.976617813110352, max interval = -7.472765922546387, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.3828125, Test ACC: 0.7357142857142858\n",
      "262, total loss = 2.581172227859497, reconstruct loss = 0.11454444378614426, cluster loss = 0.05751318112015724, calm loss = 1.0987030267715454, pilot loss = 4.973010540008545, max interval = -7.484246253967285, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.41796875, Test ACC: 0.7357142857142858\n",
      "263, total loss = 2.558743953704834, reconstruct loss = 0.1109929010272026, cluster loss = 0.05570194497704506, calm loss = 1.093196153640747, pilot loss = 4.969618797302246, max interval = -7.495774269104004, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.4072265625, Test ACC: 0.7357142857142858\n",
      "264, total loss = 2.5357155799865723, reconstruct loss = 0.10538093000650406, cluster loss = 0.05525700002908707, calm loss = 1.087702989578247, pilot loss = 4.966543674468994, max interval = -7.507641315460205, \n",
      "Train ACC: 0.6981132075471698, PTA: 0.396484375, Test ACC: 0.7357142857142858\n",
      "265, total loss = 2.524890422821045, reconstruct loss = 0.1087220162153244, cluster loss = 0.058133505284786224, calm loss = 1.0821692943572998, pilot loss = 4.963681697845459, max interval = -7.51985502243042, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.40234375, Test ACC: 0.7357142857142858\n",
      "266, total loss = 2.501375675201416, reconstruct loss = 0.10527677088975906, cluster loss = 0.05487710237503052, calm loss = 1.0767570734024048, pilot loss = 4.961187362670898, max interval = -7.532439708709717, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.41015625, Test ACC: 0.7357142857142858\n",
      "267, total loss = 2.4839162826538086, reconstruct loss = 0.10156583040952682, cluster loss = 0.056877315044403076, calm loss = 1.072058081626892, pilot loss = 4.958834648132324, max interval = -7.5447258949279785, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.388671875, Test ACC: 0.7392857142857143\n",
      "268, total loss = 2.474181652069092, reconstruct loss = 0.10822806507349014, cluster loss = 0.05674233287572861, calm loss = 1.0668518543243408, pilot loss = 4.956340312957764, max interval = -7.556818962097168, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.39453125, Test ACC: 0.7392857142857143\n",
      "269, total loss = 2.4473583698272705, reconstruct loss = 0.09892436116933823, cluster loss = 0.055745456367731094, calm loss = 1.061197280883789, pilot loss = 4.954209327697754, max interval = -7.569161891937256, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.361328125, Test ACC: 0.7357142857142858\n",
      "270, total loss = 2.43208646774292, reconstruct loss = 0.09955514222383499, cluster loss = 0.055868521332740784, calm loss = 1.0558631420135498, pilot loss = 4.952361583709717, max interval = -7.581658363342285, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.388671875, Test ACC: 0.7357142857142858\n",
      "271, total loss = 2.4338130950927734, reconstruct loss = 0.11670748144388199, cluster loss = 0.05595948174595833, calm loss = 1.0506112575531006, pilot loss = 4.951199531555176, max interval = -7.5945234298706055, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4013671875, Test ACC: 0.7357142857142858\n",
      "272, total loss = 2.411945343017578, reconstruct loss = 0.11064860969781876, cluster loss = 0.05492192506790161, calm loss = 1.045374870300293, pilot loss = 4.951111793518066, max interval = -7.607882976531982, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.384765625, Test ACC: 0.7357142857142858\n",
      "273, total loss = 2.3905181884765625, reconstruct loss = 0.10351762920618057, cluster loss = 0.05538979917764664, calm loss = 1.0402191877365112, pilot loss = 4.950899600982666, max interval = -7.6211700439453125, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3828125, Test ACC: 0.7357142857142858\n",
      "274, total loss = 2.374722719192505, reconstruct loss = 0.10239516198635101, cluster loss = 0.055368829518556595, calm loss = 1.035119652748108, pilot loss = 4.950144290924072, max interval = -7.633600234985352, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.408203125, Test ACC: 0.7392857142857143\n",
      "275, total loss = 2.373444080352783, reconstruct loss = 0.11547579616308212, cluster loss = 0.05522673577070236, calm loss = 1.0302479267120361, pilot loss = 4.949259281158447, max interval = -7.645549297332764, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4072265625, Test ACC: 0.7392857142857143\n",
      "276, total loss = 2.35380220413208, reconstruct loss = 0.10953366756439209, cluster loss = 0.056054018437862396, calm loss = 1.024877667427063, pilot loss = 4.948741912841797, max interval = -7.657753944396973, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.40234375, Test ACC: 0.7392857142857143\n",
      "277, total loss = 2.334177017211914, reconstruct loss = 0.10389978438615799, cluster loss = 0.05627104267477989, calm loss = 1.0194637775421143, pilot loss = 4.948541164398193, max interval = -7.669893741607666, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4111328125, Test ACC: 0.7392857142857143\n",
      "278, total loss = 2.3256163597106934, reconstruct loss = 0.11065743118524551, cluster loss = 0.05520759895443916, calm loss = 1.0138860940933228, pilot loss = 4.948855400085449, max interval = -7.682602405548096, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.38671875, Test ACC: 0.7392857142857143\n",
      "279, total loss = 2.3117663860321045, reconstruct loss = 0.10944941639900208, cluster loss = 0.05683565512299538, calm loss = 1.008396029472351, pilot loss = 4.948732852935791, max interval = -7.694833755493164, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4072265625, Test ACC: 0.7392857142857143\n",
      "280, total loss = 2.299744129180908, reconstruct loss = 0.11299531906843185, cluster loss = 0.055686622858047485, calm loss = 1.003092885017395, pilot loss = 4.948452949523926, max interval = -7.707321643829346, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.390625, Test ACC: 0.7392857142857143\n",
      "281, total loss = 2.267765998840332, reconstruct loss = 0.09565676748752594, cluster loss = 0.055313460528850555, calm loss = 0.9980217218399048, pilot loss = 4.947900772094727, max interval = -7.719533920288086, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.376953125, Test ACC: 0.7392857142857143\n",
      "282, total loss = 2.272599697113037, reconstruct loss = 0.11427473276853561, cluster loss = 0.05572915077209473, calm loss = 0.9931185841560364, pilot loss = 4.947556495666504, max interval = -7.732188701629639, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3974609375, Test ACC: 0.7392857142857143\n",
      "283, total loss = 2.2547590732574463, reconstruct loss = 0.11008956283330917, cluster loss = 0.056061215698719025, calm loss = 0.988369345664978, pilot loss = 4.947681427001953, max interval = -7.745429515838623, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.431640625, Test ACC: 0.7428571428571429\n",
      "284, total loss = 2.232895612716675, reconstruct loss = 0.1043144091963768, cluster loss = 0.053773194551467896, calm loss = 0.9839180707931519, pilot loss = 4.947808742523193, max interval = -7.758833408355713, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3818359375, Test ACC: 0.7428571428571429\n",
      "285, total loss = 2.2335917949676514, reconstruct loss = 0.11689313501119614, cluster loss = 0.055650316178798676, calm loss = 0.9796863794326782, pilot loss = 4.9479756355285645, max interval = -7.772549152374268, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.41796875, Test ACC: 0.7464285714285714\n",
      "286, total loss = 2.2137796878814697, reconstruct loss = 0.11130251735448837, cluster loss = 0.05506131052970886, calm loss = 0.9754959344863892, pilot loss = 4.948114395141602, max interval = -7.786103248596191, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4033203125, Test ACC: 0.7464285714285714\n",
      "287, total loss = 2.204411506652832, reconstruct loss = 0.11548169702291489, cluster loss = 0.055022913962602615, calm loss = 0.971407413482666, pilot loss = 4.948633670806885, max interval = -7.800169467926025, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.37109375, Test ACC: 0.75\n",
      "288, total loss = 2.188713550567627, reconstruct loss = 0.11272682994604111, cluster loss = 0.055726341903209686, calm loss = 0.9674860239028931, pilot loss = 4.949166774749756, max interval = -7.814692497253418, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4189453125, Test ACC: 0.7535714285714286\n",
      "289, total loss = 2.1797726154327393, reconstruct loss = 0.12041112035512924, cluster loss = 0.05263369530439377, calm loss = 0.963841438293457, pilot loss = 4.949526309967041, max interval = -7.829200267791748, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.380859375, Test ACC: 0.7535714285714286\n",
      "290, total loss = 2.158698558807373, reconstruct loss = 0.11008929461240768, cluster loss = 0.055426012724637985, calm loss = 0.9600712060928345, pilot loss = 4.9503302574157715, max interval = -7.844182014465332, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.4072265625, Test ACC: 0.7535714285714286\n",
      "291, total loss = 2.1388814449310303, reconstruct loss = 0.10578756034374237, cluster loss = 0.05391795188188553, calm loss = 0.9558025598526001, pilot loss = 4.951409339904785, max interval = -7.859505653381348, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3798828125, Test ACC: 0.7535714285714286\n",
      "292, total loss = 2.1300485134124756, reconstruct loss = 0.11168830096721649, cluster loss = 0.053300198167562485, calm loss = 0.9515424966812134, pilot loss = 4.953003883361816, max interval = -7.875732421875, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3896484375, Test ACC: 0.7571428571428571\n",
      "293, total loss = 2.1155099868774414, reconstruct loss = 0.10776717215776443, cluster loss = 0.05631772428750992, calm loss = 0.9477499127388, pilot loss = 4.9546332359313965, max interval = -7.8919901847839355, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.3994140625, Test ACC: 0.7571428571428571\n",
      "294, total loss = 2.1118597984313965, reconstruct loss = 0.11814653873443604, cluster loss = 0.05573492869734764, calm loss = 0.9442903399467468, pilot loss = 4.955499172210693, max interval = -7.907364845275879, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.41015625, Test ACC: 0.7571428571428571\n",
      "295, total loss = 2.0889997482299805, reconstruct loss = 0.10961534082889557, cluster loss = 0.05451808124780655, calm loss = 0.9408073425292969, pilot loss = 4.9563517570495605, max interval = -7.922208309173584, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.416015625, Test ACC: 0.7571428571428571\n",
      "296, total loss = 2.085050582885742, reconstruct loss = 0.11859654635190964, cluster loss = 0.05445295572280884, calm loss = 0.9375234842300415, pilot loss = 4.957326412200928, max interval = -7.937157154083252, \n",
      "Train ACC: 0.7075471698113207, PTA: 0.40234375, Test ACC: 0.7571428571428571\n",
      "297, total loss = 2.072906017303467, reconstruct loss = 0.12019138038158417, cluster loss = 0.05372245982289314, calm loss = 0.9340711832046509, pilot loss = 4.958376884460449, max interval = -7.952180862426758, \n",
      "Train ACC: 0.7169811320754716, PTA: 0.3837890625, Test ACC: 0.7571428571428571\n",
      "298, total loss = 2.05118989944458, reconstruct loss = 0.11139195412397385, cluster loss = 0.053978435695171356, calm loss = 0.9307670593261719, pilot loss = 4.958728790283203, max interval = -7.966651439666748, \n",
      "Train ACC: 0.7169811320754716, PTA: 0.412109375, Test ACC: 0.7571428571428571\n",
      "299, total loss = 2.0432074069976807, reconstruct loss = 0.11658468097448349, cluster loss = 0.05421577766537666, calm loss = 0.9274538159370422, pilot loss = 4.95862340927124, max interval = -7.980798721313477, \n",
      "Train ACC: 0.7169811320754716, PTA: 0.4091796875, Test ACC: 0.7571428571428571\n",
      "300, total loss = 2.029723882675171, reconstruct loss = 0.11691141873598099, cluster loss = 0.0537448450922966, calm loss = 0.9241535067558289, pilot loss = 4.958942413330078, max interval = -7.995464324951172, \n",
      "Train ACC: 0.7169811320754716, PTA: 0.3798828125, Test ACC: 0.7607142857142857\n",
      "301, total loss = 2.021791458129883, reconstruct loss = 0.12173116952180862, cluster loss = 0.054571546614170074, calm loss = 0.9209291338920593, pilot loss = 4.959437370300293, max interval = -8.010833740234375, \n",
      "Train ACC: 0.7169811320754716, PTA: 0.4033203125, Test ACC: 0.7642857142857142\n",
      "302, total loss = 2.0052013397216797, reconstruct loss = 0.11850116401910782, cluster loss = 0.054299887269735336, calm loss = 0.9180229902267456, pilot loss = 4.9602484703063965, max interval = -8.026409149169922, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.419921875, Test ACC: 0.7642857142857142\n",
      "303, total loss = 1.9864333868026733, reconstruct loss = 0.11346875131130219, cluster loss = 0.05382293462753296, calm loss = 0.9150762557983398, pilot loss = 4.961187362670898, max interval = -8.042351722717285, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.384765625, Test ACC: 0.7642857142857142\n",
      "304, total loss = 1.9727219343185425, reconstruct loss = 0.11454397439956665, cluster loss = 0.05242506042122841, calm loss = 0.9123589396476746, pilot loss = 4.9624714851379395, max interval = -8.05930233001709, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.3798828125, Test ACC: 0.7678571428571429\n",
      "305, total loss = 1.96978759765625, reconstruct loss = 0.12457381188869476, cluster loss = 0.052874721586704254, calm loss = 0.9099327325820923, pilot loss = 4.964096546173096, max interval = -8.077193260192871, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.4013671875, Test ACC: 0.7678571428571429\n",
      "306, total loss = 1.9521586894989014, reconstruct loss = 0.11932635307312012, cluster loss = 0.054011985659599304, calm loss = 0.9070503115653992, pilot loss = 4.966655254364014, max interval = -8.095915794372559, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.4013671875, Test ACC: 0.7678571428571429\n",
      "307, total loss = 1.9473168849945068, reconstruct loss = 0.12921632826328278, cluster loss = 0.05308213457465172, calm loss = 0.9041198492050171, pilot loss = 4.969973087310791, max interval = -8.116059303283691, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.40625, Test ACC: 0.7678571428571429\n",
      "308, total loss = 1.9118757247924805, reconstruct loss = 0.10716193169355392, cluster loss = 0.05352018401026726, calm loss = 0.9012178182601929, pilot loss = 4.973577499389648, max interval = -8.136686325073242, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.39453125, Test ACC: 0.7678571428571429\n",
      "309, total loss = 1.910907506942749, reconstruct loss = 0.11950648576021194, cluster loss = 0.053763531148433685, calm loss = 0.8987545967102051, pilot loss = 4.976816654205322, max interval = -8.157034873962402, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.412109375, Test ACC: 0.7678571428571429\n",
      "310, total loss = 1.896102786064148, reconstruct loss = 0.11921882629394531, cluster loss = 0.05298382788896561, calm loss = 0.8960806131362915, pilot loss = 4.979762077331543, max interval = -8.176920890808105, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.404296875, Test ACC: 0.7678571428571429\n",
      "311, total loss = 1.8856955766677856, reconstruct loss = 0.12340886145830154, cluster loss = 0.0521642230451107, calm loss = 0.8932112455368042, pilot loss = 4.982950687408447, max interval = -8.19693374633789, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.40625, Test ACC: 0.7678571428571429\n",
      "312, total loss = 1.871706485748291, reconstruct loss = 0.12085863202810287, cluster loss = 0.05414991453289986, calm loss = 0.8905288577079773, pilot loss = 4.986209869384766, max interval = -8.21681022644043, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.396484375, Test ACC: 0.7678571428571429\n",
      "313, total loss = 1.8496670722961426, reconstruct loss = 0.11329308152198792, cluster loss = 0.05323753133416176, calm loss = 0.8880524635314941, pilot loss = 4.9887824058532715, max interval = -8.23619556427002, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.3818359375, Test ACC: 0.7678571428571429\n",
      "314, total loss = 1.8546334505081177, reconstruct loss = 0.13160865008831024, cluster loss = 0.05357466638088226, calm loss = 0.8857030868530273, pilot loss = 4.99049186706543, max interval = -8.254709243774414, \n",
      "Train ACC: 0.7264150943396226, PTA: 0.396484375, Test ACC: 0.7678571428571429\n",
      "315, total loss = 1.8204002380371094, reconstruct loss = 0.11117241531610489, cluster loss = 0.05292634665966034, calm loss = 0.8835932016372681, pilot loss = 4.992817401885986, max interval = -8.273675918579102, \n",
      "Train ACC: 0.7358490566037735, PTA: 0.40625, Test ACC: 0.7678571428571429\n",
      "316, total loss = 1.807586908340454, reconstruct loss = 0.11101258546113968, cluster loss = 0.05374862626194954, calm loss = 0.8809398412704468, pilot loss = 4.995868682861328, max interval = -8.293371200561523, \n",
      "Train ACC: 0.7358490566037735, PTA: 0.388671875, Test ACC: 0.7714285714285715\n",
      "317, total loss = 1.7887589931488037, reconstruct loss = 0.10815980285406113, cluster loss = 0.051531072705984116, calm loss = 0.877724289894104, pilot loss = 4.999117851257324, max interval = -8.312949180603027, \n",
      "Train ACC: 0.7452830188679245, PTA: 0.3916015625, Test ACC: 0.7714285714285715\n",
      "318, total loss = 1.79057776927948, reconstruct loss = 0.12225500494241714, cluster loss = 0.052561335265636444, calm loss = 0.8752323985099792, pilot loss = 5.001752853393555, max interval = -8.332038879394531, \n",
      "Train ACC: 0.7452830188679245, PTA: 0.4052734375, Test ACC: 0.7714285714285715\n",
      "319, total loss = 1.7688336372375488, reconstruct loss = 0.11390992999076843, cluster loss = 0.052496302872896194, calm loss = 0.8729562759399414, pilot loss = 5.0043110847473145, max interval = -8.351367950439453, \n",
      "Train ACC: 0.7452830188679245, PTA: 0.3818359375, Test ACC: 0.7714285714285715\n",
      "320, total loss = 1.7673455476760864, reconstruct loss = 0.12497862428426743, cluster loss = 0.05328299105167389, calm loss = 0.8704317212104797, pilot loss = 5.0079569816589355, max interval = -8.371909141540527, \n",
      "Train ACC: 0.7452830188679245, PTA: 0.3974609375, Test ACC: 0.7714285714285715\n",
      "321, total loss = 1.7556378841400146, reconstruct loss = 0.12680314481258392, cluster loss = 0.05305815860629082, calm loss = 0.8675409555435181, pilot loss = 5.012437343597412, max interval = -8.393068313598633, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.416015625, Test ACC: 0.775\n",
      "322, total loss = 1.7311017513275146, reconstruct loss = 0.11591339111328125, cluster loss = 0.05265319347381592, calm loss = 0.8649219274520874, pilot loss = 5.016716957092285, max interval = -8.414236068725586, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.39453125, Test ACC: 0.775\n",
      "323, total loss = 1.7325587272644043, reconstruct loss = 0.1306709498167038, cluster loss = 0.052690014243125916, calm loss = 0.8624728918075562, pilot loss = 5.020164489746094, max interval = -8.434595108032227, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4072265625, Test ACC: 0.775\n",
      "324, total loss = 1.7159569263458252, reconstruct loss = 0.12834219634532928, cluster loss = 0.05184313654899597, calm loss = 0.8597000241279602, pilot loss = 5.022704601287842, max interval = -8.45332145690918, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4013671875, Test ACC: 0.775\n",
      "325, total loss = 1.6908401250839233, reconstruct loss = 0.11595401167869568, cluster loss = 0.05222863331437111, calm loss = 0.8568986654281616, pilot loss = 5.025882244110107, max interval = -8.47247314453125, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.375, Test ACC: 0.7714285714285715\n",
      "326, total loss = 1.6818211078643799, reconstruct loss = 0.1198398619890213, cluster loss = 0.052564334124326706, calm loss = 0.8540703058242798, pilot loss = 5.02972412109375, max interval = -8.492715835571289, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.404296875, Test ACC: 0.7714285714285715\n",
      "327, total loss = 1.6661372184753418, reconstruct loss = 0.11839467287063599, cluster loss = 0.05159502476453781, calm loss = 0.8508952260017395, pilot loss = 5.033641338348389, max interval = -8.512612342834473, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.3818359375, Test ACC: 0.7714285714285715\n",
      "328, total loss = 1.6616363525390625, reconstruct loss = 0.1274067461490631, cluster loss = 0.051078468561172485, calm loss = 0.8479583859443665, pilot loss = 5.037965774536133, max interval = -8.533041000366211, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.3916015625, Test ACC: 0.7714285714285715\n",
      "329, total loss = 1.633807897567749, reconstruct loss = 0.11278650164604187, cluster loss = 0.05068638548254967, calm loss = 0.8454138040542603, pilot loss = 5.041957855224609, max interval = -8.553297996520996, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.3642578125, Test ACC: 0.7714285714285715\n",
      "330, total loss = 1.6335089206695557, reconstruct loss = 0.12461331486701965, cluster loss = 0.052071940153837204, calm loss = 0.8424299955368042, pilot loss = 5.045990943908691, max interval = -8.573979377746582, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4072265625, Test ACC: 0.7714285714285715\n",
      "331, total loss = 1.628410816192627, reconstruct loss = 0.13332591950893402, cluster loss = 0.05141494423151016, calm loss = 0.8396208882331848, pilot loss = 5.050090789794922, max interval = -8.594493865966797, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4169921875, Test ACC: 0.7714285714285715\n",
      "332, total loss = 1.615943431854248, reconstruct loss = 0.1331237107515335, cluster loss = 0.052212491631507874, calm loss = 0.8371402025222778, pilot loss = 5.054401397705078, max interval = -8.615649223327637, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4208984375, Test ACC: 0.7714285714285715\n",
      "333, total loss = 1.5897774696350098, reconstruct loss = 0.12082922458648682, cluster loss = 0.051295630633831024, calm loss = 0.8346673250198364, pilot loss = 5.059357166290283, max interval = -8.63758373260498, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.3798828125, Test ACC: 0.775\n",
      "334, total loss = 1.5837831497192383, reconstruct loss = 0.1282818466424942, cluster loss = 0.05088963359594345, calm loss = 0.8321233987808228, pilot loss = 5.064606189727783, max interval = -8.659958839416504, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.423828125, Test ACC: 0.775\n",
      "335, total loss = 1.56503164768219, reconstruct loss = 0.12265759706497192, cluster loss = 0.05074365437030792, calm loss = 0.8294554948806763, pilot loss = 5.070349216461182, max interval = -8.682777404785156, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.39453125, Test ACC: 0.775\n",
      "336, total loss = 1.5466117858886719, reconstruct loss = 0.11616119742393494, cluster loss = 0.05147424712777138, calm loss = 0.8271465301513672, pilot loss = 5.075597286224365, max interval = -8.704935073852539, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4150390625, Test ACC: 0.775\n",
      "337, total loss = 1.5418862104415894, reconstruct loss = 0.12515348196029663, cluster loss = 0.05135709047317505, calm loss = 0.8243293762207031, pilot loss = 5.080132961273193, max interval = -8.726699829101562, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.404296875, Test ACC: 0.7785714285714286\n",
      "338, total loss = 1.5244444608688354, reconstruct loss = 0.12201091647148132, cluster loss = 0.05185803398489952, calm loss = 0.8212810754776001, pilot loss = 5.083591461181641, max interval = -8.748311042785645, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.4052734375, Test ACC: 0.7785714285714286\n",
      "339, total loss = 1.5055116415023804, reconstruct loss = 0.11861099302768707, cluster loss = 0.050609033554792404, calm loss = 0.8190043568611145, pilot loss = 5.086038112640381, max interval = -8.768840789794922, \n",
      "Train ACC: 0.7547169811320755, PTA: 0.3994140625, Test ACC: 0.7785714285714286\n",
      "340, total loss = 1.498428463935852, reconstruct loss = 0.1258663386106491, cluster loss = 0.05056457221508026, calm loss = 0.8167621493339539, pilot loss = 5.088939189910889, max interval = -8.790082931518555, \n",
      "Train ACC: 0.7641509433962265, PTA: 0.375, Test ACC: 0.7785714285714286\n",
      "341, total loss = 1.4786592721939087, reconstruct loss = 0.11873699724674225, cluster loss = 0.05192834511399269, calm loss = 0.8148094415664673, pilot loss = 5.093054294586182, max interval = -8.81305980682373, \n",
      "Train ACC: 0.7641509433962265, PTA: 0.3994140625, Test ACC: 0.7785714285714286\n",
      "342, total loss = 1.4620298147201538, reconstruct loss = 0.11801919341087341, cluster loss = 0.05092942714691162, calm loss = 0.8120632171630859, pilot loss = 5.097861289978027, max interval = -8.837190628051758, \n",
      "Train ACC: 0.7641509433962265, PTA: 0.396484375, Test ACC: 0.7785714285714286\n",
      "343, total loss = 1.4490233659744263, reconstruct loss = 0.11986258625984192, cluster loss = 0.05068720877170563, calm loss = 0.809877872467041, pilot loss = 5.10279655456543, max interval = -8.861869812011719, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.37890625, Test ACC: 0.7785714285714286\n",
      "344, total loss = 1.4355400800704956, reconstruct loss = 0.1203569695353508, cluster loss = 0.05127714201807976, calm loss = 0.8077036738395691, pilot loss = 5.107504844665527, max interval = -8.88618278503418, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3759765625, Test ACC: 0.7785714285714286\n",
      "345, total loss = 1.4226964712142944, reconstruct loss = 0.12020380049943924, cluster loss = 0.05200466886162758, calm loss = 0.8058603405952454, pilot loss = 5.111319065093994, max interval = -8.908049583435059, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.404296875, Test ACC: 0.7821428571428571\n",
      "346, total loss = 1.421933889389038, reconstruct loss = 0.135627880692482, cluster loss = 0.05102229118347168, calm loss = 0.8036037683486938, pilot loss = 5.113852500915527, max interval = -8.930048942565918, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.4140625, Test ACC: 0.7857142857142857\n",
      "347, total loss = 1.39751398563385, reconstruct loss = 0.12573443353176117, cluster loss = 0.051933206617832184, calm loss = 0.8010503649711609, pilot loss = 5.116507530212402, max interval = -8.952131271362305, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3955078125, Test ACC: 0.7857142857142857\n",
      "348, total loss = 1.3870974779129028, reconstruct loss = 0.13253867626190186, cluster loss = 0.050132669508457184, calm loss = 0.7984892129898071, pilot loss = 5.12005615234375, max interval = -8.975455284118652, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.41015625, Test ACC: 0.7857142857142857\n",
      "349, total loss = 1.3614968061447144, reconstruct loss = 0.12080942094326019, cluster loss = 0.051079630851745605, calm loss = 0.796181857585907, pilot loss = 5.123909950256348, max interval = -8.998719215393066, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3740234375, Test ACC: 0.7857142857142857\n",
      "350, total loss = 1.3497588634490967, reconstruct loss = 0.12531419098377228, cluster loss = 0.04899920895695686, calm loss = 0.7939809560775757, pilot loss = 5.127717018127441, max interval = -9.021133422851562, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.4189453125, Test ACC: 0.7857142857142857\n",
      "351, total loss = 1.3453611135482788, reconstruct loss = 0.1333673894405365, cluster loss = 0.05004351586103439, calm loss = 0.7922143936157227, pilot loss = 5.132046222686768, max interval = -9.043960571289062, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3994140625, Test ACC: 0.7857142857142857\n",
      "352, total loss = 1.3377810716629028, reconstruct loss = 0.13860033452510834, cluster loss = 0.050760187208652496, calm loss = 0.7896949648857117, pilot loss = 5.137720584869385, max interval = -9.067683219909668, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.37890625, Test ACC: 0.7857142857142857\n",
      "353, total loss = 1.3139708042144775, reconstruct loss = 0.12877538800239563, cluster loss = 0.0501810759305954, calm loss = 0.787368893623352, pilot loss = 5.1434326171875, max interval = -9.091561317443848, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.396484375, Test ACC: 0.7857142857142857\n",
      "354, total loss = 1.3072417974472046, reconstruct loss = 0.13395218551158905, cluster loss = 0.05128414183855057, calm loss = 0.785568118095398, pilot loss = 5.148920059204102, max interval = -9.115302085876465, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3984375, Test ACC: 0.7857142857142857\n",
      "355, total loss = 1.2919352054595947, reconstruct loss = 0.13226911425590515, cluster loss = 0.050927676260471344, calm loss = 0.7839005589485168, pilot loss = 5.154310703277588, max interval = -9.139464378356934, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.392578125, Test ACC: 0.7857142857142857\n",
      "356, total loss = 1.2638686895370483, reconstruct loss = 0.11837020516395569, cluster loss = 0.05012468993663788, calm loss = 0.781742513179779, pilot loss = 5.16008186340332, max interval = -9.163609504699707, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.4013671875, Test ACC: 0.7857142857142857\n",
      "357, total loss = 1.2566112279891968, reconstruct loss = 0.12539955973625183, cluster loss = 0.048908401280641556, calm loss = 0.7799713015556335, pilot loss = 5.1651530265808105, max interval = -9.186887741088867, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.416015625, Test ACC: 0.7857142857142857\n",
      "358, total loss = 1.236140489578247, reconstruct loss = 0.11827778816223145, cluster loss = 0.04910191148519516, calm loss = 0.778003990650177, pilot loss = 5.169754505157471, max interval = -9.209891319274902, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.37109375, Test ACC: 0.7857142857142857\n",
      "359, total loss = 1.2306643724441528, reconstruct loss = 0.12732815742492676, cluster loss = 0.04855993017554283, calm loss = 0.7760283946990967, pilot loss = 5.17482328414917, max interval = -9.234180450439453, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.392578125, Test ACC: 0.7821428571428571\n",
      "360, total loss = 1.2246671915054321, reconstruct loss = 0.13469889760017395, cluster loss = 0.04966656118631363, calm loss = 0.7738739252090454, pilot loss = 5.180550575256348, max interval = -9.259856224060059, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.4140625, Test ACC: 0.7821428571428571\n",
      "361, total loss = 1.1939997673034668, reconstruct loss = 0.11814052611589432, cluster loss = 0.050069235265254974, calm loss = 0.772135853767395, pilot loss = 5.18629264831543, max interval = -9.286201477050781, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.396484375, Test ACC: 0.7821428571428571\n",
      "362, total loss = 1.1868795156478882, reconstruct loss = 0.1255534589290619, cluster loss = 0.0496891625225544, calm loss = 0.7709656953811646, pilot loss = 5.191789627075195, max interval = -9.312496185302734, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.40625, Test ACC: 0.7785714285714286\n",
      "363, total loss = 1.1654160022735596, reconstruct loss = 0.11794598400592804, cluster loss = 0.05088990554213524, calm loss = 0.7690064907073975, pilot loss = 5.197122097015381, max interval = -9.338720321655273, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3984375, Test ACC: 0.7785714285714286\n",
      "364, total loss = 1.1571404933929443, reconstruct loss = 0.12662191689014435, cluster loss = 0.048787955194711685, calm loss = 0.7672099471092224, pilot loss = 5.203158378601074, max interval = -9.365885734558105, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3916015625, Test ACC: 0.7785714285714286\n",
      "365, total loss = 1.1517325639724731, reconstruct loss = 0.13392356038093567, cluster loss = 0.05097565799951553, calm loss = 0.7657656669616699, pilot loss = 5.209217071533203, max interval = -9.393656730651855, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.423828125, Test ACC: 0.7785714285714286\n",
      "366, total loss = 1.1420131921768188, reconstruct loss = 0.1415514200925827, cluster loss = 0.04951770231127739, calm loss = 0.7644473910331726, pilot loss = 5.216070175170898, max interval = -9.424160957336426, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.40234375, Test ACC: 0.7785714285714286\n",
      "367, total loss = 1.113939881324768, reconstruct loss = 0.13016314804553986, cluster loss = 0.049417220056056976, calm loss = 0.763058066368103, pilot loss = 5.222365856170654, max interval = -9.454761505126953, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.4287109375, Test ACC: 0.7785714285714286\n",
      "368, total loss = 1.094398856163025, reconstruct loss = 0.12686170637607574, cluster loss = 0.05002965033054352, calm loss = 0.7620011568069458, pilot loss = 5.229043006896973, max interval = -9.486764907836914, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.4013671875, Test ACC: 0.7785714285714286\n",
      "369, total loss = 1.082821249961853, reconstruct loss = 0.12506143748760223, cluster loss = 0.047980185598134995, calm loss = 0.7638586163520813, pilot loss = 5.23667049407959, max interval = -9.511256217956543, \n",
      "Train ACC: 0.7735849056603774, PTA: 0.3935546875, Test ACC: 0.775\n",
      "370, total loss = 1.0879366397857666, reconstruct loss = 0.13772791624069214, cluster loss = 0.04989789426326752, calm loss = 0.7652846574783325, pilot loss = 5.244686603546143, max interval = -9.53817367553711, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.4228515625, Test ACC: 0.775\n",
      "371, total loss = 1.0666383504867554, reconstruct loss = 0.1289704293012619, cluster loss = 0.049822017550468445, calm loss = 0.7652336359024048, pilot loss = 5.251925468444824, max interval = -9.566152572631836, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.388671875, Test ACC: 0.775\n",
      "372, total loss = 1.0408164262771606, reconstruct loss = 0.11853110045194626, cluster loss = 0.04970385879278183, calm loss = 0.7631481885910034, pilot loss = 5.259369850158691, max interval = -9.595518112182617, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.3974609375, Test ACC: 0.775\n",
      "373, total loss = 1.0384278297424316, reconstruct loss = 0.13407747447490692, cluster loss = 0.04898121580481529, calm loss = 0.75970858335495, pilot loss = 5.267613887786865, max interval = -9.626874923706055, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.431640625, Test ACC: 0.775\n",
      "374, total loss = 1.014512300491333, reconstruct loss = 0.12847493588924408, cluster loss = 0.04837959632277489, calm loss = 0.7561938762664795, pilot loss = 5.27602481842041, max interval = -9.659077644348145, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.3916015625, Test ACC: 0.775\n",
      "375, total loss = 1.0008333921432495, reconstruct loss = 0.12709708511829376, cluster loss = 0.04900091513991356, calm loss = 0.7541400194168091, pilot loss = 5.284671783447266, max interval = -9.68686294555664, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.416015625, Test ACC: 0.775\n",
      "376, total loss = 0.9932389259338379, reconstruct loss = 0.1313006728887558, cluster loss = 0.04827474057674408, calm loss = 0.752852737903595, pilot loss = 5.293529033660889, max interval = -9.71340274810791, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.416015625, Test ACC: 0.775\n",
      "377, total loss = 0.9775103330612183, reconstruct loss = 0.12628252804279327, cluster loss = 0.049294665455818176, calm loss = 0.7514445185661316, pilot loss = 5.302872180938721, max interval = -9.741403579711914, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.3994140625, Test ACC: 0.7785714285714286\n",
      "378, total loss = 0.9738545417785645, reconstruct loss = 0.13483959436416626, cluster loss = 0.04958638921380043, calm loss = 0.7498250603675842, pilot loss = 5.311734199523926, max interval = -9.769523620605469, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.421875, Test ACC: 0.7785714285714286\n",
      "379, total loss = 0.9428689479827881, reconstruct loss = 0.11671072989702225, cluster loss = 0.04950101673603058, calm loss = 0.7485406994819641, pilot loss = 5.319798469543457, max interval = -9.797364234924316, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.4150390625, Test ACC: 0.7785714285714286\n",
      "380, total loss = 0.951391339302063, reconstruct loss = 0.13968904316425323, cluster loss = 0.04856361821293831, calm loss = 0.7472817301750183, pilot loss = 5.327473163604736, max interval = -9.825752258300781, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.4052734375, Test ACC: 0.7785714285714286\n",
      "381, total loss = 0.9234566688537598, reconstruct loss = 0.12551644444465637, cluster loss = 0.04927458614110947, calm loss = 0.7459787130355835, pilot loss = 5.335238456726074, max interval = -9.855572700500488, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.404296875, Test ACC: 0.7785714285714286\n",
      "382, total loss = 0.9142968654632568, reconstruct loss = 0.13134406507015228, cluster loss = 0.04896501451730728, calm loss = 0.7441946268081665, pilot loss = 5.343865871429443, max interval = -9.886231422424316, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.419921875, Test ACC: 0.7785714285714286\n",
      "383, total loss = 0.8969923257827759, reconstruct loss = 0.1298576295375824, cluster loss = 0.04832477867603302, calm loss = 0.7422710657119751, pilot loss = 5.352811813354492, max interval = -9.917860984802246, \n",
      "Train ACC: 0.7830188679245284, PTA: 0.41015625, Test ACC: 0.7785714285714286\n",
      "384, total loss = 0.8829615116119385, reconstruct loss = 0.13223110139369965, cluster loss = 0.04732733592391014, calm loss = 0.7401559948921204, pilot loss = 5.362526893615723, max interval = -9.950643539428711, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.37890625, Test ACC: 0.775\n",
      "385, total loss = 0.8671797513961792, reconstruct loss = 0.12624172866344452, cluster loss = 0.04918332025408745, calm loss = 0.7393163442611694, pilot loss = 5.371758460998535, max interval = -9.979188919067383, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.4072265625, Test ACC: 0.775\n",
      "386, total loss = 0.839219331741333, reconstruct loss = 0.11041396856307983, cluster loss = 0.04854981601238251, calm loss = 0.7385654449462891, pilot loss = 5.380289554595947, max interval = -10.006648063659668, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.392578125, Test ACC: 0.775\n",
      "387, total loss = 0.84423828125, reconstruct loss = 0.12969504296779633, cluster loss = 0.047712430357933044, calm loss = 0.7373051643371582, pilot loss = 5.3882832527160645, max interval = -10.03536319732666, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.40234375, Test ACC: 0.775\n",
      "388, total loss = 0.8374440670013428, reconstruct loss = 0.13881400227546692, cluster loss = 0.0473654679954052, calm loss = 0.7352455854415894, pilot loss = 5.396611213684082, max interval = -10.066473960876465, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.4326171875, Test ACC: 0.775\n",
      "389, total loss = 0.8106874227523804, reconstruct loss = 0.1259695440530777, cluster loss = 0.0487259104847908, calm loss = 0.733352541923523, pilot loss = 5.406474590301514, max interval = -10.099597930908203, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.4462890625, Test ACC: 0.7785714285714286\n",
      "390, total loss = 0.7962391376495361, reconstruct loss = 0.1281375139951706, cluster loss = 0.047050513327121735, calm loss = 0.7303460836410522, pilot loss = 5.416665077209473, max interval = -10.131125450134277, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.3974609375, Test ACC: 0.7821428571428571\n",
      "391, total loss = 0.7832993268966675, reconstruct loss = 0.1252872198820114, cluster loss = 0.049398522824048996, calm loss = 0.7283026576042175, pilot loss = 5.4268903732299805, max interval = -10.160503387451172, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.431640625, Test ACC: 0.7821428571428571\n",
      "392, total loss = 0.7651199102401733, reconstruct loss = 0.12071874737739563, cluster loss = 0.04852748289704323, calm loss = 0.7266204953193665, pilot loss = 5.436272621154785, max interval = -10.18962574005127, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.3984375, Test ACC: 0.7821428571428571\n",
      "393, total loss = 0.7568734884262085, reconstruct loss = 0.12710040807724, cluster loss = 0.04721175134181976, calm loss = 0.7246463298797607, pilot loss = 5.445631980895996, max interval = -10.2191162109375, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.4072265625, Test ACC: 0.7821428571428571\n",
      "394, total loss = 0.7347110509872437, reconstruct loss = 0.11761585623025894, cluster loss = 0.04888536408543587, calm loss = 0.7224829196929932, pilot loss = 5.4535393714904785, max interval = -10.247747421264648, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.40234375, Test ACC: 0.7821428571428571\n",
      "395, total loss = 0.726813554763794, reconstruct loss = 0.12466486543416977, cluster loss = 0.0484536811709404, calm loss = 0.72046959400177, pilot loss = 5.4623517990112305, max interval = -10.278120994567871, \n",
      "Train ACC: 0.7924528301886793, PTA: 0.400390625, Test ACC: 0.7821428571428571\n",
      "396, total loss = 0.7252966165542603, reconstruct loss = 0.13756272196769714, cluster loss = 0.049169059842824936, calm loss = 0.7185834050178528, pilot loss = 5.47141695022583, max interval = -10.309917449951172, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.419921875, Test ACC: 0.7821428571428571\n",
      "397, total loss = 0.6933397054672241, reconstruct loss = 0.12314464151859283, cluster loss = 0.04685274139046669, calm loss = 0.7170832753181458, pilot loss = 5.4803948402404785, max interval = -10.34227466583252, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.384765625, Test ACC: 0.7821428571428571\n",
      "398, total loss = 0.6797267198562622, reconstruct loss = 0.12297684699296951, cluster loss = 0.04675409197807312, calm loss = 0.7156303524971008, pilot loss = 5.490616798400879, max interval = -10.373796463012695, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.384765625, Test ACC: 0.7821428571428571\n",
      "399, total loss = 0.6611584424972534, reconstruct loss = 0.11950039118528366, cluster loss = 0.0466354675590992, calm loss = 0.7134772539138794, pilot loss = 5.50065279006958, max interval = -10.40637493133545, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.4033203125, Test ACC: 0.7821428571428571\n",
      "400, total loss = 0.6488031148910522, reconstruct loss = 0.12163354456424713, cluster loss = 0.046908922493457794, calm loss = 0.7110209465026855, pilot loss = 5.510982513427734, max interval = -10.438640594482422, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.384765625, Test ACC: 0.7821428571428571\n",
      "401, total loss = 0.6352931261062622, reconstruct loss = 0.1219455748796463, cluster loss = 0.047323741018772125, calm loss = 0.7090433239936829, pilot loss = 5.520719051361084, max interval = -10.469993591308594, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.3994140625, Test ACC: 0.7821428571428571\n",
      "402, total loss = 0.6220980882644653, reconstruct loss = 0.12303555011749268, cluster loss = 0.04768671095371246, calm loss = 0.7073556184768677, pilot loss = 5.529664039611816, max interval = -10.50121784210205, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.400390625, Test ACC: 0.7821428571428571\n",
      "403, total loss = 0.6045677661895752, reconstruct loss = 0.12153332680463791, cluster loss = 0.0463755764067173, calm loss = 0.7058511972427368, pilot loss = 5.538357257843018, max interval = -10.532444953918457, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.400390625, Test ACC: 0.7821428571428571\n",
      "404, total loss = 0.5738568305969238, reconstruct loss = 0.10323399305343628, cluster loss = 0.04775678366422653, calm loss = 0.7043461799621582, pilot loss = 5.548404216766357, max interval = -10.564284324645996, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.3935546875, Test ACC: 0.7821428571428571\n",
      "405, total loss = 0.576157808303833, reconstruct loss = 0.12016898393630981, cluster loss = 0.047675762325525284, calm loss = 0.7027414441108704, pilot loss = 5.558629512786865, max interval = -10.597322463989258, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.38671875, Test ACC: 0.7821428571428571\n",
      "406, total loss = 0.558733344078064, reconstruct loss = 0.11909247934818268, cluster loss = 0.04700274392962456, calm loss = 0.7008295655250549, pilot loss = 5.569516658782959, max interval = -10.632471084594727, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4033203125, Test ACC: 0.7821428571428571\n",
      "407, total loss = 0.5600998401641846, reconstruct loss = 0.1340855360031128, cluster loss = 0.04752008616924286, calm loss = 0.6988219022750854, pilot loss = 5.580900192260742, max interval = -10.666007041931152, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.431640625, Test ACC: 0.7821428571428571\n",
      "408, total loss = 0.5387696027755737, reconstruct loss = 0.12855443358421326, cluster loss = 0.04620013386011124, calm loss = 0.6971043348312378, pilot loss = 5.591335296630859, max interval = -10.699081420898438, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.3916015625, Test ACC: 0.7821428571428571\n",
      "409, total loss = 0.5244930982589722, reconstruct loss = 0.12849758565425873, cluster loss = 0.04695593938231468, calm loss = 0.6954435110092163, pilot loss = 5.60132360458374, max interval = -10.732309341430664, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.4072265625, Test ACC: 0.7821428571428571\n",
      "410, total loss = 0.498645544052124, reconstruct loss = 0.11711954325437546, cluster loss = 0.047090426087379456, calm loss = 0.6938561201095581, pilot loss = 5.611965656280518, max interval = -10.766046524047852, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.4072265625, Test ACC: 0.7821428571428571\n",
      "411, total loss = 0.4911518096923828, reconstruct loss = 0.12355021387338638, cluster loss = 0.048391301184892654, calm loss = 0.6922438740730286, pilot loss = 5.622473239898682, max interval = -10.800444602966309, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.44140625, Test ACC: 0.7821428571428571\n",
      "412, total loss = 0.471895694732666, reconstruct loss = 0.12065477669239044, cluster loss = 0.04713621735572815, calm loss = 0.6912769079208374, pilot loss = 5.633089542388916, max interval = -10.835749626159668, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.4013671875, Test ACC: 0.7857142857142857\n",
      "413, total loss = 0.45655179023742676, reconstruct loss = 0.11657923460006714, cluster loss = 0.049177173525094986, calm loss = 0.6908518671989441, pilot loss = 5.643532752990723, max interval = -10.869016647338867, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.4130859375, Test ACC: 0.7857142857142857\n",
      "414, total loss = 0.4448808431625366, reconstruct loss = 0.11939097940921783, cluster loss = 0.04721095785498619, calm loss = 0.6908620595932007, pilot loss = 5.653120040893555, max interval = -10.900551795959473, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.41796875, Test ACC: 0.7857142857142857\n",
      "415, total loss = 0.4254263639450073, reconstruct loss = 0.11260247230529785, cluster loss = 0.04829404130578041, calm loss = 0.6901366710662842, pilot loss = 5.662235260009766, max interval = -10.932123184204102, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.40234375, Test ACC: 0.7892857142857143\n",
      "416, total loss = 0.41895031929016113, reconstruct loss = 0.1218934953212738, cluster loss = 0.047764502465724945, calm loss = 0.6883475184440613, pilot loss = 5.672064304351807, max interval = -10.965323448181152, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.419921875, Test ACC: 0.7892857142857143\n",
      "417, total loss = 0.40358126163482666, reconstruct loss = 0.11799349635839462, cluster loss = 0.04860085994005203, calm loss = 0.6869527101516724, pilot loss = 5.6829915046691895, max interval = -10.996468544006348, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.423828125, Test ACC: 0.7892857142857143\n",
      "418, total loss = 0.39376842975616455, reconstruct loss = 0.12254492938518524, cluster loss = 0.0474974550306797, calm loss = 0.6849367022514343, pilot loss = 5.694635391235352, max interval = -11.029115676879883, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.40625, Test ACC: 0.7892857142857143\n",
      "419, total loss = 0.38564157485961914, reconstruct loss = 0.12671735882759094, cluster loss = 0.04807198792695999, calm loss = 0.6836522817611694, pilot loss = 5.706270217895508, max interval = -11.062243461608887, \n",
      "Train ACC: 0.8018867924528302, PTA: 0.3720703125, Test ACC: 0.7892857142857143\n",
      "420, total loss = 0.36655116081237793, reconstruct loss = 0.12235742062330246, cluster loss = 0.047739941626787186, calm loss = 0.6817333102226257, pilot loss = 5.7183051109313965, max interval = -11.097213745117188, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4306640625, Test ACC: 0.7892857142857143\n",
      "421, total loss = 0.3410710096359253, reconstruct loss = 0.11289699375629425, cluster loss = 0.04622600972652435, calm loss = 0.6804925203323364, pilot loss = 5.730495929718018, max interval = -11.13353157043457, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4140625, Test ACC: 0.7892857142857143\n",
      "422, total loss = 0.3328801393508911, reconstruct loss = 0.11844275146722794, cluster loss = 0.04738597571849823, calm loss = 0.6794050335884094, pilot loss = 5.74345588684082, max interval = -11.171725273132324, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.412109375, Test ACC: 0.7892857142857143\n",
      "423, total loss = 0.3207606077194214, reconstruct loss = 0.1220809817314148, cluster loss = 0.04716004058718681, calm loss = 0.6781493425369263, pilot loss = 5.754910469055176, max interval = -11.20843505859375, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4384765625, Test ACC: 0.7892857142857143\n",
      "424, total loss = 0.30428504943847656, reconstruct loss = 0.11940586566925049, cluster loss = 0.04775144159793854, calm loss = 0.6771652698516846, pilot loss = 5.765347957611084, max interval = -11.242452621459961, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4482421875, Test ACC: 0.7892857142857143\n",
      "425, total loss = 0.300952672958374, reconstruct loss = 0.12986040115356445, cluster loss = 0.04768459498882294, calm loss = 0.6760128736495972, pilot loss = 5.775802135467529, max interval = -11.27529525756836, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.412109375, Test ACC: 0.7857142857142857\n",
      "426, total loss = 0.2687944173812866, reconstruct loss = 0.11458934098482132, cluster loss = 0.04557567834854126, calm loss = 0.6740148663520813, pilot loss = 5.787678241729736, max interval = -11.31047248840332, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4150390625, Test ACC: 0.7821428571428571\n",
      "427, total loss = 0.2654130458831787, reconstruct loss = 0.12555107474327087, cluster loss = 0.04666290432214737, calm loss = 0.6716946363449097, pilot loss = 5.800928115844727, max interval = -11.348085403442383, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4228515625, Test ACC: 0.7821428571428571\n",
      "428, total loss = 0.23700451850891113, reconstruct loss = 0.11055883020162582, cluster loss = 0.04658474773168564, calm loss = 0.670545756816864, pilot loss = 5.813884258270264, max interval = -11.383963584899902, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.416015625, Test ACC: 0.7821428571428571\n",
      "429, total loss = 0.24524927139282227, reconstruct loss = 0.1324840486049652, cluster loss = 0.0469706654548645, calm loss = 0.6694570779800415, pilot loss = 5.826231956481934, max interval = -11.420099258422852, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.3994140625, Test ACC: 0.7821428571428571\n",
      "430, total loss = 0.2200993299484253, reconstruct loss = 0.12271223962306976, cluster loss = 0.04624765366315842, calm loss = 0.6684138178825378, pilot loss = 5.838035583496094, max interval = -11.456365585327148, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4169921875, Test ACC: 0.7821428571428571\n",
      "431, total loss = 0.1973254680633545, reconstruct loss = 0.1143958568572998, cluster loss = 0.04637410491704941, calm loss = 0.6673351526260376, pilot loss = 5.849437236785889, max interval = -11.49190616607666, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4150390625, Test ACC: 0.7821428571428571\n",
      "432, total loss = 0.18889307975769043, reconstruct loss = 0.11978834122419357, cluster loss = 0.04697680473327637, calm loss = 0.6668148636817932, pilot loss = 5.8597331047058105, max interval = -11.526442527770996, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4384765625, Test ACC: 0.7821428571428571\n",
      "433, total loss = 0.15730512142181396, reconstruct loss = 0.10342651605606079, cluster loss = 0.04599546268582344, calm loss = 0.6657878756523132, pilot loss = 5.8695878982543945, max interval = -11.559365272521973, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.38671875, Test ACC: 0.7821428571428571\n",
      "434, total loss = 0.15984594821929932, reconstruct loss = 0.12231452763080597, cluster loss = 0.04505721479654312, calm loss = 0.6641286015510559, pilot loss = 5.881058216094971, max interval = -11.595355033874512, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.439453125, Test ACC: 0.7821428571428571\n",
      "435, total loss = 0.1401306390762329, reconstruct loss = 0.11549749225378036, cluster loss = 0.046790070831775665, calm loss = 0.6624839901924133, pilot loss = 5.89390230178833, max interval = -11.632219314575195, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4306640625, Test ACC: 0.7821428571428571\n",
      "436, total loss = 0.12600374221801758, reconstruct loss = 0.11687460541725159, cluster loss = 0.04520558938384056, calm loss = 0.6616921424865723, pilot loss = 5.906744003295898, max interval = -11.669281005859375, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.3955078125, Test ACC: 0.7785714285714286\n",
      "437, total loss = 0.11682939529418945, reconstruct loss = 0.12142856419086456, cluster loss = 0.04629390686750412, calm loss = 0.6607670783996582, pilot loss = 5.919081211090088, max interval = -11.706713676452637, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.41796875, Test ACC: 0.7785714285714286\n",
      "438, total loss = 0.09616541862487793, reconstruct loss = 0.11629503220319748, cluster loss = 0.04626433923840523, calm loss = 0.6599308252334595, pilot loss = 5.931893825531006, max interval = -11.745931625366211, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.3955078125, Test ACC: 0.7821428571428571\n",
      "439, total loss = 0.07135236263275146, reconstruct loss = 0.10494691878557205, cluster loss = 0.0475602000951767, calm loss = 0.6595703959465027, pilot loss = 5.944856643676758, max interval = -11.78498649597168, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4228515625, Test ACC: 0.7857142857142857\n",
      "440, total loss = 0.06448161602020264, reconstruct loss = 0.11399790644645691, cluster loss = 0.046250734478235245, calm loss = 0.6586372256278992, pilot loss = 5.9566240310668945, max interval = -11.821304321289062, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.40625, Test ACC: 0.7857142857142857\n",
      "441, total loss = 0.044306039810180664, reconstruct loss = 0.10879020392894745, cluster loss = 0.04685961455106735, calm loss = 0.6576086282730103, pilot loss = 5.967774391174316, max interval = -11.857982635498047, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.404296875, Test ACC: 0.7857142857142857\n",
      "442, total loss = 0.040763258934020996, reconstruct loss = 0.12162896990776062, cluster loss = 0.04588199779391289, calm loss = 0.656726062297821, pilot loss = 5.980555534362793, max interval = -11.896953582763672, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.439453125, Test ACC: 0.7857142857142857\n",
      "443, total loss = 0.0306626558303833, reconstruct loss = 0.12695623934268951, cluster loss = 0.04627019166946411, calm loss = 0.6558729410171509, pilot loss = 5.994283199310303, max interval = -11.937909126281738, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4091796875, Test ACC: 0.7857142857142857\n",
      "444, total loss = 0.00784003734588623, reconstruct loss = 0.1191873773932457, cluster loss = 0.04571530222892761, calm loss = 0.6555759906768799, pilot loss = 6.007902145385742, max interval = -11.977622032165527, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4140625, Test ACC: 0.7857142857142857\n",
      "445, total loss = -0.005704283714294434, reconstruct loss = 0.12045083940029144, cluster loss = 0.04570881277322769, calm loss = 0.6555387377738953, pilot loss = 6.0208330154418945, max interval = -12.017157554626465, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4189453125, Test ACC: 0.7857142857142857\n",
      "446, total loss = -0.023795366287231445, reconstruct loss = 0.11591600626707077, cluster loss = 0.04807985946536064, calm loss = 0.6548720598220825, pilot loss = 6.033568382263184, max interval = -12.057122230529785, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4130859375, Test ACC: 0.7857142857142857\n",
      "447, total loss = -0.03850364685058594, reconstruct loss = 0.11753222346305847, cluster loss = 0.0463620163500309, calm loss = 0.6540787220001221, pilot loss = 6.046879768371582, max interval = -12.095844268798828, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.416015625, Test ACC: 0.7857142857142857\n",
      "448, total loss = -0.05165445804595947, reconstruct loss = 0.1192406564950943, cluster loss = 0.04690153896808624, calm loss = 0.6530166268348694, pilot loss = 6.060662269592285, max interval = -12.135987281799316, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4140625, Test ACC: 0.7857142857142857\n",
      "449, total loss = -0.07483804225921631, reconstruct loss = 0.11251300573348999, cluster loss = 0.04592691734433174, calm loss = 0.6523463129997253, pilot loss = 6.074663162231445, max interval = -12.17712116241455, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4482421875, Test ACC: 0.7857142857142857\n",
      "450, total loss = -0.09020459651947021, reconstruct loss = 0.11183378845453262, cluster loss = 0.04694994539022446, calm loss = 0.6515672206878662, pilot loss = 6.089157581329346, max interval = -12.219133377075195, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4189453125, Test ACC: 0.7821428571428571\n",
      "451, total loss = -0.10134649276733398, reconstruct loss = 0.11607758700847626, cluster loss = 0.045699380338191986, calm loss = 0.6514107584953308, pilot loss = 6.103546142578125, max interval = -12.259634971618652, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4111328125, Test ACC: 0.7821428571428571\n",
      "452, total loss = -0.12037765979766846, reconstruct loss = 0.11225471645593643, cluster loss = 0.04590621590614319, calm loss = 0.650521457195282, pilot loss = 6.117020606994629, max interval = -12.299612998962402, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4013671875, Test ACC: 0.7821428571428571\n",
      "453, total loss = -0.1408015489578247, reconstruct loss = 0.10956568270921707, cluster loss = 0.044218599796295166, calm loss = 0.6498379111289978, pilot loss = 6.129547119140625, max interval = -12.339433670043945, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.400390625, Test ACC: 0.7821428571428571\n",
      "454, total loss = -0.14953410625457764, reconstruct loss = 0.11388949304819107, cluster loss = 0.04671093821525574, calm loss = 0.6498529314994812, pilot loss = 6.141599178314209, max interval = -12.378864288330078, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4169921875, Test ACC: 0.7821428571428571\n",
      "455, total loss = -0.16195440292358398, reconstruct loss = 0.11849857866764069, cluster loss = 0.04509451612830162, calm loss = 0.6495362520217896, pilot loss = 6.1552557945251465, max interval = -12.419920921325684, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4296875, Test ACC: 0.7821428571428571\n",
      "456, total loss = -0.19533097743988037, reconstruct loss = 0.10218659788370132, cluster loss = 0.043826013803482056, calm loss = 0.648186206817627, pilot loss = 6.17020845413208, max interval = -12.46190071105957, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.380859375, Test ACC: 0.7821428571428571\n",
      "457, total loss = -0.19403588771820068, reconstruct loss = 0.11858250200748444, cluster loss = 0.044962525367736816, calm loss = 0.6463772654533386, pilot loss = 6.185629844665527, max interval = -12.504525184631348, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.41796875, Test ACC: 0.7821428571428571\n",
      "458, total loss = -0.21716046333312988, reconstruct loss = 0.10993444919586182, cluster loss = 0.04677988588809967, calm loss = 0.6446996927261353, pilot loss = 6.200624465942383, max interval = -12.546807289123535, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.421875, Test ACC: 0.7821428571428571\n",
      "459, total loss = -0.23735809326171875, reconstruct loss = 0.10563752800226212, cluster loss = 0.046780139207839966, calm loss = 0.643606960773468, pilot loss = 6.215623378753662, max interval = -12.589372634887695, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.41796875, Test ACC: 0.7821428571428571\n",
      "460, total loss = -0.24321484565734863, reconstruct loss = 0.11643809080123901, cluster loss = 0.045437343418598175, calm loss = 0.6431565284729004, pilot loss = 6.230001926422119, max interval = -12.631132125854492, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4150390625, Test ACC: 0.7857142857142857\n",
      "461, total loss = -0.2643864154815674, reconstruct loss = 0.11033819615840912, cluster loss = 0.046460799872875214, calm loss = 0.642565131187439, pilot loss = 6.243772029876709, max interval = -12.672937393188477, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.3984375, Test ACC: 0.7857142857142857\n",
      "462, total loss = -0.2823423147201538, reconstruct loss = 0.11095096170902252, cluster loss = 0.04479195922613144, calm loss = 0.6411267518997192, pilot loss = 6.25715446472168, max interval = -12.714128494262695, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4384765625, Test ACC: 0.7892857142857143\n",
      "463, total loss = -0.29860150814056396, reconstruct loss = 0.10937727987766266, cluster loss = 0.04695647209882736, calm loss = 0.6397637128829956, pilot loss = 6.270355701446533, max interval = -12.755098342895508, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4443359375, Test ACC: 0.7892857142857143\n",
      "464, total loss = -0.31378352642059326, reconstruct loss = 0.11248326301574707, cluster loss = 0.04539955034852028, calm loss = 0.6384981870651245, pilot loss = 6.284603118896484, max interval = -12.797531127929688, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.423828125, Test ACC: 0.7892857142857143\n",
      "465, total loss = -0.33688461780548096, reconstruct loss = 0.10613720118999481, cluster loss = 0.045358944684267044, calm loss = 0.6374207735061646, pilot loss = 6.300682067871094, max interval = -12.842828750610352, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.421875, Test ACC: 0.7892857142857143\n",
      "466, total loss = -0.35001134872436523, reconstruct loss = 0.1097474917769432, cluster loss = 0.04482927918434143, calm loss = 0.636914074420929, pilot loss = 6.317022323608398, max interval = -12.888590812683105, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.419921875, Test ACC: 0.7892857142857143\n",
      "467, total loss = -0.36971330642700195, reconstruct loss = 0.1059810146689415, cluster loss = 0.04589376598596573, calm loss = 0.6359453797340393, pilot loss = 6.333631992340088, max interval = -12.935211181640625, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4228515625, Test ACC: 0.7892857142857143\n",
      "468, total loss = -0.3786426782608032, reconstruct loss = 0.11501725018024445, cluster loss = 0.04530812054872513, calm loss = 0.6346604228019714, pilot loss = 6.350813865661621, max interval = -12.982739448547363, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4208984375, Test ACC: 0.7857142857142857\n",
      "469, total loss = -0.3982279300689697, reconstruct loss = 0.11251571029424667, cluster loss = 0.04401034116744995, calm loss = 0.6342902183532715, pilot loss = 6.367702960968018, max interval = -13.028879165649414, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4296875, Test ACC: 0.7857142857142857\n",
      "470, total loss = -0.4136359691619873, reconstruct loss = 0.11371587961912155, cluster loss = 0.04579438641667366, calm loss = 0.632856011390686, pilot loss = 6.384946346282959, max interval = -13.077729225158691, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.443359375, Test ACC: 0.7857142857142857\n",
      "471, total loss = -0.43741536140441895, reconstruct loss = 0.10916206985712051, cluster loss = 0.04540959373116493, calm loss = 0.6311361193656921, pilot loss = 6.4024481773376465, max interval = -13.127182960510254, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.435546875, Test ACC: 0.7857142857142857\n",
      "472, total loss = -0.45431363582611084, reconstruct loss = 0.10969589650630951, cluster loss = 0.043720830231904984, calm loss = 0.630625307559967, pilot loss = 6.41964054107666, max interval = -13.173497200012207, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4072265625, Test ACC: 0.7857142857142857\n",
      "473, total loss = -0.4706108570098877, reconstruct loss = 0.10758675634860992, cluster loss = 0.047849416732788086, calm loss = 0.62933748960495, pilot loss = 6.43752384185791, max interval = -13.22336483001709, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4521484375, Test ACC: 0.7857142857142857\n",
      "474, total loss = -0.49463093280792236, reconstruct loss = 0.10442014783620834, cluster loss = 0.046657487750053406, calm loss = 0.6277783513069153, pilot loss = 6.4572062492370605, max interval = -13.277338981628418, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4228515625, Test ACC: 0.7857142857142857\n",
      "475, total loss = -0.5058977603912354, reconstruct loss = 0.11296618729829788, cluster loss = 0.044302210211753845, calm loss = 0.6272035837173462, pilot loss = 6.47764778137207, max interval = -13.330655097961426, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.421875, Test ACC: 0.7857142857142857\n",
      "476, total loss = -0.5234755277633667, reconstruct loss = 0.11156599968671799, cluster loss = 0.0458386167883873, calm loss = 0.6270705461502075, pilot loss = 6.498273849487305, max interval = -13.385233879089355, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4111328125, Test ACC: 0.7857142857142857\n",
      "477, total loss = -0.5447506904602051, reconstruct loss = 0.10821188241243362, cluster loss = 0.0453900471329689, calm loss = 0.6277991533279419, pilot loss = 6.518491744995117, max interval = -13.440116882324219, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4296875, Test ACC: 0.7892857142857143\n",
      "478, total loss = -0.5607179403305054, reconstruct loss = 0.11138268560171127, cluster loss = 0.04420565813779831, calm loss = 0.6281991004943848, pilot loss = 6.538559436798096, max interval = -13.495003700256348, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.42578125, Test ACC: 0.7892857142857143\n",
      "479, total loss = -0.5807874202728271, reconstruct loss = 0.11077320575714111, cluster loss = 0.045662932097911835, calm loss = 0.6269919276237488, pilot loss = 6.5595808029174805, max interval = -13.553192138671875, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4384765625, Test ACC: 0.7892857142857143\n",
      "480, total loss = -0.5985285043716431, reconstruct loss = 0.1110464334487915, cluster loss = 0.04481050372123718, calm loss = 0.6285743713378906, pilot loss = 6.58173942565918, max interval = -13.611626625061035, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.443359375, Test ACC: 0.7892857142857143\n",
      "481, total loss = -0.6138442754745483, reconstruct loss = 0.11164017021656036, cluster loss = 0.04578433930873871, calm loss = 0.6300002336502075, pilot loss = 6.6012043952941895, max interval = -13.6655912399292, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4287109375, Test ACC: 0.7928571428571428\n",
      "482, total loss = -0.6269593238830566, reconstruct loss = 0.11130810528993607, cluster loss = 0.0466698594391346, calm loss = 0.6322022080421448, pilot loss = 6.617768287658691, max interval = -13.711931228637695, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4482421875, Test ACC: 0.7928571428571428\n",
      "483, total loss = -0.6413220167160034, reconstruct loss = 0.114273302257061, cluster loss = 0.045391496270895004, calm loss = 0.6328202486038208, pilot loss = 6.631641864776611, max interval = -13.755565643310547, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4453125, Test ACC: 0.7928571428571428\n",
      "484, total loss = -0.6740924119949341, reconstruct loss = 0.10036617517471313, cluster loss = 0.045006219297647476, calm loss = 0.6317188143730164, pilot loss = 6.643074989318848, max interval = -13.79672908782959, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4375, Test ACC: 0.7892857142857143\n",
      "485, total loss = -0.6795939207077026, reconstruct loss = 0.11449830234050751, cluster loss = 0.04597316309809685, calm loss = 0.6285669207572937, pilot loss = 6.652585983276367, max interval = -13.835250854492188, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4365234375, Test ACC: 0.7892857142857143\n",
      "486, total loss = -0.7072048187255859, reconstruct loss = 0.10510952025651932, cluster loss = 0.04486073553562164, calm loss = 0.6262051463127136, pilot loss = 6.6611833572387695, max interval = -13.868609428405762, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4296875, Test ACC: 0.7892857142857143\n",
      "487, total loss = -0.7251253128051758, reconstruct loss = 0.10428836941719055, cluster loss = 0.04529687762260437, calm loss = 0.6237943768501282, pilot loss = 6.670104026794434, max interval = -13.902972221374512, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.3974609375, Test ACC: 0.7892857142857143\n",
      "488, total loss = -0.7369890213012695, reconstruct loss = 0.11113055050373077, cluster loss = 0.04451747611165047, calm loss = 0.6211918592453003, pilot loss = 6.680059432983398, max interval = -13.93909740447998, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4091796875, Test ACC: 0.7857142857142857\n",
      "489, total loss = -0.7538267374038696, reconstruct loss = 0.11131471395492554, cluster loss = 0.04486272111535072, calm loss = 0.6191164255142212, pilot loss = 6.69050931930542, max interval = -13.975881576538086, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4169921875, Test ACC: 0.7857142857142857\n",
      "490, total loss = -0.7737655639648438, reconstruct loss = 0.1088784784078598, cluster loss = 0.045276228338479996, calm loss = 0.6180590391159058, pilot loss = 6.70380973815918, max interval = -14.018980026245117, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.4521484375, Test ACC: 0.7857142857142857\n",
      "491, total loss = -0.788174033164978, reconstruct loss = 0.11352416127920151, cluster loss = 0.044796284288167953, calm loss = 0.6177984476089478, pilot loss = 6.719776630401611, max interval = -14.067965507507324, \n",
      "Train ACC: 0.8113207547169812, PTA: 0.423828125, Test ACC: 0.7857142857142857\n",
      "492, total loss = -0.8107702732086182, reconstruct loss = 0.11067257076501846, cluster loss = 0.04476618766784668, calm loss = 0.6176589727401733, pilot loss = 6.736527919769287, max interval = -14.119877815246582, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.421875, Test ACC: 0.7857142857142857\n",
      "493, total loss = -0.8344531059265137, reconstruct loss = 0.10737478733062744, cluster loss = 0.04458576440811157, calm loss = 0.617702841758728, pilot loss = 6.753404140472412, max interval = -14.172928810119629, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4111328125, Test ACC: 0.7857142857142857\n",
      "494, total loss = -0.8426892757415771, reconstruct loss = 0.11793050169944763, cluster loss = 0.04376240447163582, calm loss = 0.618218719959259, pilot loss = 6.769447326660156, max interval = -14.222270965576172, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4287109375, Test ACC: 0.7857142857142857\n",
      "495, total loss = -0.8728897571563721, reconstruct loss = 0.1049710065126419, cluster loss = 0.04608342796564102, calm loss = 0.6176703572273254, pilot loss = 6.784694671630859, max interval = -14.271232604980469, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.431640625, Test ACC: 0.7857142857142857\n",
      "496, total loss = -0.89589524269104, reconstruct loss = 0.100556381046772, cluster loss = 0.0451124869287014, calm loss = 0.6175660490989685, pilot loss = 6.800134181976318, max interval = -14.318328857421875, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.404296875, Test ACC: 0.7857142857142857\n",
      "497, total loss = -0.8990089893341064, reconstruct loss = 0.11652717739343643, cluster loss = 0.0431542806327343, calm loss = 0.6179355382919312, pilot loss = 6.816160202026367, max interval = -14.366235733032227, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.453125, Test ACC: 0.7857142857142857\n",
      "498, total loss = -0.933854341506958, reconstruct loss = 0.099282406270504, cluster loss = 0.043460413813591, calm loss = 0.6173568964004517, pilot loss = 6.832274436950684, max interval = -14.414031028747559, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.4140625, Test ACC: 0.7892857142857143\n",
      "499, total loss = -0.9412351846694946, reconstruct loss = 0.1092463955283165, cluster loss = 0.044882070273160934, calm loss = 0.6171115040779114, pilot loss = 6.850522994995117, max interval = -14.466581344604492, \n",
      "Train ACC: 0.8207547169811321, PTA: 0.439453125, Test ACC: 0.7892857142857143\n",
      "INFO:tensorflow:sdec_ckpt\\model_supervise.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACC_TRAIN': array([[0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.6509434 ],\n",
       "        [0.6509434 ],\n",
       "        [0.6509434 ],\n",
       "        [0.6509434 ],\n",
       "        [0.64150943],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.63207547],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.61320755],\n",
       "        [0.61320755],\n",
       "        [0.61320755],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.59433962],\n",
       "        [0.58490566],\n",
       "        [0.58490566],\n",
       "        [0.58490566],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.56603774],\n",
       "        [0.56603774],\n",
       "        [0.56603774],\n",
       "        [0.56603774],\n",
       "        [0.56603774],\n",
       "        [0.56603774],\n",
       "        [0.55660377],\n",
       "        [0.55660377],\n",
       "        [0.55660377],\n",
       "        [0.55660377],\n",
       "        [0.54716981],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.53773585],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.51886792],\n",
       "        [0.50943396],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.50943396],\n",
       "        [0.50943396],\n",
       "        [0.50943396],\n",
       "        [0.50943396],\n",
       "        [0.50943396],\n",
       "        [0.51886792],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.52830189],\n",
       "        [0.53773585],\n",
       "        [0.54716981],\n",
       "        [0.55660377],\n",
       "        [0.56603774],\n",
       "        [0.56603774],\n",
       "        [0.5754717 ],\n",
       "        [0.5754717 ],\n",
       "        [0.58490566],\n",
       "        [0.58490566],\n",
       "        [0.58490566],\n",
       "        [0.59433962],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.60377358],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.62264151],\n",
       "        [0.63207547],\n",
       "        [0.64150943],\n",
       "        [0.6509434 ],\n",
       "        [0.6509434 ],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66037736],\n",
       "        [0.66981132],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.68867925],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.68867925],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.67924528],\n",
       "        [0.68867925],\n",
       "        [0.68867925],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.69811321],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.70754717],\n",
       "        [0.71698113],\n",
       "        [0.71698113],\n",
       "        [0.71698113],\n",
       "        [0.71698113],\n",
       "        [0.71698113],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.72641509],\n",
       "        [0.73584906],\n",
       "        [0.73584906],\n",
       "        [0.74528302],\n",
       "        [0.74528302],\n",
       "        [0.74528302],\n",
       "        [0.74528302],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.75471698],\n",
       "        [0.76415094],\n",
       "        [0.76415094],\n",
       "        [0.76415094],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.77358491],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.78301887],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.79245283],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.80188679],\n",
       "        [0.81132075],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.81132075],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472],\n",
       "        [0.82075472]]),\n",
       " 'PTA': array([[0.76660156],\n",
       "        [0.75585938],\n",
       "        [0.75195312],\n",
       "        [0.77441406],\n",
       "        [0.77441406],\n",
       "        [0.75585938],\n",
       "        [0.76367188],\n",
       "        [0.74804688],\n",
       "        [0.74902344],\n",
       "        [0.76660156],\n",
       "        [0.74902344],\n",
       "        [0.7578125 ],\n",
       "        [0.75683594],\n",
       "        [0.7578125 ],\n",
       "        [0.77832031],\n",
       "        [0.73535156],\n",
       "        [0.7578125 ],\n",
       "        [0.74804688],\n",
       "        [0.72753906],\n",
       "        [0.75878906],\n",
       "        [0.75390625],\n",
       "        [0.7421875 ],\n",
       "        [0.75390625],\n",
       "        [0.73144531],\n",
       "        [0.73046875],\n",
       "        [0.76269531],\n",
       "        [0.76855469],\n",
       "        [0.75390625],\n",
       "        [0.73730469],\n",
       "        [0.75097656],\n",
       "        [0.7578125 ],\n",
       "        [0.7265625 ],\n",
       "        [0.7421875 ],\n",
       "        [0.74707031],\n",
       "        [0.71972656],\n",
       "        [0.73632812],\n",
       "        [0.72167969],\n",
       "        [0.73242188],\n",
       "        [0.74511719],\n",
       "        [0.71777344],\n",
       "        [0.74609375],\n",
       "        [0.73632812],\n",
       "        [0.7265625 ],\n",
       "        [0.72753906],\n",
       "        [0.7265625 ],\n",
       "        [0.72753906],\n",
       "        [0.73046875],\n",
       "        [0.70019531],\n",
       "        [0.71582031],\n",
       "        [0.73925781],\n",
       "        [0.73925781],\n",
       "        [0.70507812],\n",
       "        [0.70898438],\n",
       "        [0.72460938],\n",
       "        [0.71972656],\n",
       "        [0.73242188],\n",
       "        [0.70507812],\n",
       "        [0.72265625],\n",
       "        [0.72753906],\n",
       "        [0.70898438],\n",
       "        [0.71972656],\n",
       "        [0.72851562],\n",
       "        [0.72070312],\n",
       "        [0.71972656],\n",
       "        [0.71972656],\n",
       "        [0.70898438],\n",
       "        [0.75195312],\n",
       "        [0.703125  ],\n",
       "        [0.69824219],\n",
       "        [0.70214844],\n",
       "        [0.69824219],\n",
       "        [0.72363281],\n",
       "        [0.71679688],\n",
       "        [0.68847656],\n",
       "        [0.70117188],\n",
       "        [0.70605469],\n",
       "        [0.70117188],\n",
       "        [0.71679688],\n",
       "        [0.72460938],\n",
       "        [0.71484375],\n",
       "        [0.70410156],\n",
       "        [0.71289062],\n",
       "        [0.73144531],\n",
       "        [0.7109375 ],\n",
       "        [0.68261719],\n",
       "        [0.71875   ],\n",
       "        [0.73144531],\n",
       "        [0.69140625],\n",
       "        [0.68847656],\n",
       "        [0.67578125],\n",
       "        [0.69140625],\n",
       "        [0.71582031],\n",
       "        [0.70507812],\n",
       "        [0.69042969],\n",
       "        [0.68554688],\n",
       "        [0.70703125],\n",
       "        [0.70800781],\n",
       "        [0.70214844],\n",
       "        [0.70117188],\n",
       "        [0.68945312],\n",
       "        [0.6484375 ],\n",
       "        [0.3125    ],\n",
       "        [0.33105469],\n",
       "        [0.29589844],\n",
       "        [0.32226562],\n",
       "        [0.32128906],\n",
       "        [0.31835938],\n",
       "        [0.31640625],\n",
       "        [0.31445312],\n",
       "        [0.34375   ],\n",
       "        [0.31835938],\n",
       "        [0.30664062],\n",
       "        [0.33398438],\n",
       "        [0.32617188],\n",
       "        [0.33984375],\n",
       "        [0.29296875],\n",
       "        [0.34765625],\n",
       "        [0.33691406],\n",
       "        [0.33300781],\n",
       "        [0.33105469],\n",
       "        [0.31054688],\n",
       "        [0.32421875],\n",
       "        [0.32128906],\n",
       "        [0.32128906],\n",
       "        [0.32324219],\n",
       "        [0.33203125],\n",
       "        [0.35449219],\n",
       "        [0.3359375 ],\n",
       "        [0.35742188],\n",
       "        [0.34277344],\n",
       "        [0.35253906],\n",
       "        [0.35839844],\n",
       "        [0.34960938],\n",
       "        [0.3515625 ],\n",
       "        [0.37011719],\n",
       "        [0.34472656],\n",
       "        [0.3515625 ],\n",
       "        [0.359375  ],\n",
       "        [0.35742188],\n",
       "        [0.36621094],\n",
       "        [0.37792969],\n",
       "        [0.33691406],\n",
       "        [0.36230469],\n",
       "        [0.34277344],\n",
       "        [0.33300781],\n",
       "        [0.34472656],\n",
       "        [0.34375   ],\n",
       "        [0.35449219],\n",
       "        [0.34375   ],\n",
       "        [0.36425781],\n",
       "        [0.34179688],\n",
       "        [0.36328125],\n",
       "        [0.36035156],\n",
       "        [0.37011719],\n",
       "        [0.36816406],\n",
       "        [0.38574219],\n",
       "        [0.35351562],\n",
       "        [0.35351562],\n",
       "        [0.36425781],\n",
       "        [0.37890625],\n",
       "        [0.37597656],\n",
       "        [0.37207031],\n",
       "        [0.37011719],\n",
       "        [0.35351562],\n",
       "        [0.36328125],\n",
       "        [0.35058594],\n",
       "        [0.37011719],\n",
       "        [0.38183594],\n",
       "        [0.38085938],\n",
       "        [0.37402344],\n",
       "        [0.41796875],\n",
       "        [0.37402344],\n",
       "        [0.40625   ],\n",
       "        [0.37304688],\n",
       "        [0.37890625],\n",
       "        [0.39648438],\n",
       "        [0.39160156],\n",
       "        [0.37109375],\n",
       "        [0.39160156],\n",
       "        [0.3984375 ],\n",
       "        [0.38085938],\n",
       "        [0.39648438],\n",
       "        [0.40625   ],\n",
       "        [0.37792969],\n",
       "        [0.3828125 ],\n",
       "        [0.3671875 ],\n",
       "        [0.38867188],\n",
       "        [0.38476562],\n",
       "        [0.38964844],\n",
       "        [0.38378906],\n",
       "        [0.39453125],\n",
       "        [0.3828125 ],\n",
       "        [0.36523438],\n",
       "        [0.38964844],\n",
       "        [0.42675781],\n",
       "        [0.37988281],\n",
       "        [0.40136719],\n",
       "        [0.38183594],\n",
       "        [0.37695312],\n",
       "        [0.39746094],\n",
       "        [0.40429688],\n",
       "        [0.37011719],\n",
       "        [0.39648438],\n",
       "        [0.40820312],\n",
       "        [0.40625   ],\n",
       "        [0.37402344],\n",
       "        [0.38476562],\n",
       "        [0.35449219],\n",
       "        [0.38085938],\n",
       "        [0.38183594],\n",
       "        [0.38476562],\n",
       "        [0.41601562],\n",
       "        [0.39648438],\n",
       "        [0.40722656],\n",
       "        [0.38867188],\n",
       "        [0.41308594],\n",
       "        [0.41113281],\n",
       "        [0.41015625],\n",
       "        [0.41015625],\n",
       "        [0.40527344],\n",
       "        [0.38574219],\n",
       "        [0.38671875],\n",
       "        [0.39355469],\n",
       "        [0.38378906],\n",
       "        [0.40722656],\n",
       "        [0.38964844],\n",
       "        [0.37011719],\n",
       "        [0.39550781],\n",
       "        [0.40332031],\n",
       "        [0.39648438],\n",
       "        [0.38671875],\n",
       "        [0.40625   ],\n",
       "        [0.40820312],\n",
       "        [0.390625  ],\n",
       "        [0.40136719],\n",
       "        [0.40332031],\n",
       "        [0.39746094],\n",
       "        [0.38867188],\n",
       "        [0.41015625],\n",
       "        [0.39746094],\n",
       "        [0.39160156],\n",
       "        [0.37304688],\n",
       "        [0.37695312],\n",
       "        [0.41113281],\n",
       "        [0.40136719],\n",
       "        [0.37402344],\n",
       "        [0.3984375 ],\n",
       "        [0.40722656],\n",
       "        [0.37695312],\n",
       "        [0.38183594],\n",
       "        [0.42285156],\n",
       "        [0.36132812],\n",
       "        [0.40527344],\n",
       "        [0.43847656],\n",
       "        [0.40136719],\n",
       "        [0.3828125 ],\n",
       "        [0.41894531],\n",
       "        [0.41992188],\n",
       "        [0.39355469],\n",
       "        [0.39257812],\n",
       "        [0.38183594],\n",
       "        [0.3828125 ],\n",
       "        [0.41796875],\n",
       "        [0.40722656],\n",
       "        [0.39648438],\n",
       "        [0.40234375],\n",
       "        [0.41015625],\n",
       "        [0.38867188],\n",
       "        [0.39453125],\n",
       "        [0.36132812],\n",
       "        [0.38867188],\n",
       "        [0.40136719],\n",
       "        [0.38476562],\n",
       "        [0.3828125 ],\n",
       "        [0.40820312],\n",
       "        [0.40722656],\n",
       "        [0.40234375],\n",
       "        [0.41113281],\n",
       "        [0.38671875],\n",
       "        [0.40722656],\n",
       "        [0.390625  ],\n",
       "        [0.37695312],\n",
       "        [0.39746094],\n",
       "        [0.43164062],\n",
       "        [0.38183594],\n",
       "        [0.41796875],\n",
       "        [0.40332031],\n",
       "        [0.37109375],\n",
       "        [0.41894531],\n",
       "        [0.38085938],\n",
       "        [0.40722656],\n",
       "        [0.37988281],\n",
       "        [0.38964844],\n",
       "        [0.39941406],\n",
       "        [0.41015625],\n",
       "        [0.41601562],\n",
       "        [0.40234375],\n",
       "        [0.38378906],\n",
       "        [0.41210938],\n",
       "        [0.40917969],\n",
       "        [0.37988281],\n",
       "        [0.40332031],\n",
       "        [0.41992188],\n",
       "        [0.38476562],\n",
       "        [0.37988281],\n",
       "        [0.40136719],\n",
       "        [0.40136719],\n",
       "        [0.40625   ],\n",
       "        [0.39453125],\n",
       "        [0.41210938],\n",
       "        [0.40429688],\n",
       "        [0.40625   ],\n",
       "        [0.39648438],\n",
       "        [0.38183594],\n",
       "        [0.39648438],\n",
       "        [0.40625   ],\n",
       "        [0.38867188],\n",
       "        [0.39160156],\n",
       "        [0.40527344],\n",
       "        [0.38183594],\n",
       "        [0.39746094],\n",
       "        [0.41601562],\n",
       "        [0.39453125],\n",
       "        [0.40722656],\n",
       "        [0.40136719],\n",
       "        [0.375     ],\n",
       "        [0.40429688],\n",
       "        [0.38183594],\n",
       "        [0.39160156],\n",
       "        [0.36425781],\n",
       "        [0.40722656],\n",
       "        [0.41699219],\n",
       "        [0.42089844],\n",
       "        [0.37988281],\n",
       "        [0.42382812],\n",
       "        [0.39453125],\n",
       "        [0.41503906],\n",
       "        [0.40429688],\n",
       "        [0.40527344],\n",
       "        [0.39941406],\n",
       "        [0.375     ],\n",
       "        [0.39941406],\n",
       "        [0.39648438],\n",
       "        [0.37890625],\n",
       "        [0.37597656],\n",
       "        [0.40429688],\n",
       "        [0.4140625 ],\n",
       "        [0.39550781],\n",
       "        [0.41015625],\n",
       "        [0.37402344],\n",
       "        [0.41894531],\n",
       "        [0.39941406],\n",
       "        [0.37890625],\n",
       "        [0.39648438],\n",
       "        [0.3984375 ],\n",
       "        [0.39257812],\n",
       "        [0.40136719],\n",
       "        [0.41601562],\n",
       "        [0.37109375],\n",
       "        [0.39257812],\n",
       "        [0.4140625 ],\n",
       "        [0.39648438],\n",
       "        [0.40625   ],\n",
       "        [0.3984375 ],\n",
       "        [0.39160156],\n",
       "        [0.42382812],\n",
       "        [0.40234375],\n",
       "        [0.42871094],\n",
       "        [0.40136719],\n",
       "        [0.39355469],\n",
       "        [0.42285156],\n",
       "        [0.38867188],\n",
       "        [0.39746094],\n",
       "        [0.43164062],\n",
       "        [0.39160156],\n",
       "        [0.41601562],\n",
       "        [0.41601562],\n",
       "        [0.39941406],\n",
       "        [0.421875  ],\n",
       "        [0.41503906],\n",
       "        [0.40527344],\n",
       "        [0.40429688],\n",
       "        [0.41992188],\n",
       "        [0.41015625],\n",
       "        [0.37890625],\n",
       "        [0.40722656],\n",
       "        [0.39257812],\n",
       "        [0.40234375],\n",
       "        [0.43261719],\n",
       "        [0.44628906],\n",
       "        [0.39746094],\n",
       "        [0.43164062],\n",
       "        [0.3984375 ],\n",
       "        [0.40722656],\n",
       "        [0.40234375],\n",
       "        [0.40039062],\n",
       "        [0.41992188],\n",
       "        [0.38476562],\n",
       "        [0.38476562],\n",
       "        [0.40332031],\n",
       "        [0.38476562],\n",
       "        [0.39941406],\n",
       "        [0.40039062],\n",
       "        [0.40039062],\n",
       "        [0.39355469],\n",
       "        [0.38671875],\n",
       "        [0.40332031],\n",
       "        [0.43164062],\n",
       "        [0.39160156],\n",
       "        [0.40722656],\n",
       "        [0.40722656],\n",
       "        [0.44140625],\n",
       "        [0.40136719],\n",
       "        [0.41308594],\n",
       "        [0.41796875],\n",
       "        [0.40234375],\n",
       "        [0.41992188],\n",
       "        [0.42382812],\n",
       "        [0.40625   ],\n",
       "        [0.37207031],\n",
       "        [0.43066406],\n",
       "        [0.4140625 ],\n",
       "        [0.41210938],\n",
       "        [0.43847656],\n",
       "        [0.44824219],\n",
       "        [0.41210938],\n",
       "        [0.41503906],\n",
       "        [0.42285156],\n",
       "        [0.41601562],\n",
       "        [0.39941406],\n",
       "        [0.41699219],\n",
       "        [0.41503906],\n",
       "        [0.43847656],\n",
       "        [0.38671875],\n",
       "        [0.43945312],\n",
       "        [0.43066406],\n",
       "        [0.39550781],\n",
       "        [0.41796875],\n",
       "        [0.39550781],\n",
       "        [0.42285156],\n",
       "        [0.40625   ],\n",
       "        [0.40429688],\n",
       "        [0.43945312],\n",
       "        [0.40917969],\n",
       "        [0.4140625 ],\n",
       "        [0.41894531],\n",
       "        [0.41308594],\n",
       "        [0.41601562],\n",
       "        [0.4140625 ],\n",
       "        [0.44824219],\n",
       "        [0.41894531],\n",
       "        [0.41113281],\n",
       "        [0.40136719],\n",
       "        [0.40039062],\n",
       "        [0.41699219],\n",
       "        [0.4296875 ],\n",
       "        [0.38085938],\n",
       "        [0.41796875],\n",
       "        [0.421875  ],\n",
       "        [0.41796875],\n",
       "        [0.41503906],\n",
       "        [0.3984375 ],\n",
       "        [0.43847656],\n",
       "        [0.44433594],\n",
       "        [0.42382812],\n",
       "        [0.421875  ],\n",
       "        [0.41992188],\n",
       "        [0.42285156],\n",
       "        [0.42089844],\n",
       "        [0.4296875 ],\n",
       "        [0.44335938],\n",
       "        [0.43554688],\n",
       "        [0.40722656],\n",
       "        [0.45214844],\n",
       "        [0.42285156],\n",
       "        [0.421875  ],\n",
       "        [0.41113281],\n",
       "        [0.4296875 ],\n",
       "        [0.42578125],\n",
       "        [0.43847656],\n",
       "        [0.44335938],\n",
       "        [0.42871094],\n",
       "        [0.44824219],\n",
       "        [0.4453125 ],\n",
       "        [0.4375    ],\n",
       "        [0.43652344],\n",
       "        [0.4296875 ],\n",
       "        [0.39746094],\n",
       "        [0.40917969],\n",
       "        [0.41699219],\n",
       "        [0.45214844],\n",
       "        [0.42382812],\n",
       "        [0.421875  ],\n",
       "        [0.41113281],\n",
       "        [0.42871094],\n",
       "        [0.43164062],\n",
       "        [0.40429688],\n",
       "        [0.453125  ],\n",
       "        [0.4140625 ],\n",
       "        [0.43945312]]),\n",
       " 'ACC_TEST': array([[0.625     ],\n",
       "        [0.625     ],\n",
       "        [0.625     ],\n",
       "        [0.625     ],\n",
       "        [0.625     ],\n",
       "        [0.61785714],\n",
       "        [0.61785714],\n",
       "        [0.61785714],\n",
       "        [0.61428571],\n",
       "        [0.61071429],\n",
       "        [0.61071429],\n",
       "        [0.60714286],\n",
       "        [0.60357143],\n",
       "        [0.60357143],\n",
       "        [0.60357143],\n",
       "        [0.6       ],\n",
       "        [0.6       ],\n",
       "        [0.6       ],\n",
       "        [0.6       ],\n",
       "        [0.59642857],\n",
       "        [0.59285714],\n",
       "        [0.59285714],\n",
       "        [0.59285714],\n",
       "        [0.58928571],\n",
       "        [0.58214286],\n",
       "        [0.58214286],\n",
       "        [0.58214286],\n",
       "        [0.58214286],\n",
       "        [0.58214286],\n",
       "        [0.58214286],\n",
       "        [0.575     ],\n",
       "        [0.575     ],\n",
       "        [0.575     ],\n",
       "        [0.575     ],\n",
       "        [0.575     ],\n",
       "        [0.575     ],\n",
       "        [0.57142857],\n",
       "        [0.57142857],\n",
       "        [0.56785714],\n",
       "        [0.56428571],\n",
       "        [0.56071429],\n",
       "        [0.55714286],\n",
       "        [0.55714286],\n",
       "        [0.55714286],\n",
       "        [0.55714286],\n",
       "        [0.55714286],\n",
       "        [0.55357143],\n",
       "        [0.55357143],\n",
       "        [0.55357143],\n",
       "        [0.55      ],\n",
       "        [0.54642857],\n",
       "        [0.54642857],\n",
       "        [0.54642857],\n",
       "        [0.54642857],\n",
       "        [0.54642857],\n",
       "        [0.54642857],\n",
       "        [0.54285714],\n",
       "        [0.53928571],\n",
       "        [0.53571429],\n",
       "        [0.53571429],\n",
       "        [0.53214286],\n",
       "        [0.52857143],\n",
       "        [0.52857143],\n",
       "        [0.53214286],\n",
       "        [0.53214286],\n",
       "        [0.52857143],\n",
       "        [0.52857143],\n",
       "        [0.525     ],\n",
       "        [0.525     ],\n",
       "        [0.525     ],\n",
       "        [0.525     ],\n",
       "        [0.52142857],\n",
       "        [0.51785714],\n",
       "        [0.51785714],\n",
       "        [0.51785714],\n",
       "        [0.51785714],\n",
       "        [0.51428571],\n",
       "        [0.51071429],\n",
       "        [0.51071429],\n",
       "        [0.51071429],\n",
       "        [0.50714286],\n",
       "        [0.50714286],\n",
       "        [0.50357143],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.49642857],\n",
       "        [0.49642857],\n",
       "        [0.49285714],\n",
       "        [0.48928571],\n",
       "        [0.48571429],\n",
       "        [0.48214286],\n",
       "        [0.48571429],\n",
       "        [0.48571429],\n",
       "        [0.48571429],\n",
       "        [0.48571429],\n",
       "        [0.48571429],\n",
       "        [0.48571429],\n",
       "        [0.48571429],\n",
       "        [0.48214286],\n",
       "        [0.48214286],\n",
       "        [0.51785714],\n",
       "        [0.51785714],\n",
       "        [0.51785714],\n",
       "        [0.525     ],\n",
       "        [0.52857143],\n",
       "        [0.53214286],\n",
       "        [0.53571429],\n",
       "        [0.53928571],\n",
       "        [0.53928571],\n",
       "        [0.53928571],\n",
       "        [0.53928571],\n",
       "        [0.54285714],\n",
       "        [0.54642857],\n",
       "        [0.54642857],\n",
       "        [0.55      ],\n",
       "        [0.55357143],\n",
       "        [0.55357143],\n",
       "        [0.55714286],\n",
       "        [0.56071429],\n",
       "        [0.56071429],\n",
       "        [0.56785714],\n",
       "        [0.57142857],\n",
       "        [0.575     ],\n",
       "        [0.575     ],\n",
       "        [0.57857143],\n",
       "        [0.58571429],\n",
       "        [0.58571429],\n",
       "        [0.58928571],\n",
       "        [0.58928571],\n",
       "        [0.59285714],\n",
       "        [0.59285714],\n",
       "        [0.59285714],\n",
       "        [0.59642857],\n",
       "        [0.59642857],\n",
       "        [0.60357143],\n",
       "        [0.60714286],\n",
       "        [0.60357143],\n",
       "        [0.60357143],\n",
       "        [0.61071429],\n",
       "        [0.61071429],\n",
       "        [0.61071429],\n",
       "        [0.61071429],\n",
       "        [0.61428571],\n",
       "        [0.61785714],\n",
       "        [0.61785714],\n",
       "        [0.61785714],\n",
       "        [0.62142857],\n",
       "        [0.62142857],\n",
       "        [0.62857143],\n",
       "        [0.63214286],\n",
       "        [0.63571429],\n",
       "        [0.63214286],\n",
       "        [0.63214286],\n",
       "        [0.63571429],\n",
       "        [0.63214286],\n",
       "        [0.63928571],\n",
       "        [0.64285714],\n",
       "        [0.64285714],\n",
       "        [0.65      ],\n",
       "        [0.65357143],\n",
       "        [0.65357143],\n",
       "        [0.65714286],\n",
       "        [0.66071429],\n",
       "        [0.66071429],\n",
       "        [0.66785714],\n",
       "        [0.67142857],\n",
       "        [0.67142857],\n",
       "        [0.675     ],\n",
       "        [0.675     ],\n",
       "        [0.67857143],\n",
       "        [0.67857143],\n",
       "        [0.68214286],\n",
       "        [0.68571429],\n",
       "        [0.68571429],\n",
       "        [0.69285714],\n",
       "        [0.68928571],\n",
       "        [0.68928571],\n",
       "        [0.68928571],\n",
       "        [0.69285714],\n",
       "        [0.69285714],\n",
       "        [0.69285714],\n",
       "        [0.69642857],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.69642857],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.69642857],\n",
       "        [0.69642857],\n",
       "        [0.69642857],\n",
       "        [0.69642857],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.7       ],\n",
       "        [0.70357143],\n",
       "        [0.70357143],\n",
       "        [0.70357143],\n",
       "        [0.70357143],\n",
       "        [0.70357143],\n",
       "        [0.70357143],\n",
       "        [0.70714286],\n",
       "        [0.70714286],\n",
       "        [0.70714286],\n",
       "        [0.70714286],\n",
       "        [0.70357143],\n",
       "        [0.70357143],\n",
       "        [0.7       ],\n",
       "        [0.70357143],\n",
       "        [0.70714286],\n",
       "        [0.70714286],\n",
       "        [0.70357143],\n",
       "        [0.70714286],\n",
       "        [0.70714286],\n",
       "        [0.71071429],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71428571],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.71785714],\n",
       "        [0.72142857],\n",
       "        [0.72857143],\n",
       "        [0.72857143],\n",
       "        [0.72857143],\n",
       "        [0.72857143],\n",
       "        [0.73214286],\n",
       "        [0.73214286],\n",
       "        [0.73214286],\n",
       "        [0.73214286],\n",
       "        [0.73214286],\n",
       "        [0.73214286],\n",
       "        [0.73214286],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73571429],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.73928571],\n",
       "        [0.74285714],\n",
       "        [0.74285714],\n",
       "        [0.74642857],\n",
       "        [0.74642857],\n",
       "        [0.75      ],\n",
       "        [0.75357143],\n",
       "        [0.75357143],\n",
       "        [0.75357143],\n",
       "        [0.75357143],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.75714286],\n",
       "        [0.76071429],\n",
       "        [0.76428571],\n",
       "        [0.76428571],\n",
       "        [0.76428571],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.76785714],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.77142857],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.78214286],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.775     ],\n",
       "        [0.77857143],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78571429],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.77857143],\n",
       "        [0.77857143],\n",
       "        [0.78214286],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78214286],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.79285714],\n",
       "        [0.79285714],\n",
       "        [0.79285714],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78928571],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78571429],\n",
       "        [0.78928571],\n",
       "        [0.78928571]]),\n",
       " 'AUC': array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " 'CSI': array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '4'\n",
    "import random\n",
    "from tools import *\n",
    "from Data_import import data_frame,read_seasonal_occurrence_prob_21_years\n",
    "from model_evaluation import *\n",
    "from ClusterNN import cluster_NN,svm_classifier\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "# Southern runway\n",
    "Data = data_frame()\n",
    "clusternn = cluster_NN()\n",
    "pilot_train_ = Data.pilot_semi_learning_generator(semi_ratio = 1)\n",
    "clusternn.train(Data,pilot_train_,train_steps = 500, BATCH_SIZE = 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871c7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Southern runway\n",
    "corridor_month_2017 = Data.read_data_month(year=2017)\n",
    "corridor_month_2018 = Data.read_data_month(year=2018)\n",
    "corridor_month_2019 = Data.read_data_month(year=2019)\n",
    "corridor_month_2020 = Data.read_data_month(year=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fabffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ae_ckpt\\model_encoder_encodedDim4_cluaterDim4.ckpt\n",
      "INFO:tensorflow:Restoring parameters from sdec_ckpt\\model_supervise.ckpt\n"
     ]
    }
   ],
   "source": [
    "corridor_months_south = []\n",
    "for i in range(12):\n",
    "    corridor_months_south.append(np.vstack((corridor_month_2017[i], corridor_month_2018[i], corridor_month_2019[i], corridor_month_2020[i])))\n",
    "hazard_factors_months_south = clusternn.seasonal_statistic_fit(Data,corridor_months_south,pilot_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672f6eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "def hazard_factor_ratio_cal(hazard_factors_months_i):\n",
    "    hazard_factors_months = []\n",
    "    for i in range(12):\n",
    "        hazard_factors_months = hazard_factors_months+list(hazard_factors_months_i[i])\n",
    "    hazard_factors_months = np.array(hazard_factors_months)\n",
    "    percentitle_value = (np.quantile(hazard_factors_months,0.90))\n",
    "    print(percentitle_value)\n",
    "    ratio_hazard_factor_extremes = []\n",
    "    for i in range(12):\n",
    "        ratio_hazard_factor_extremes.append(np.sum(hazard_factors_months_i[i]>percentitle_value)/hazard_factors_months_i[i].size)\n",
    "    return ratio_hazard_factor_extremes\n",
    "def correlation_heatmap(train):\n",
    "    correlations = train.corr(method='spearman')\n",
    "    cmap = sns.diverging_palette(220,20, center='light',as_cmap=True)\n",
    "    mask = np.zeros_like(correlations, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = False\n",
    "    sns.heatmap(correlations, mask=mask, cmap=cmap, fmt='.2f',\n",
    "    square=True, linewidths=.2, annot=True, vmax=0.99,cbar_kws={'shrink': .50,'extend':'both','pad':0.02}\n",
    "    )\n",
    "    plt.gca().add_patch(plt.Rectangle(xy=(0, 0),width=3,height=3,edgecolor='k',fill=False,linewidth=3))\n",
    "    plt.gca().add_patch(plt.Rectangle(xy=(3, 3),width=5,height=5,edgecolor='k',fill=False,linewidth=3))\n",
    "    plt.xticks([0.5,1.5],['21 years','2017~2020'])\n",
    "    plt.yticks([0.5,1.5],['21 years','2017~2020'])\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d4896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.709770977851136\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Occurrence_prob_21 = read_seasonal_occurrence_prob_21_years()\n",
    "\n",
    "plt.plot(range(1,13),Occurrence_prob_21.normalize(hazard_factor_ratio_cal(hazard_factors_months_south)),label='2017~2020',marker='.',alpha=0.6,linewidth=1.5,color=\"#fa625f\")\n",
    "plt.vlines([2.5,5.5,8.5,11.5],[-0.5,-0.5,-0.5,-0.5],[1.5,1.5,1.5,1.5],colors='C7',linewidth=0.5,alpha=0.5)\n",
    "plt.plot(range(1,13),Occurrence_prob_21.ratio_pilot_month_21_years_south[0],label='21-years',marker='.',color='#2E94B9',linewidth=1.5)\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend(frameon=False,ncol=2)\n",
    "# plt.show(block=True)\n",
    "plt.savefig(f'../figures/seasonal_occurrence_south.png',dpi=600)  #\n",
    "plt.savefig(f'../figures/seasonal_occurrence_south.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f54d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.709770977851136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD4CAYAAADRlDL+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWAklEQVR4nO3dfZRcdX3H8fdnN/vA5mGNkIQQ8kQMEBEiFBMIaRusoHAQpYVYqPZAhBzqwYdiW6utkFO0pVYptmlFpIhSQWIRIUQFpYk1WHlIUBMSEAp5EISQmJBsyCa7ybd/zN11EiY7s5ud38zOfl7n3JM7v/sw381kP/n97r1zryICM7NU6ipdgJkNLg4dM0vKoWNmSTl0zCwph46ZJTWk3G8gyafHzMosIlTpGkrlno6ZJVX2nk6XH180K9Vb2SGYvehhAOYsWFjhSqxUyxZcVekSesU9HTNLyqFjZkk5dMwsKYeOmSXl0DGzpBw6ZpaUQ8fMknLomFlSDh0zS8qhY2ZJOXTMLCmHjpkl5dAxs6QcOmaWlEPHzJJy6JhZUg4dM0vKoWNmSTl0zCwph46ZJeXQMbOkHDpmlpRDx8yScuiYWVIOHTNLyqFjZkk5dMwsKYeOmSXl0DGzpBw6ZpaUQ8fMknLomFlSDh0zS8qhY2ZJOXTMLCmHjpklVVLoSGqUVC+pSdJ7JR1R7sLMrDaV2tP5HvAm4DbgPcDV5SrIzGpbqaFzCzAKmBIRlwEvlq8kM6tlpYbOTuD9wPsl/Q5wWvlKMrNaNqTE9c4H5kfEvuz1+8tUj5nVuFJ7OmuB1q4Xkt5RnnLMrNaV2tP5AHC+pK6ezjjg2PKUZGa1rNTQeW9ErOt6IWl8ecoxs1pXaui8VdLfAPXZ6+OAM8pTkpnVslJD5y3AV4CJwArg3LJVZGY1rdQDyUcAe4EJwHTg8rJVZGY1rdTQuY1c8HyF3DU6XyhXQWZW20oNnWZgQkRsB5YC95evJDOrZaUe0/kI8KNs/gfAd4B3l6OgajJi2nQmXDiP1dd9dL/24ce+hRHHnQR1YtPSJXRs31awzdKbe/pb2bpzF8OaG7nn0VXd7bOPP4bWlmYA2js6eWjVLzll8tFcOmcGR4wYyo1LfsSjz26oVNmDSqk9ncXA89n8KcCp5Smnumxf+3PqGpte1z7pkit5YfEdbF7+QybMvfygbZbWiRPGMqKlmR/84mmGNTcxbdyY7mUXnjadJSvXsGTlGs49eRoALU2NfOSr3+bz9y3lz872ydhUSg2dF4D5kn4ILAE+XL6Sqkt0duz3unnseGLvXgB2b3mZEcdPL9hm6c2cOpH1r2wFYP0rW5k5dWL3sqdf3MRlZ87guKNG853Hcj2g5U89B8BTL77Mb9peS19wQsvnnhHL554Rla4DSg+d9cBFwCXAkRHxXz2tLGm+pMclPX6oBVabhuGtdO7c0f16yLDhBdssvdaWw2hr3w3Ans5O3jispXvZrUsf4aiRrVx51ix+sX7/myScNnUSdyxfkbTWwazU0LkW+BBweN6XPg8qIm6OiFMjouaGYR3bt1HX2Nz9Ojr2FGyz9Lbt3EVTQ+4wZUtTI9t3tXcvu/KsWdxw/zLu+skTXHPhO7vbW1uaaW4YwornfpW83lTyezjV0NspKXQiYl5E/BswUdI9ki6XNKzMtVUX1VHf3EL7S7+irrERgKbRR/HqmicKtll6jzyzjiljDgdg4qiRPPbsBoY25T6XSaPeyK49Hfz0mfXU1+X+2Tc3DGHm1Il894m11NeJEYc1H3Tf1n9KOnsl6Z3ANHK3tLiP3GnziyW1R8TtZayvolrGH0PzmHG0jJ9M06ixtE6bzrpvfImNd9/GuPMvoa6xiXV33gxQsM3SWr3xJU6efDTnnDyNtvY9tLXv5urz5nDd3Q+y6H9/xgUzTmLzjjYWr3iShvo6rv+Td9PS1MAfzZzO0KZGrvjyXZX+EfpdoZ7N8rlnxOxFD6sS9QAoonhvS9IG4DPA1yOiPWtrBNZFxFFFtg2AH18069CrtbKbvehhAOYsWFjhSqxUyxZcBVAwRA42nKpk6JR6nc7v5X/LHCAi9kg6pf9LMrN+U199D3wpKXQODJy89pf6tRoz61eqqy++UmKl9nTMbADSkIZKl/A6Dh2zGlaNPZ0+Dfgk+ZpxswFAQ4YUnCqpx3fPrihuB/KvdhNwNDC1jHWZWT+odMAUUqyiyyJi1YGNkiaXqR4z60fVOLzqMXQKBU7W/nyhdjOrLtXY0yl6TEfS70gal/d6tKRLy1qVmfUL1dUXnCqp2DGdhcA7gFXZVcnXRMQmSR8jdwtTM6ti1djTKVbRu4ATI2JX9gXPD0i6l/0PLJtZlRqI1+ms7JqJiDbgJknvAQ4va1Vm1i8qPZQqpFjozANmAQ91NUTEvZJ6/JKnmVWHATe8yno3DxVo/1LZKjKzfjMQezpmNoANuJ6OmQ1sqq++X/Hqq8jM+o3qPbwys4RUP/BOmZvZAKaBeudAMxuYBuLFgWY2gPmUuZkl1ddT5pI+DmwCWiNiYV7724EpwLHA1yJiddZ+D3A6sDgiruhp39U34DOzfqP6IQWnHreRZpN7mu/twEhJM7N2AX8bEV8BPgcszNrfBtwUEUcWCxxw6JjVNNXXF56k+ZIez5vm5212LrA2m1+TvQYYnU1ExCvAlCyIzgRukfQ1SS0U4dAxq2Ea0lBwioibI+LUvCn/sbRHAFuz+XbgyGx+C3C4pPGSGoCOyPkcMBnYDPx1sZp8TMeshvXxQPIrQFePZTi5sCEiOiVdAvwV8ALw464NsmWfAL5abOfu6ZjVsD4+DeK7wEnZ/JuBByS1AkTE0oj4MLmHM3wKuo/1QC6glhfbuXs6ZjWsL9fpRMTDks6UNA/Ylk03ARdLmkEuiP45Il7INlku6VFgNXBLsf07dMxqWF+v04mIzxzQdHHW/ijw6AHr9uo5eA4dsxrmW1uYWVq+ItnMUqpzT8fMUvLwyszS8vDKzFLy8MrM0nJPx8xS8k28zCypOj8NwsyS8tMgzCwlnzI3s6R8j2QzS8o9HTNLyj0dM0vKp8zNLKliT36ohOqryMz6jXzK3MxSck/HzJKqxp6OIqK8byAFQLnfx2yQU6HGHa9uK/iLN7z1DQXXT8E9HbMa1qm+9XR68yxzSccC7wNeI/cs81/2tO9koTNnwcLiK1nFLVtwFQDL5/bqBv9WQbMXPXzQZXv37ev1/vKeZf4FSZ+WNDMiHsl7lvnbJY0CvgXMAb4IXAR0AHcCf9jT/v2wPbMa1rl3X8GpH59lfhgwJSLaImI3MFlSj50ZD6/MatjefYWPpWbPLr+54MISnmUOvESuZzMS2J63bScwCvj1wWpy6JjVsM59e/uyWW+eZb4FaM7btoXcE0EPysMrsxp2sOFVESU/yzwbUq2X1CKpGdgYEbt62rl7OmY17GDDq5704VnmnyDX+9kNXF1s/w4dsxrWubdPw6vePst8NbC61H07dMxq2N4qvCjXoWNWw0o4fpOcQ8eshvXl4sByc+iY1bBOh46ZpeThlZkl5eGVmSXlno6ZJbU3HDpmlpB7OmaWlEPHzJLygWQzS8rX6ZhZUn35lnm5OXTMalhfv2VeTg4dsxrm4ZWZJeXhlZkl5eGVmSXlU+ZmlpQvDjSzpDocOmaW0j5/4dPMUuprT0fSx4FNQGtELMxrvwA4PHv5WkTckbX/CzAX+FlEvKunffthe2Y1bN++KDj1RNJs4PCIuB0YKWlm3uKPRsQtEXELMC9bfxzwREQcWSxwwKFjVtMO9oRPSfMlPZ43zc/b7FxgbTa/JnvdZYWkv5N0KvDvWdvbgU9Lul/SEcVqcuiY1bC9sa/gFBE3R8SpedPNeZsdAWzN5tuBI/OWfRqYAvwT8D8AWY9oCvAQcEOxmhw6ZjWsj88yfwVoyeaHA1vyln0OuBL4PPDNrsbI+WegsdjOSwodSRMlzZT0plLWN7Pq0MfQ+S5wUjb/ZuABSa3Z6xMiYkdELAEaACQp+7MReKzYzns8eyXpdOCTQJB7OPrwbMfXRsTyYjs3s8rqyz2SI+JhSWdKmgdsy6abyD3P/AuSPgy8AHw522SRpK3AE9l6PSp2ynx6RJx/YGP2pg4dsyrX1yuSI+IzBzRdnLXfX2Ddi3qz72LDq7EHDqkkHQOM7c2bmFll7N23r+BUScV6OguBv5d0drZuG7AMWFDessysPwy4715FxCvAFfltkloi4rWyVmVm/aIab+LV4/BK0imSFku6WdLxv21W0SPUZlZ5A3F4dTvwBXKnwc6RNC0i7snOkJlZlRtwwytgR0Tcms2vkjRF0h+SO4VuZlVuIN6u9EZJ746IxQAR8X+S2sguCjKz6ta5b4DdrjQivgkgqQ4YBWyLiJcl/UGK4szs0Ay44ZWkqcD1wCRgL9AiaQNwNfCbsldnZodkIA6vzgMujog9XQ2SmoGPAk+VszAzO3QDbngFDAXqC7Q3l6EWM+tnA7Gncxdwt6QpwKvAYcA64BNlrsvM+sGAO6YTEc8A52ZDqpHAlvyhlplVt0pfCFhIsSuSJ0r6V3IHjjsiYo+kUZLuS1OemdWaYsOr/wK+B6wCrpb0QET8SNJR5S+t8uae/la27tzFsOZG7nl0VXf77OOPobUld1irvaOTh1b9klMmH82lc2ZwxIih3LjkRzz67IZKlT2ojZg2nQkXzmP1dR/dr334sW9hxHEnQZ3YtHQJHdu3FWyrNcsWXKU5CxbGgW2VqgeK39qiLiKuiYjFEfEpYKekdwDV12frZydOGMuIlmZ+8IunGdbcxLRxY7qXXXjadJasXMOSlWs49+RpALQ0NfKRr36bz9+3lD87+4xKlT3obV/7c+oam17XPumSK3lh8R1sXv5DJsy9/KBtVn7FQufrkn6v60VEPE7uQPKIchZVDWZOncj6V3L3pl7/ylZmTp3YvezpFzdx2ZkzOO6o0XznsVwPaPlTzwHw1Isv85s2fwm/kqKzY7/XzWPHE3tzp453b3mZEcdPL9hWq/J7NpXu5UCR0ImILwI/B5B0gqT6iHiW/R9J8Tr5j7fov1LTam05jLb23QDs6ezkjcNaupfduvQRjhrZypVnzeIX61/cb7vTpk7ijuUrktZqPWsY3krnzh3dr4cMG16wzdIoemP2iHg1m30e+FjW9lyRbbofb3HIFVbItp27aGrIHfJqaWpk+6727mVXnjWLG+5fxl0/eYJrLnxnd3trSzPNDUNY8dyvktdrB9exfRt1jb+9tCw69hRsq2XLFlylaujlQO8eQbMHGFauQqrNI8+sY8qY3NNTJ44ayWPPbmBoU+7pGpNGvZFdezr46TPrqa/L/RU2Nwxh5tSJfPeJtdTXiRGH+frJilMd9c0ttL/0K+oac59d0+ijeHXNEwXbLI3ePMv8AuBb5Sqk2qze+BInTz6ac06eRlv7Htrad3P1eXO47u4HWfS/P+OCGSexeUcbi1c8SUN9Hdf/ybtpaWrgj2ZOZ2hTI1d8+a5K/wiDUsv4Y2geM46W8ZNpGjWW1mnTWfeNL7Hx7tsYd/4l1DU2se7O3HPlCrVZ+SmitMukJX0yIv6h128gBcDvX/uvvd3UKmDZgqsAWD7XZ+AGitmLHgaoiqFTKXozvFop6ZSyVWJmg0KxK5I/2PVA9Ih4ICJWpinLzGpVsWM6nwWOkDQaeA74dkT8uvxlmVmtKhY6r0XEP0Lue1jA+ySNA16IiBvLXZyZ1Z5iodN9xVRErAduBJA05mAbmJn1pNiB5Askve3Axoh4uUz1mFmNK3Y/neWpCjGzwaE3p8y7SfJFHGbWJ8WeBvE40E7uKxDdzcDRwNQy1mVmNarYgeTLImLVgY2SJpepHjOrccVubfG6wMnany9POWZW64p+4VPSXHL3zxkDbAG+D3wjSv3SlplZnmLHdP4CeBn4F3LHdoYDbwb+Guj1lz/NzIr1dDZHxO0HtD0iaV65CjKz2lYsdOol3QY8A2wFWoATgMfKXJeZ1ahiB5L/A1hI7tHCI4BtwLWA7zxuZn1S7NYWC4HbgZOAUcCdEbGB7F7JZma9VWx49S7gxIjYJWkY8AFJ97L/xYJmZiUr9jWI7pt2RURbRNwEzAAOL2tVZlazivV05gGzgIe6GiLi3sHyWGEz63/FvmXeRl7g5LV/qWwVmVlN69O3zM3M+sqhY2ZJOXTMLCmHjpkl5dAxs6QcOmaWlEPHzJJy6JhZUg4dM0vKoWNmSTl0zCwph46ZJeXQMbOkHDpmlpRDx8yScuiYWVIOHTNLyqFjZkk5dMwsKYeOmSXl0DGzpBw6ZpaUQ8fMknLomFlSDh0zS8qhY2ZJOXTMLCmHjpklpYgo7xtIAVDu9zEb5FTpAkpV9tCpZZLmR8TNla7DSuPPqzp4eHVo5le6AOsVf15VwKFjZkk5dMwsKYfOofHxgYHFn1cV8IFkM0vKPR0zS8qhY2ZJOXTMLKlBGzqShkv6lqTnJP17XvtJklZUsrbBrtBnI+lySZdJ+ktJdVnbfp+VpN+VtFnSOkkvS7qih/f4mKSVklZImpy1HSvp05I+LunYrO1iSY9IWivp1KxttKS/k/QhSbPK+XdRkyJiUE7AWcBQoAV4Gnhb3rKfVLq+wTwV+myAr2fL/hR4X6HPCpjJb0+OfBIYfZD9vwGYk81fB/xbNv89YBjQBHyb3FcL3pMt+yCwJJu/BTg2m1/c9Z6eSpsGbU8nIn4QETsj4jVgNfBS3uI9B64vabKkjZLOyV5/NWv7fUmXSLpT0ixJJ0v6oqRrJF2QrfPz7H/oWyW9J1t/qaTmRD/ugFLgszkXeCZb/GT2usuevO0eiSwJgFERsekg+98WEcuyl48Bv5Z0GDAlItoiYjcwGaiPiHvz18vmz86rB2BSH37MQWvQhk4XScOBDRGxsaf1IuJ54LPANEkCVgLrgY8AvwH+BzgROBL4T+AB4Lxsu+3ArcAV5H5hNgIfAvaW42eqFV2fDdABbM2a28n9Hfe03STg+Wz+XZI+Jel9khokDZX0lrzVTyd3/c5Icp9Tl05gVN7rdwA3ZPMNeeFWtB7b35BKF1AFPgBcU+K6XwOWA2uB/yb3j/INEfF9gOxYw3By4bIBqM+22xsRW7J1biAXSs8Bl5L7hbLCuj6bPyYXCpD7+91SZLsLgEXZ/OaI+HtJJwB/A+wEbgSQ9DbgwYjYJKkJyO95tgDbsvXeBKyPiDXZsra89Uqpx/IM6p6OpPcC34mIHZLGFFs/InYB9wFXRsSTwGZguqQZkoYA7yT3D/t54GAHo4cDM4BdwDmH/lPUpvzPBngQOCFb9Gbg+0U2HxcRLwBExOPZn09GxIKI+KeI6JA0ldx/GEsljSY3TFsvqSUb9m6MiF3Zv4vpEXG3pGGShgLLsiACaIqIX/bnz17rBm1PR9KHgL8EtkhqJPe/362SjgHGS/rdiPhxgU2/QTa2j4i92X7uIxcyf0qu93MtuYONx0maABwt6eyIeBD4c+Cn5I4hLS/nzzhQHeSzeUzSB8kNZa7P1nvdZyXpSODFIvufAtwP7JB0PfDriDhP0ieAvwJ2A1dLOpzcMLlT0ifJHVg+ldzn+2FJL2Xz1gv+GkQvZL8AlwLfjIjtRVY3swIG9fCqNySNJXfgeLcDx6zv3NMxs6Tc0zGzpBw6ZpaUQ8fMknLomFlSDh0zS+r/AbCGXT5vHWW/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Occurrence_prob_21 = read_seasonal_occurrence_prob_21_years()\n",
    "df = np.vstack((Occurrence_prob_21.ratio_pilot_month_21_years_south[0],hazard_factor_ratio_cal(hazard_factors_months_south))).T\n",
    "df = pd.DataFrame(df)\n",
    "correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f082de",
   "metadata": {},
   "source": [
    "Northern runway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adfb7c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1766: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '4'\n",
    "import random\n",
    "from tools import *\n",
    "from Data_import import data_frame,read_seasonal_occurrence_prob_21_years\n",
    "from model_evaluation import *\n",
    "from ClusterNN import cluster_NN,svm_classifier\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "# Northern runway\n",
    "Data = data_frame()\n",
    "clusternn = cluster_NN()\n",
    "Data.read_data_for_transfer_learning()\n",
    "corridor_month_2020_transfer = Data.read_data_month_transfer(year=2020)\n",
    "corridor_month_2021_transfer = Data.read_data_month_transfer(year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38541cc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ae_ckpt\\model_encoder_encodedDim4_cluaterDim4.ckpt\n",
      "INFO:tensorflow:Restoring parameters from sdec_ckpt\\model_supervise.ckpt\n",
      "0, total loss = -1.780018925666809, reconstruct loss = 0.10521600395441055, cluster loss = 0.04433736950159073, calm loss = 0.6168895959854126, pilot loss = 5.273406982421875, max interval = -13.404990196228027, \n",
      "Train ACC: 0.9, PTA: 0.4287109375, Test ACC: 0.7419354838709677\n",
      "1, total loss = -1.808419942855835, reconstruct loss = 0.10295084863901138, cluster loss = 0.044317230582237244, calm loss = 0.6218396425247192, pilot loss = 5.287709712982178, max interval = -13.469799995422363, \n",
      "Train ACC: 0.9, PTA: 0.392578125, Test ACC: 0.7419354838709677\n",
      "2, total loss = -1.8418176174163818, reconstruct loss = 0.10636231303215027, cluster loss = 0.04321380332112312, calm loss = 0.6197491884231567, pilot loss = 5.296112060546875, max interval = -13.529824256896973, \n",
      "Train ACC: 0.9, PTA: 0.388671875, Test ACC: 0.7419354838709677\n",
      "3, total loss = -1.8758671283721924, reconstruct loss = 0.10023058950901031, cluster loss = 0.044111400842666626, calm loss = 0.6205331683158875, pilot loss = 5.310554504394531, max interval = -13.592742919921875, \n",
      "Train ACC: 0.9, PTA: 0.3701171875, Test ACC: 0.7419354838709677\n",
      "4, total loss = -1.9044241905212402, reconstruct loss = 0.09964130073785782, cluster loss = 0.043895281851291656, calm loss = 0.6215031147003174, pilot loss = 5.327150821685791, max interval = -13.65749740600586, \n",
      "Train ACC: 0.9, PTA: 0.376953125, Test ACC: 0.7419354838709677\n",
      "5, total loss = -1.9321446418762207, reconstruct loss = 0.09951669722795486, cluster loss = 0.0442693866789341, calm loss = 0.6220028400421143, pilot loss = 5.344136714935303, max interval = -13.722455978393555, \n",
      "Train ACC: 0.9, PTA: 0.396484375, Test ACC: 0.7419354838709677\n",
      "6, total loss = -1.966613531112671, reconstruct loss = 0.09364864230155945, cluster loss = 0.043206606060266495, calm loss = 0.6223043203353882, pilot loss = 5.361687660217285, max interval = -13.787330627441406, \n",
      "Train ACC: 0.9, PTA: 0.3876953125, Test ACC: 0.7419354838709677\n",
      "7, total loss = -1.9892690181732178, reconstruct loss = 0.09757623821496964, cluster loss = 0.04327721148729324, calm loss = 0.6232597827911377, pilot loss = 5.379032135009766, max interval = -13.85158920288086, \n",
      "Train ACC: 0.9, PTA: 0.3994140625, Test ACC: 0.7419354838709677\n",
      "8, total loss = -2.0153274536132812, reconstruct loss = 0.09932743012905121, cluster loss = 0.04327237606048584, calm loss = 0.6233545541763306, pilot loss = 5.3962554931640625, max interval = -13.916092872619629, \n",
      "Train ACC: 0.9, PTA: 0.38671875, Test ACC: 0.7419354838709677\n",
      "9, total loss = -2.05354905128479, reconstruct loss = 0.089344821870327, cluster loss = 0.04280702769756317, calm loss = 0.6232113838195801, pilot loss = 5.413176536560059, max interval = -13.979784965515137, \n",
      "Train ACC: 0.9, PTA: 0.3798828125, Test ACC: 0.7419354838709677\n",
      "10, total loss = -2.069373607635498, reconstruct loss = 0.09907744079828262, cluster loss = 0.04422423616051674, calm loss = 0.6234315633773804, pilot loss = 5.429986000061035, max interval = -14.04269790649414, \n",
      "Train ACC: 0.9, PTA: 0.4091796875, Test ACC: 0.7419354838709677\n",
      "11, total loss = -2.092881917953491, reconstruct loss = 0.10491763055324554, cluster loss = 0.04264958202838898, calm loss = 0.6227989196777344, pilot loss = 5.4426655769348145, max interval = -14.09963607788086, \n",
      "Train ACC: 0.9, PTA: 0.3955078125, Test ACC: 0.7419354838709677\n",
      "12, total loss = -2.1276907920837402, reconstruct loss = 0.09613731503486633, cluster loss = 0.04379279166460037, calm loss = 0.6222759485244751, pilot loss = 5.45221471786499, max interval = -14.151400566101074, \n",
      "Train ACC: 0.9, PTA: 0.376953125, Test ACC: 0.7419354838709677\n",
      "13, total loss = -2.1634421348571777, reconstruct loss = 0.08782443404197693, cluster loss = 0.04317460209131241, calm loss = 0.622773289680481, pilot loss = 5.462778091430664, max interval = -14.205570220947266, \n",
      "Train ACC: 0.9, PTA: 0.359375, Test ACC: 0.7419354838709677\n",
      "14, total loss = -2.1848325729370117, reconstruct loss = 0.09450700134038925, cluster loss = 0.042429011315107346, calm loss = 0.6235845685005188, pilot loss = 5.474173069000244, max interval = -14.262102127075195, \n",
      "Train ACC: 0.9, PTA: 0.36328125, Test ACC: 0.7419354838709677\n",
      "15, total loss = -2.2086191177368164, reconstruct loss = 0.09645643830299377, cluster loss = 0.044159624725580215, calm loss = 0.6248653531074524, pilot loss = 5.486320495605469, max interval = -14.320575714111328, \n",
      "Train ACC: 0.9, PTA: 0.4033203125, Test ACC: 0.7419354838709677\n",
      "16, total loss = -2.238650321960449, reconstruct loss = 0.09567282348871231, cluster loss = 0.04261576011776924, calm loss = 0.6264714002609253, pilot loss = 5.49929666519165, max interval = -14.381038665771484, \n",
      "Train ACC: 0.8, PTA: 0.3603515625, Test ACC: 0.7419354838709677\n",
      "17, total loss = -2.2666306495666504, reconstruct loss = 0.09538565576076508, cluster loss = 0.04174773395061493, calm loss = 0.6285251379013062, pilot loss = 5.513545036315918, max interval = -14.442704200744629, \n",
      "Train ACC: 0.8, PTA: 0.38671875, Test ACC: 0.7419354838709677\n",
      "18, total loss = -2.296722650527954, reconstruct loss = 0.08993528038263321, cluster loss = 0.04326144978404045, calm loss = 0.6307864189147949, pilot loss = 5.529879093170166, max interval = -14.506689071655273, \n",
      "Train ACC: 0.8, PTA: 0.35546875, Test ACC: 0.7419354838709677\n",
      "19, total loss = -2.3154048919677734, reconstruct loss = 0.09686123579740524, cluster loss = 0.04306485503911972, calm loss = 0.6333844661712646, pilot loss = 5.548188209533691, max interval = -14.572915077209473, \n",
      "Train ACC: 0.8, PTA: 0.37109375, Test ACC: 0.7419354838709677\n",
      "20, total loss = -2.337571620941162, reconstruct loss = 0.1008782908320427, cluster loss = 0.043191954493522644, calm loss = 0.6351320147514343, pilot loss = 5.566773414611816, max interval = -14.639603614807129, \n",
      "Train ACC: 0.8, PTA: 0.3837890625, Test ACC: 0.7419354838709677\n",
      "21, total loss = -2.3691792488098145, reconstruct loss = 0.09531759470701218, cluster loss = 0.04267323017120361, calm loss = 0.6366726756095886, pilot loss = 5.581563949584961, max interval = -14.699459075927734, \n",
      "Train ACC: 0.8, PTA: 0.3720703125, Test ACC: 0.7419354838709677\n",
      "22, total loss = -2.3982534408569336, reconstruct loss = 0.09217450767755508, cluster loss = 0.04241039603948593, calm loss = 0.6378036737442017, pilot loss = 5.595826625823975, max interval = -14.75817584991455, \n",
      "Train ACC: 0.8, PTA: 0.3583984375, Test ACC: 0.7419354838709677\n",
      "23, total loss = -2.433858871459961, reconstruct loss = 0.08325596898794174, cluster loss = 0.04265521839261055, calm loss = 0.6381887197494507, pilot loss = 5.609461784362793, max interval = -14.816737174987793, \n",
      "Train ACC: 0.8, PTA: 0.3447265625, Test ACC: 0.7419354838709677\n",
      "24, total loss = -2.4497551918029785, reconstruct loss = 0.09181918948888779, cluster loss = 0.043742988258600235, calm loss = 0.639151930809021, pilot loss = 5.624353885650635, max interval = -14.875940322875977, \n",
      "Train ACC: 0.8, PTA: 0.3583984375, Test ACC: 0.7419354838709677\n",
      "25, total loss = -2.473875045776367, reconstruct loss = 0.09273490309715271, cluster loss = 0.044029586017131805, calm loss = 0.640608012676239, pilot loss = 5.640468597412109, max interval = -14.937274932861328, \n",
      "Train ACC: 0.8, PTA: 0.3642578125, Test ACC: 0.7419354838709677\n",
      "26, total loss = -2.497432231903076, reconstruct loss = 0.09546536952257156, cluster loss = 0.042926233261823654, calm loss = 0.6424742937088013, pilot loss = 5.65701961517334, max interval = -14.999621391296387, \n",
      "Train ACC: 0.8, PTA: 0.3701171875, Test ACC: 0.7419354838709677\n",
      "27, total loss = -2.527172565460205, reconstruct loss = 0.0912855714559555, cluster loss = 0.04271406680345535, calm loss = 0.6441953778266907, pilot loss = 5.671180725097656, max interval = -15.058584213256836, \n",
      "Train ACC: 0.8, PTA: 0.345703125, Test ACC: 0.7419354838709677\n",
      "28, total loss = -2.5444560050964355, reconstruct loss = 0.09775537997484207, cluster loss = 0.043590232729911804, calm loss = 0.6457700729370117, pilot loss = 5.68485164642334, max interval = -15.115608215332031, \n",
      "Train ACC: 0.8, PTA: 0.3662109375, Test ACC: 0.7419354838709677\n",
      "29, total loss = -2.5806097984313965, reconstruct loss = 0.08870897442102432, cluster loss = 0.041194189339876175, calm loss = 0.64691561460495, pilot loss = 5.698184013366699, max interval = -15.171655654907227, \n",
      "Train ACC: 0.8, PTA: 0.3466796875, Test ACC: 0.7419354838709677\n",
      "30, total loss = -2.5973243713378906, reconstruct loss = 0.09585694223642349, cluster loss = 0.041867695748806, calm loss = 0.6478276252746582, pilot loss = 5.712498188018799, max interval = -15.228521347045898, \n",
      "Train ACC: 0.8, PTA: 0.369140625, Test ACC: 0.7419354838709677\n",
      "31, total loss = -2.6255853176116943, reconstruct loss = 0.09198076277971268, cluster loss = 0.04202376678586006, calm loss = 0.649069607257843, pilot loss = 5.727849960327148, max interval = -15.287349700927734, \n",
      "Train ACC: 0.8, PTA: 0.3486328125, Test ACC: 0.7419354838709677\n",
      "32, total loss = -2.639883518218994, reconstruct loss = 0.10123652219772339, cluster loss = 0.04319052770733833, calm loss = 0.6503738164901733, pilot loss = 5.743619918823242, max interval = -15.34712028503418, \n",
      "Train ACC: 0.8, PTA: 0.37109375, Test ACC: 0.7419354838709677\n",
      "33, total loss = -2.667120933532715, reconstruct loss = 0.09935755282640457, cluster loss = 0.041798271238803864, calm loss = 0.6516130566596985, pilot loss = 5.759178161621094, max interval = -15.405418395996094, \n",
      "Train ACC: 0.8, PTA: 0.3388671875, Test ACC: 0.7419354838709677\n",
      "34, total loss = -2.702662467956543, reconstruct loss = 0.08622007071971893, cluster loss = 0.0437520369887352, calm loss = 0.652229368686676, pilot loss = 5.774194240570068, max interval = -15.462613105773926, \n",
      "Train ACC: 0.8, PTA: 0.3525390625, Test ACC: 0.7419354838709677\n",
      "35, total loss = -2.7131924629211426, reconstruct loss = 0.09971994906663895, cluster loss = 0.04347987845540047, calm loss = 0.6531032919883728, pilot loss = 5.786566734313965, max interval = -15.515544891357422, \n",
      "Train ACC: 0.8, PTA: 0.3583984375, Test ACC: 0.7419354838709677\n",
      "36, total loss = -2.7433605194091797, reconstruct loss = 0.09517179429531097, cluster loss = 0.04200010001659393, calm loss = 0.6540529131889343, pilot loss = 5.799665927886963, max interval = -15.570169448852539, \n",
      "Train ACC: 0.8, PTA: 0.3486328125, Test ACC: 0.7419354838709677\n",
      "37, total loss = -2.768244743347168, reconstruct loss = 0.09324364364147186, cluster loss = 0.043084144592285156, calm loss = 0.6547629833221436, pilot loss = 5.8125200271606445, max interval = -15.623961448669434, \n",
      "Train ACC: 0.8, PTA: 0.3662109375, Test ACC: 0.7419354838709677\n",
      "38, total loss = -2.7861766815185547, reconstruct loss = 0.10021329671144485, cluster loss = 0.041802503168582916, calm loss = 0.6552308797836304, pilot loss = 5.825059413909912, max interval = -15.676360130310059, \n",
      "Train ACC: 0.8, PTA: 0.3662109375, Test ACC: 0.7419354838709677\n",
      "39, total loss = -2.8187971115112305, reconstruct loss = 0.09060955792665482, cluster loss = 0.04302864521741867, calm loss = 0.655370831489563, pilot loss = 5.8351287841796875, max interval = -15.7256498336792, \n",
      "Train ACC: 0.8, PTA: 0.328125, Test ACC: 0.7419354838709677\n",
      "40, total loss = -2.8371925354003906, reconstruct loss = 0.09534552693367004, cluster loss = 0.04323945194482803, calm loss = 0.6562181711196899, pilot loss = 5.844371795654297, max interval = -15.77348518371582, \n",
      "Train ACC: 0.8, PTA: 0.361328125, Test ACC: 0.7419354838709677\n",
      "41, total loss = -2.8611645698547363, reconstruct loss = 0.09471969306468964, cluster loss = 0.043655671179294586, calm loss = 0.656894326210022, pilot loss = 5.853407382965088, max interval = -15.821380615234375, \n",
      "Train ACC: 0.8, PTA: 0.359375, Test ACC: 0.7419354838709677\n",
      "42, total loss = -2.8878870010375977, reconstruct loss = 0.09368158131837845, cluster loss = 0.042211830615997314, calm loss = 0.6574231386184692, pilot loss = 5.862681865692139, max interval = -15.870092391967773, \n",
      "Train ACC: 0.8, PTA: 0.3349609375, Test ACC: 0.7419354838709677\n",
      "43, total loss = -2.914039373397827, reconstruct loss = 0.09109330177307129, cluster loss = 0.04301619529724121, calm loss = 0.6578677892684937, pilot loss = 5.872799873352051, max interval = -15.92007064819336, \n",
      "Train ACC: 0.8, PTA: 0.33984375, Test ACC: 0.7419354838709677\n",
      "44, total loss = -2.9346799850463867, reconstruct loss = 0.09539765864610672, cluster loss = 0.04209524765610695, calm loss = 0.6589102149009705, pilot loss = 5.884317874908447, max interval = -15.972412109375, \n",
      "Train ACC: 0.8, PTA: 0.3408203125, Test ACC: 0.7419354838709677\n",
      "45, total loss = -2.9637701511383057, reconstruct loss = 0.09222954511642456, cluster loss = 0.040612172335386276, calm loss = 0.6592127084732056, pilot loss = 5.895013332366943, max interval = -16.02311134338379, \n",
      "Train ACC: 0.8, PTA: 0.3134765625, Test ACC: 0.7419354838709677\n",
      "46, total loss = -2.9881937503814697, reconstruct loss = 0.09177249670028687, cluster loss = 0.04141285642981529, calm loss = 0.6592132449150085, pilot loss = 5.902956485748291, max interval = -16.069917678833008, \n",
      "Train ACC: 0.8, PTA: 0.3271484375, Test ACC: 0.7419354838709677\n",
      "47, total loss = -3.011977434158325, reconstruct loss = 0.09169189631938934, cluster loss = 0.041721731424331665, calm loss = 0.6596498489379883, pilot loss = 5.910876274108887, max interval = -16.116235733032227, \n",
      "Train ACC: 0.8, PTA: 0.330078125, Test ACC: 0.7419354838709677\n",
      "48, total loss = -3.0364980697631836, reconstruct loss = 0.09138868749141693, cluster loss = 0.04171307384967804, calm loss = 0.6597397923469543, pilot loss = 5.918583869934082, max interval = -16.16203498840332, \n",
      "Train ACC: 0.8, PTA: 0.3349609375, Test ACC: 0.7419354838709677\n",
      "49, total loss = -3.0573949813842773, reconstruct loss = 0.0950317308306694, cluster loss = 0.04147735610604286, calm loss = 0.6596100926399231, pilot loss = 5.926328659057617, max interval = -16.20771026611328, \n",
      "Train ACC: 0.8, PTA: 0.3330078125, Test ACC: 0.7419354838709677\n",
      "50, total loss = -3.078279972076416, reconstruct loss = 0.09778720140457153, cluster loss = 0.0423470139503479, calm loss = 0.659363865852356, pilot loss = 5.935461044311523, max interval = -16.255495071411133, \n",
      "Train ACC: 0.8, PTA: 0.333984375, Test ACC: 0.7419354838709677\n",
      "51, total loss = -3.11214017868042, reconstruct loss = 0.08935266733169556, cluster loss = 0.04154514521360397, calm loss = 0.6597636938095093, pilot loss = 5.94759464263916, max interval = -16.308652877807617, \n",
      "Train ACC: 0.8, PTA: 0.314453125, Test ACC: 0.7419354838709677\n",
      "52, total loss = -3.1346938610076904, reconstruct loss = 0.08997316658496857, cluster loss = 0.04319821298122406, calm loss = 0.6604528427124023, pilot loss = 5.960549831390381, max interval = -16.36368751525879, \n",
      "Train ACC: 0.8, PTA: 0.32421875, Test ACC: 0.7419354838709677\n",
      "53, total loss = -3.15653657913208, reconstruct loss = 0.09333688020706177, cluster loss = 0.040981195867061615, calm loss = 0.6616710424423218, pilot loss = 5.973615646362305, max interval = -16.417011260986328, \n",
      "Train ACC: 0.8, PTA: 0.328125, Test ACC: 0.7419354838709677\n",
      "54, total loss = -3.1840732097625732, reconstruct loss = 0.08993910253047943, cluster loss = 0.042945779860019684, calm loss = 0.660749614238739, pilot loss = 5.982607841491699, max interval = -16.465909957885742, \n",
      "Train ACC: 0.8, PTA: 0.330078125, Test ACC: 0.7419354838709677\n",
      "55, total loss = -3.205566883087158, reconstruct loss = 0.09405206888914108, cluster loss = 0.041452907025814056, calm loss = 0.6604094505310059, pilot loss = 5.988829135894775, max interval = -16.508838653564453, \n",
      "Train ACC: 0.8, PTA: 0.3388671875, Test ACC: 0.7419354838709677\n",
      "56, total loss = -3.234311580657959, reconstruct loss = 0.0902339294552803, cluster loss = 0.040718261152505875, calm loss = 0.6606386303901672, pilot loss = 5.997898101806641, max interval = -16.556760787963867, \n",
      "Train ACC: 0.8, PTA: 0.3212890625, Test ACC: 0.7419354838709677\n",
      "57, total loss = -3.255871295928955, reconstruct loss = 0.09192632883787155, cluster loss = 0.04179409146308899, calm loss = 0.661282479763031, pilot loss = 6.009289741516113, max interval = -16.608787536621094, \n",
      "Train ACC: 0.8, PTA: 0.3076171875, Test ACC: 0.7419354838709677\n",
      "58, total loss = -3.270918369293213, reconstruct loss = 0.10072250664234161, cluster loss = 0.04222601652145386, calm loss = 0.6622411012649536, pilot loss = 6.021665573120117, max interval = -16.662595748901367, \n",
      "Train ACC: 0.8, PTA: 0.349609375, Test ACC: 0.7419354838709677\n",
      "59, total loss = -3.3048605918884277, reconstruct loss = 0.091578409075737, cluster loss = 0.042527709156274796, calm loss = 0.6624513864517212, pilot loss = 6.034198760986328, max interval = -16.716737747192383, \n",
      "Train ACC: 0.8, PTA: 0.3232421875, Test ACC: 0.7419354838709677\n",
      "60, total loss = -3.3363232612609863, reconstruct loss = 0.08562306314706802, cluster loss = 0.04204844683408737, calm loss = 0.6623979210853577, pilot loss = 6.046740531921387, max interval = -16.770414352416992, \n",
      "Train ACC: 0.8, PTA: 0.3134765625, Test ACC: 0.7419354838709677\n",
      "61, total loss = -3.3583474159240723, reconstruct loss = 0.08994144946336746, cluster loss = 0.04064936935901642, calm loss = 0.6624298095703125, pilot loss = 6.059600353240967, max interval = -16.824548721313477, \n",
      "Train ACC: 0.8, PTA: 0.3203125, Test ACC: 0.7419354838709677\n",
      "62, total loss = -3.3933422565460205, reconstruct loss = 0.08075737208127975, cluster loss = 0.04023656249046326, calm loss = 0.6624616384506226, pilot loss = 6.072843551635742, max interval = -16.879878997802734, \n",
      "Train ACC: 0.8, PTA: 0.28125, Test ACC: 0.7419354838709677\n",
      "63, total loss = -3.410123348236084, reconstruct loss = 0.08984643965959549, cluster loss = 0.0407557338476181, calm loss = 0.6629254221916199, pilot loss = 6.0854010581970215, max interval = -16.936264038085938, \n",
      "Train ACC: 0.8, PTA: 0.328125, Test ACC: 0.7419354838709677\n",
      "64, total loss = -3.4294567108154297, reconstruct loss = 0.09614818543195724, cluster loss = 0.041686490178108215, calm loss = 0.6634103059768677, pilot loss = 6.096991062164307, max interval = -16.991548538208008, \n",
      "Train ACC: 0.8, PTA: 0.3369140625, Test ACC: 0.7419354838709677\n",
      "65, total loss = -3.4590768814086914, reconstruct loss = 0.09311076998710632, cluster loss = 0.04233246296644211, calm loss = 0.663873016834259, pilot loss = 6.106985092163086, max interval = -17.04547119140625, \n",
      "Train ACC: 0.8, PTA: 0.3232421875, Test ACC: 0.7419354838709677\n",
      "66, total loss = -3.4934630393981934, reconstruct loss = 0.08691876381635666, cluster loss = 0.04126454144716263, calm loss = 0.6641063690185547, pilot loss = 6.115384101867676, max interval = -17.096641540527344, \n",
      "Train ACC: 0.8, PTA: 0.3173828125, Test ACC: 0.7419354838709677\n",
      "67, total loss = -3.518688201904297, reconstruct loss = 0.08814146369695663, cluster loss = 0.041046686470508575, calm loss = 0.6643294095993042, pilot loss = 6.124955177307129, max interval = -17.148191452026367, \n",
      "Train ACC: 0.8, PTA: 0.302734375, Test ACC: 0.7419354838709677\n",
      "68, total loss = -3.544100046157837, reconstruct loss = 0.08811390399932861, cluster loss = 0.040457434952259064, calm loss = 0.6651991009712219, pilot loss = 6.138693809509277, max interval = -17.204570770263672, \n",
      "Train ACC: 0.8, PTA: 0.306640625, Test ACC: 0.7419354838709677\n",
      "69, total loss = -3.567474126815796, reconstruct loss = 0.08850914984941483, cluster loss = 0.04189879447221756, calm loss = 0.6654065251350403, pilot loss = 6.149988174438477, max interval = -17.257104873657227, \n",
      "Train ACC: 0.8, PTA: 0.3154296875, Test ACC: 0.7419354838709677\n",
      "70, total loss = -3.595261812210083, reconstruct loss = 0.08732154965400696, cluster loss = 0.040411632508039474, calm loss = 0.6650794744491577, pilot loss = 6.160098075866699, max interval = -17.307044982910156, \n",
      "Train ACC: 0.8, PTA: 0.296875, Test ACC: 0.7419354838709677\n",
      "71, total loss = -3.613344430923462, reconstruct loss = 0.0926324725151062, cluster loss = 0.041567444801330566, calm loss = 0.6655367612838745, pilot loss = 6.17189359664917, max interval = -17.359708786010742, \n",
      "Train ACC: 0.8, PTA: 0.314453125, Test ACC: 0.7419354838709677\n",
      "72, total loss = -3.6463050842285156, reconstruct loss = 0.08511166274547577, cluster loss = 0.041508473455905914, calm loss = 0.6664971113204956, pilot loss = 6.186067581176758, max interval = -17.417678833007812, \n",
      "Train ACC: 0.8, PTA: 0.3046875, Test ACC: 0.7419354838709677\n",
      "73, total loss = -3.673464775085449, reconstruct loss = 0.0830470621585846, cluster loss = 0.0413527674973011, calm loss = 0.6684078574180603, pilot loss = 6.202156066894531, max interval = -17.479110717773438, \n",
      "Train ACC: 0.8, PTA: 0.2783203125, Test ACC: 0.7419354838709677\n",
      "74, total loss = -3.6937294006347656, reconstruct loss = 0.0876666009426117, cluster loss = 0.04182223230600357, calm loss = 0.6699684858322144, pilot loss = 6.217223167419434, max interval = -17.5391788482666, \n",
      "Train ACC: 0.8, PTA: 0.3232421875, Test ACC: 0.7419354838709677\n",
      "75, total loss = -3.728811502456665, reconstruct loss = 0.08094100654125214, cluster loss = 0.03879360482096672, calm loss = 0.6711996793746948, pilot loss = 6.231775283813477, max interval = -17.598003387451172, \n",
      "Train ACC: 0.8, PTA: 0.2568359375, Test ACC: 0.7419354838709677\n",
      "76, total loss = -3.747863531112671, reconstruct loss = 0.08571889996528625, cluster loss = 0.04112466052174568, calm loss = 0.6720502972602844, pilot loss = 6.246368408203125, max interval = -17.657533645629883, \n",
      "Train ACC: 0.8, PTA: 0.2978515625, Test ACC: 0.7419354838709677\n",
      "77, total loss = -3.765404224395752, reconstruct loss = 0.09384363889694214, cluster loss = 0.04229933023452759, calm loss = 0.6725977063179016, pilot loss = 6.261229038238525, max interval = -17.71798324584961, \n",
      "Train ACC: 0.8, PTA: 0.3173828125, Test ACC: 0.7419354838709677\n",
      "78, total loss = -3.7929162979125977, reconstruct loss = 0.09335304796695709, cluster loss = 0.042146336287260056, calm loss = 0.6730954051017761, pilot loss = 6.276219367980957, max interval = -17.778587341308594, \n",
      "Train ACC: 0.8, PTA: 0.310546875, Test ACC: 0.7419354838709677\n",
      "79, total loss = -3.8272054195404053, reconstruct loss = 0.08714152872562408, cluster loss = 0.039556629955768585, calm loss = 0.674808919429779, pilot loss = 6.291788101196289, max interval = -17.839784622192383, \n",
      "Train ACC: 0.8, PTA: 0.28515625, Test ACC: 0.7419354838709677\n",
      "80, total loss = -3.8539481163024902, reconstruct loss = 0.08632070571184158, cluster loss = 0.04093353822827339, calm loss = 0.6757297515869141, pilot loss = 6.305643081665039, max interval = -17.89999008178711, \n",
      "Train ACC: 0.8, PTA: 0.310546875, Test ACC: 0.7419354838709677\n",
      "81, total loss = -3.8806955814361572, reconstruct loss = 0.08491892367601395, cluster loss = 0.04180576279759407, calm loss = 0.6773380041122437, pilot loss = 6.3202362060546875, max interval = -17.9606876373291, \n",
      "Train ACC: 0.8, PTA: 0.2744140625, Test ACC: 0.7419354838709677\n",
      "82, total loss = -3.904252052307129, reconstruct loss = 0.08800014853477478, cluster loss = 0.040563806891441345, calm loss = 0.6798217296600342, pilot loss = 6.3372673988342285, max interval = -18.024944305419922, \n",
      "Train ACC: 0.8, PTA: 0.3125, Test ACC: 0.7419354838709677\n",
      "83, total loss = -3.922306537628174, reconstruct loss = 0.09396053105592728, cluster loss = 0.04230370745062828, calm loss = 0.6813217997550964, pilot loss = 6.350198268890381, max interval = -18.08245277404785, \n",
      "Train ACC: 0.8, PTA: 0.314453125, Test ACC: 0.7419354838709677\n",
      "84, total loss = -3.9562525749206543, reconstruct loss = 0.08654870092868805, cluster loss = 0.04129251465201378, calm loss = 0.6825973391532898, pilot loss = 6.364287853240967, max interval = -18.14096450805664, \n",
      "Train ACC: 0.8, PTA: 0.287109375, Test ACC: 0.7419354838709677\n",
      "85, total loss = -3.9720935821533203, reconstruct loss = 0.09658180177211761, cluster loss = 0.0418429970741272, calm loss = 0.6837204098701477, pilot loss = 6.3797101974487305, max interval = -18.202451705932617, \n",
      "Train ACC: 0.8, PTA: 0.310546875, Test ACC: 0.7419354838709677\n",
      "86, total loss = -4.003423690795898, reconstruct loss = 0.09099366515874863, cluster loss = 0.0421314500272274, calm loss = 0.6848150491714478, pilot loss = 6.397007942199707, max interval = -18.266016006469727, \n",
      "Train ACC: 0.8, PTA: 0.2939453125, Test ACC: 0.7419354838709677\n",
      "87, total loss = -4.030562400817871, reconstruct loss = 0.08991269767284393, cluster loss = 0.04154255613684654, calm loss = 0.6861651539802551, pilot loss = 6.417481422424316, max interval = -18.333681106567383, \n",
      "Train ACC: 0.8, PTA: 0.2919921875, Test ACC: 0.7419354838709677\n",
      "88, total loss = -4.059051036834717, reconstruct loss = 0.08697523176670074, cluster loss = 0.041421569883823395, calm loss = 0.6875582337379456, pilot loss = 6.438900947570801, max interval = -18.40270233154297, \n",
      "Train ACC: 0.8, PTA: 0.2939453125, Test ACC: 0.7419354838709677\n",
      "89, total loss = -4.087011337280273, reconstruct loss = 0.08628319203853607, cluster loss = 0.04006893187761307, calm loss = 0.689224123954773, pilot loss = 6.4612226486206055, max interval = -18.474096298217773, \n",
      "Train ACC: 0.8, PTA: 0.2919921875, Test ACC: 0.7419354838709677\n",
      "90, total loss = -4.108372688293457, reconstruct loss = 0.0887894332408905, cluster loss = 0.041840557008981705, calm loss = 0.6914710998535156, pilot loss = 6.485918998718262, max interval = -18.549318313598633, \n",
      "Train ACC: 0.8, PTA: 0.291015625, Test ACC: 0.7419354838709677\n",
      "91, total loss = -4.132782936096191, reconstruct loss = 0.093196339905262, cluster loss = 0.039574071764945984, calm loss = 0.693401038646698, pilot loss = 6.506535530090332, max interval = -18.619564056396484, \n",
      "Train ACC: 0.8, PTA: 0.291015625, Test ACC: 0.7419354838709677\n",
      "92, total loss = -4.152357578277588, reconstruct loss = 0.095433309674263, cluster loss = 0.04228008911013603, calm loss = 0.6967704892158508, pilot loss = 6.525097846984863, max interval = -18.68602752685547, \n",
      "Train ACC: 0.8, PTA: 0.30859375, Test ACC: 0.7419354838709677\n",
      "93, total loss = -4.184226989746094, reconstruct loss = 0.09130506217479706, cluster loss = 0.0413113497197628, calm loss = 0.6989323496818542, pilot loss = 6.5462493896484375, max interval = -18.757688522338867, \n",
      "Train ACC: 0.8, PTA: 0.28515625, Test ACC: 0.7419354838709677\n",
      "94, total loss = -4.214001655578613, reconstruct loss = 0.08751989156007767, cluster loss = 0.04062719643115997, calm loss = 0.701314389705658, pilot loss = 6.569476127624512, max interval = -18.830533981323242, \n",
      "Train ACC: 0.8, PTA: 0.2919921875, Test ACC: 0.7419354838709677\n",
      "95, total loss = -4.244854927062988, reconstruct loss = 0.08311822265386581, cluster loss = 0.03948352485895157, calm loss = 0.7033759951591492, pilot loss = 6.591662406921387, max interval = -18.901439666748047, \n",
      "Train ACC: 0.8, PTA: 0.2734375, Test ACC: 0.7419354838709677\n",
      "96, total loss = -4.265204429626465, reconstruct loss = 0.08775600045919418, cluster loss = 0.04020951688289642, calm loss = 0.7048506140708923, pilot loss = 6.611097812652588, max interval = -18.968156814575195, \n",
      "Train ACC: 0.8, PTA: 0.298828125, Test ACC: 0.7419354838709677\n",
      "97, total loss = -4.284938812255859, reconstruct loss = 0.09323746711015701, cluster loss = 0.040422696620225906, calm loss = 0.7065539956092834, pilot loss = 6.628859043121338, max interval = -19.03240394592285, \n",
      "Train ACC: 0.8, PTA: 0.28515625, Test ACC: 0.7419354838709677\n",
      "98, total loss = -4.3129096031188965, reconstruct loss = 0.09173053503036499, cluster loss = 0.03978782892227173, calm loss = 0.7081800103187561, pilot loss = 6.647721767425537, max interval = -19.098684310913086, \n",
      "Train ACC: 0.8, PTA: 0.2841796875, Test ACC: 0.7419354838709677\n",
      "99, total loss = -4.342846870422363, reconstruct loss = 0.08515764027833939, cluster loss = 0.04203319549560547, calm loss = 0.709987461566925, pilot loss = 6.666680335998535, max interval = -19.165048599243164, \n",
      "Train ACC: 0.8, PTA: 0.2958984375, Test ACC: 0.7419354838709677\n",
      "100, total loss = -4.3687424659729, reconstruct loss = 0.08776228874921799, cluster loss = 0.03991711884737015, calm loss = 0.7104436159133911, pilot loss = 6.68335485458374, max interval = -19.227327346801758, \n",
      "Train ACC: 0.8, PTA: 0.275390625, Test ACC: 0.7419354838709677\n",
      "101, total loss = -4.389196872711182, reconstruct loss = 0.09300777316093445, cluster loss = 0.04048929736018181, calm loss = 0.7109606862068176, pilot loss = 6.702448844909668, max interval = -19.292991638183594, \n",
      "Train ACC: 0.8, PTA: 0.287109375, Test ACC: 0.7419354838709677\n",
      "102, total loss = -4.4190993309021, reconstruct loss = 0.09112311154603958, cluster loss = 0.03914228826761246, calm loss = 0.7117069959640503, pilot loss = 6.723790168762207, max interval = -19.362760543823242, \n",
      "Train ACC: 0.8, PTA: 0.27734375, Test ACC: 0.7419354838709677\n",
      "103, total loss = -4.456085681915283, reconstruct loss = 0.08001494407653809, cluster loss = 0.03970780223608017, calm loss = 0.713347852230072, pilot loss = 6.747307777404785, max interval = -19.436595916748047, \n",
      "Train ACC: 0.8, PTA: 0.26953125, Test ACC: 0.7419354838709677\n",
      "104, total loss = -4.4622344970703125, reconstruct loss = 0.0980147272348404, cluster loss = 0.04127253219485283, calm loss = 0.7157691717147827, pilot loss = 6.772292137145996, max interval = -19.512598037719727, \n",
      "Train ACC: 0.8, PTA: 0.2900390625, Test ACC: 0.7419354838709677\n",
      "105, total loss = -4.498410224914551, reconstruct loss = 0.09002234786748886, cluster loss = 0.040524810552597046, calm loss = 0.7170494794845581, pilot loss = 6.790140628814697, max interval = -19.57923698425293, \n",
      "Train ACC: 0.8, PTA: 0.28515625, Test ACC: 0.7419354838709677\n",
      "106, total loss = -4.526564598083496, reconstruct loss = 0.08500940352678299, cluster loss = 0.042221952229738235, calm loss = 0.7190464735031128, pilot loss = 6.805365562438965, max interval = -19.639442443847656, \n",
      "Train ACC: 0.8, PTA: 0.2841796875, Test ACC: 0.7419354838709677\n",
      "107, total loss = -4.5466790199279785, reconstruct loss = 0.09224031120538712, cluster loss = 0.04153282940387726, calm loss = 0.7197856903076172, pilot loss = 6.821951389312744, max interval = -19.702390670776367, \n",
      "Train ACC: 0.8, PTA: 0.2783203125, Test ACC: 0.7419354838709677\n",
      "108, total loss = -4.585150718688965, reconstruct loss = 0.0837826207280159, cluster loss = 0.03946022689342499, calm loss = 0.7198619246482849, pilot loss = 6.838849067687988, max interval = -19.76667594909668, \n",
      "Train ACC: 0.8, PTA: 0.2607421875, Test ACC: 0.7419354838709677\n",
      "109, total loss = -4.603493690490723, reconstruct loss = 0.09141574054956436, cluster loss = 0.03943095728754997, calm loss = 0.7208191156387329, pilot loss = 6.858027458190918, max interval = -19.83262825012207, \n",
      "Train ACC: 0.8, PTA: 0.28515625, Test ACC: 0.7419354838709677\n",
      "110, total loss = -4.63362455368042, reconstruct loss = 0.08731954544782639, cluster loss = 0.04004254937171936, calm loss = 0.7220717668533325, pilot loss = 6.878391265869141, max interval = -19.901697158813477, \n",
      "Train ACC: 0.8, PTA: 0.271484375, Test ACC: 0.7419354838709677\n",
      "111, total loss = -4.657502174377441, reconstruct loss = 0.08752333372831345, cluster loss = 0.04231954365968704, calm loss = 0.7237920165061951, pilot loss = 6.8989458084106445, max interval = -19.971294403076172, \n",
      "Train ACC: 0.8, PTA: 0.2939453125, Test ACC: 0.7419354838709677\n",
      "112, total loss = -4.689965724945068, reconstruct loss = 0.08218846470117569, cluster loss = 0.04182317107915878, calm loss = 0.7256748080253601, pilot loss = 6.920196533203125, max interval = -20.042510986328125, \n",
      "Train ACC: 0.8, PTA: 0.2431640625, Test ACC: 0.7419354838709677\n",
      "113, total loss = -4.715529441833496, reconstruct loss = 0.08635899424552917, cluster loss = 0.03879878297448158, calm loss = 0.7276936769485474, pilot loss = 6.939385890960693, max interval = -20.1110897064209, \n",
      "Train ACC: 0.8, PTA: 0.263671875, Test ACC: 0.7419354838709677\n",
      "114, total loss = -4.735989093780518, reconstruct loss = 0.09149134904146194, cluster loss = 0.04049103707075119, calm loss = 0.7288280725479126, pilot loss = 6.957611083984375, max interval = -20.177846908569336, \n",
      "Train ACC: 0.8, PTA: 0.298828125, Test ACC: 0.7419354838709677\n",
      "115, total loss = -4.773599624633789, reconstruct loss = 0.08192344009876251, cluster loss = 0.03976300358772278, calm loss = 0.7301705479621887, pilot loss = 6.978594779968262, max interval = -20.248886108398438, \n",
      "Train ACC: 0.8, PTA: 0.2646484375, Test ACC: 0.7419354838709677\n",
      "116, total loss = -4.793020248413086, reconstruct loss = 0.08942104876041412, cluster loss = 0.04031345248222351, calm loss = 0.7314454913139343, pilot loss = 7.001856327056885, max interval = -20.32330322265625, \n",
      "Train ACC: 0.8, PTA: 0.2841796875, Test ACC: 0.7419354838709677\n",
      "117, total loss = -4.820660591125488, reconstruct loss = 0.09060708433389664, cluster loss = 0.039362452924251556, calm loss = 0.7325237989425659, pilot loss = 7.025089263916016, max interval = -20.397979736328125, \n",
      "Train ACC: 0.8, PTA: 0.2646484375, Test ACC: 0.7419354838709677\n",
      "118, total loss = -4.846479415893555, reconstruct loss = 0.09080767631530762, cluster loss = 0.0392192006111145, calm loss = 0.7346874475479126, pilot loss = 7.048534393310547, max interval = -20.47165298461914, \n",
      "Train ACC: 0.8, PTA: 0.259765625, Test ACC: 0.7419354838709677\n",
      "119, total loss = -4.875159740447998, reconstruct loss = 0.08940139412879944, cluster loss = 0.03963751718401909, calm loss = 0.73603755235672, pilot loss = 7.06808614730835, max interval = -20.54119873046875, \n",
      "Train ACC: 0.8, PTA: 0.26953125, Test ACC: 0.7419354838709677\n",
      "120, total loss = -4.904688835144043, reconstruct loss = 0.08970668166875839, cluster loss = 0.03830684348940849, calm loss = 0.7373528480529785, pilot loss = 7.087809085845947, max interval = -20.612096786499023, \n",
      "Train ACC: 0.8, PTA: 0.22265625, Test ACC: 0.7419354838709677\n",
      "121, total loss = -4.931571006774902, reconstruct loss = 0.08891966938972473, cluster loss = 0.039856016635894775, calm loss = 0.7398374676704407, pilot loss = 7.109744071960449, max interval = -20.686599731445312, \n",
      "Train ACC: 0.8, PTA: 0.2529296875, Test ACC: 0.7419354838709677\n",
      "122, total loss = -4.961917877197266, reconstruct loss = 0.085441954433918, cluster loss = 0.040629614144563675, calm loss = 0.7427290678024292, pilot loss = 7.13248348236084, max interval = -20.762828826904297, \n",
      "Train ACC: 0.8, PTA: 0.251953125, Test ACC: 0.7419354838709677\n",
      "123, total loss = -4.989079475402832, reconstruct loss = 0.08608091622591019, cluster loss = 0.03986488655209541, calm loss = 0.7455155849456787, pilot loss = 7.158299922943115, max interval = -20.84244155883789, \n",
      "Train ACC: 0.8, PTA: 0.2685546875, Test ACC: 0.7419354838709677\n",
      "124, total loss = -5.020166397094727, reconstruct loss = 0.08512789756059647, cluster loss = 0.03820747137069702, calm loss = 0.7465112805366516, pilot loss = 7.177865028381348, max interval = -20.912622451782227, \n",
      "Train ACC: 0.8, PTA: 0.2509765625, Test ACC: 0.7419354838709677\n",
      "125, total loss = -5.048901557922363, reconstruct loss = 0.0811445564031601, cluster loss = 0.041612409055233, calm loss = 0.74735027551651, pilot loss = 7.1985039710998535, max interval = -20.983659744262695, \n",
      "Train ACC: 0.8, PTA: 0.2568359375, Test ACC: 0.7419354838709677\n",
      "126, total loss = -5.070296764373779, reconstruct loss = 0.08910936862230301, cluster loss = 0.04053230211138725, calm loss = 0.7481363415718079, pilot loss = 7.2207159996032715, max interval = -21.057043075561523, \n",
      "Train ACC: 0.8, PTA: 0.2509765625, Test ACC: 0.7419354838709677\n",
      "127, total loss = -5.099579334259033, reconstruct loss = 0.088057741522789, cluster loss = 0.04054167494177818, calm loss = 0.7493852376937866, pilot loss = 7.243422031402588, max interval = -21.131738662719727, \n",
      "Train ACC: 0.8, PTA: 0.28125, Test ACC: 0.7419354838709677\n",
      "128, total loss = -5.125439643859863, reconstruct loss = 0.09187399595975876, cluster loss = 0.03908492252230644, calm loss = 0.7511026263237, pilot loss = 7.265656471252441, max interval = -21.206401824951172, \n",
      "Train ACC: 0.8, PTA: 0.2578125, Test ACC: 0.7419354838709677\n",
      "129, total loss = -5.150938987731934, reconstruct loss = 0.09536198526620865, cluster loss = 0.03875921666622162, calm loss = 0.7533594369888306, pilot loss = 7.2906928062438965, max interval = -21.286470413208008, \n",
      "Train ACC: 0.8, PTA: 0.263671875, Test ACC: 0.7419354838709677\n",
      "130, total loss = -5.195418834686279, reconstruct loss = 0.07952702790498734, cluster loss = 0.03785793483257294, calm loss = 0.755648136138916, pilot loss = 7.312997341156006, max interval = -21.361370086669922, \n",
      "Train ACC: 0.8, PTA: 0.240234375, Test ACC: 0.7419354838709677\n",
      "131, total loss = -5.2172160148620605, reconstruct loss = 0.08461912721395493, cluster loss = 0.04009246081113815, calm loss = 0.757260262966156, pilot loss = 7.335197448730469, max interval = -21.43712615966797, \n",
      "Train ACC: 0.8, PTA: 0.236328125, Test ACC: 0.7419354838709677\n",
      "132, total loss = -5.243350505828857, reconstruct loss = 0.0869116261601448, cluster loss = 0.039655376225709915, calm loss = 0.7592431306838989, pilot loss = 7.3592376708984375, max interval = -21.514421463012695, \n",
      "Train ACC: 0.8, PTA: 0.2646484375, Test ACC: 0.7419354838709677\n",
      "133, total loss = -5.271315574645996, reconstruct loss = 0.08596831560134888, cluster loss = 0.04092283546924591, calm loss = 0.7618242502212524, pilot loss = 7.38546895980835, max interval = -21.596128463745117, \n",
      "Train ACC: 0.8, PTA: 0.259765625, Test ACC: 0.7419354838709677\n",
      "134, total loss = -5.29881477355957, reconstruct loss = 0.08760160952806473, cluster loss = 0.040302738547325134, calm loss = 0.7649080157279968, pilot loss = 7.414558410644531, max interval = -21.68295669555664, \n",
      "Train ACC: 0.8, PTA: 0.251953125, Test ACC: 0.7419354838709677\n",
      "135, total loss = -5.323113441467285, reconstruct loss = 0.09274046868085861, cluster loss = 0.03945591300725937, calm loss = 0.7673280835151672, pilot loss = 7.441668510437012, max interval = -21.76612091064453, \n",
      "Train ACC: 0.8, PTA: 0.265625, Test ACC: 0.7419354838709677\n",
      "136, total loss = -5.36682653427124, reconstruct loss = 0.07842893153429031, cluster loss = 0.038891859352588654, calm loss = 0.7686122059822083, pilot loss = 7.459409236907959, max interval = -21.834630966186523, \n",
      "Train ACC: 0.8, PTA: 0.2333984375, Test ACC: 0.7419354838709677\n",
      "137, total loss = -5.391268730163574, reconstruct loss = 0.08243532478809357, cluster loss = 0.03922770917415619, calm loss = 0.7703977823257446, pilot loss = 7.478228569030762, max interval = -21.905323028564453, \n",
      "Train ACC: 0.8, PTA: 0.2490234375, Test ACC: 0.7419354838709677\n",
      "138, total loss = -5.4207682609558105, reconstruct loss = 0.08265253156423569, cluster loss = 0.03851839154958725, calm loss = 0.7718616724014282, pilot loss = 7.499768257141113, max interval = -21.979761123657227, \n",
      "Train ACC: 0.8, PTA: 0.234375, Test ACC: 0.7419354838709677\n",
      "139, total loss = -5.4509477615356445, reconstruct loss = 0.08072604238986969, cluster loss = 0.04064156860113144, calm loss = 0.7735467553138733, pilot loss = 7.525202751159668, max interval = -22.062036514282227, \n",
      "Train ACC: 0.8, PTA: 0.2509765625, Test ACC: 0.7419354838709677\n",
      "140, total loss = -5.479167461395264, reconstruct loss = 0.08414039015769958, cluster loss = 0.03981662541627884, calm loss = 0.7752694487571716, pilot loss = 7.5542168617248535, max interval = -22.150096893310547, \n",
      "Train ACC: 0.8, PTA: 0.2421875, Test ACC: 0.7419354838709677\n",
      "141, total loss = -5.5005950927734375, reconstruct loss = 0.09290412068367004, cluster loss = 0.041096530854701996, calm loss = 0.7774434685707092, pilot loss = 7.584197998046875, max interval = -22.241132736206055, \n",
      "Train ACC: 0.8, PTA: 0.26953125, Test ACC: 0.7419354838709677\n",
      "142, total loss = -5.542651176452637, reconstruct loss = 0.08312667161226273, cluster loss = 0.040695492178201675, calm loss = 0.7792097330093384, pilot loss = 7.612884521484375, max interval = -22.33031463623047, \n",
      "Train ACC: 0.8, PTA: 0.236328125, Test ACC: 0.7419354838709677\n",
      "143, total loss = -5.569072723388672, reconstruct loss = 0.08712968975305557, cluster loss = 0.040234848856925964, calm loss = 0.7820350527763367, pilot loss = 7.636509895324707, max interval = -22.41104507446289, \n",
      "Train ACC: 0.8, PTA: 0.2421875, Test ACC: 0.7419354838709677\n",
      "144, total loss = -5.6041388511657715, reconstruct loss = 0.08341187238693237, cluster loss = 0.041307732462882996, calm loss = 0.7829245328903198, pilot loss = 7.6596999168396, max interval = -22.491899490356445, \n",
      "Train ACC: 0.8, PTA: 0.2607421875, Test ACC: 0.7258064516129032\n",
      "145, total loss = -5.63086462020874, reconstruct loss = 0.09171798080205917, cluster loss = 0.03911777585744858, calm loss = 0.7836554050445557, pilot loss = 7.686537742614746, max interval = -22.578340530395508, \n",
      "Train ACC: 0.8, PTA: 0.2373046875, Test ACC: 0.7258064516129032\n",
      "146, total loss = -5.669210433959961, reconstruct loss = 0.08539117872714996, cluster loss = 0.03912867605686188, calm loss = 0.7858036160469055, pilot loss = 7.7193756103515625, max interval = -22.674217224121094, \n",
      "Train ACC: 0.8, PTA: 0.2412109375, Test ACC: 0.7258064516129032\n",
      "147, total loss = -5.700567245483398, reconstruct loss = 0.08581573516130447, cluster loss = 0.03887779265642166, calm loss = 0.7891925573348999, pilot loss = 7.754312038421631, max interval = -22.774150848388672, \n",
      "Train ACC: 0.8, PTA: 0.244140625, Test ACC: 0.7258064516129032\n",
      "148, total loss = -5.7382707595825195, reconstruct loss = 0.07941942662000656, cluster loss = 0.04012356698513031, calm loss = 0.7916691899299622, pilot loss = 7.784534454345703, max interval = -22.867507934570312, \n",
      "Train ACC: 0.8, PTA: 0.2216796875, Test ACC: 0.7258064516129032\n",
      "149, total loss = -5.769932270050049, reconstruct loss = 0.0799839049577713, cluster loss = 0.04018701612949371, calm loss = 0.7943676710128784, pilot loss = 7.814659118652344, max interval = -22.960668563842773, \n",
      "Train ACC: 0.8, PTA: 0.2255859375, Test ACC: 0.7258064516129032\n",
      "150, total loss = -5.798116683959961, reconstruct loss = 0.08418186008930206, cluster loss = 0.04061064496636391, calm loss = 0.7964215874671936, pilot loss = 7.845256805419922, max interval = -23.0543212890625, \n",
      "Train ACC: 0.8, PTA: 0.232421875, Test ACC: 0.7258064516129032\n",
      "151, total loss = -5.833146095275879, reconstruct loss = 0.08138041198253632, cluster loss = 0.04083999991416931, calm loss = 0.7987338304519653, pilot loss = 7.877876281738281, max interval = -23.150732040405273, \n",
      "Train ACC: 0.8, PTA: 0.22265625, Test ACC: 0.7258064516129032\n",
      "152, total loss = -5.8668413162231445, reconstruct loss = 0.08334124833345413, cluster loss = 0.03803761303424835, calm loss = 0.8011907339096069, pilot loss = 7.910387992858887, max interval = -23.247764587402344, \n",
      "Train ACC: 0.8, PTA: 0.212890625, Test ACC: 0.7258064516129032\n",
      "153, total loss = -5.90354061126709, reconstruct loss = 0.0801587775349617, cluster loss = 0.03831089287996292, calm loss = 0.8032746315002441, pilot loss = 7.938879489898682, max interval = -23.339860916137695, \n",
      "Train ACC: 0.8, PTA: 0.2333984375, Test ACC: 0.7096774193548387\n",
      "154, total loss = -5.93269157409668, reconstruct loss = 0.08352626115083694, cluster loss = 0.039394959807395935, calm loss = 0.8050357103347778, pilot loss = 7.9669365882873535, max interval = -23.430604934692383, \n",
      "Train ACC: 0.8, PTA: 0.23046875, Test ACC: 0.7096774193548387\n",
      "155, total loss = -5.968513488769531, reconstruct loss = 0.07934247702360153, cluster loss = 0.03898857533931732, calm loss = 0.8076570630073547, pilot loss = 7.9968061447143555, max interval = -23.521780014038086, \n",
      "Train ACC: 0.8, PTA: 0.2421875, Test ACC: 0.6935483870967742\n",
      "156, total loss = -6.001119613647461, reconstruct loss = 0.08108412474393845, cluster loss = 0.038837797939777374, calm loss = 0.8086097836494446, pilot loss = 8.028206825256348, max interval = -23.61699676513672, \n",
      "Train ACC: 0.8, PTA: 0.212890625, Test ACC: 0.6935483870967742\n",
      "157, total loss = -6.038236618041992, reconstruct loss = 0.07826334238052368, cluster loss = 0.03928610682487488, calm loss = 0.8098840713500977, pilot loss = 8.060997009277344, max interval = -23.715438842773438, \n",
      "Train ACC: 0.8, PTA: 0.2197265625, Test ACC: 0.6935483870967742\n",
      "158, total loss = -6.064491271972656, reconstruct loss = 0.08470162004232407, cluster loss = 0.039913397282361984, calm loss = 0.8126856684684753, pilot loss = 8.096303939819336, max interval = -23.817625045776367, \n",
      "Train ACC: 0.8, PTA: 0.236328125, Test ACC: 0.6935483870967742\n",
      "159, total loss = -6.098730564117432, reconstruct loss = 0.08464062213897705, cluster loss = 0.03949447348713875, calm loss = 0.8148166537284851, pilot loss = 8.130208015441895, max interval = -23.91747283935547, \n",
      "Train ACC: 0.8, PTA: 0.220703125, Test ACC: 0.6935483870967742\n",
      "160, total loss = -6.138350486755371, reconstruct loss = 0.08004263788461685, cluster loss = 0.038129135966300964, calm loss = 0.8167102932929993, pilot loss = 8.159314155578613, max interval = -24.009984970092773, \n",
      "Train ACC: 0.8, PTA: 0.2255859375, Test ACC: 0.6935483870967742\n",
      "161, total loss = -6.167361259460449, reconstruct loss = 0.08485613763332367, cluster loss = 0.03805811330676079, calm loss = 0.8190628290176392, pilot loss = 8.19050407409668, max interval = -24.10626792907715, \n",
      "Train ACC: 0.8, PTA: 0.22265625, Test ACC: 0.6935483870967742\n",
      "162, total loss = -6.202822685241699, reconstruct loss = 0.0829843133687973, cluster loss = 0.038461729884147644, calm loss = 0.8216412663459778, pilot loss = 8.223508834838867, max interval = -24.205808639526367, \n",
      "Train ACC: 0.8, PTA: 0.2158203125, Test ACC: 0.6935483870967742\n",
      "163, total loss = -6.234592437744141, reconstruct loss = 0.0872834324836731, cluster loss = 0.03728194162249565, calm loss = 0.8233888745307922, pilot loss = 8.255937576293945, max interval = -24.30462074279785, \n",
      "Train ACC: 0.8, PTA: 0.22265625, Test ACC: 0.6935483870967742\n",
      "164, total loss = -6.271370887756348, reconstruct loss = 0.08445613831281662, cluster loss = 0.03829904645681381, calm loss = 0.8247377276420593, pilot loss = 8.287883758544922, max interval = -24.40228843688965, \n",
      "Train ACC: 0.8, PTA: 0.216796875, Test ACC: 0.6935483870967742\n",
      "165, total loss = -6.3108978271484375, reconstruct loss = 0.07950378209352493, cluster loss = 0.0381651446223259, calm loss = 0.8257331848144531, pilot loss = 8.315778732299805, max interval = -24.49291229248047, \n",
      "Train ACC: 0.8, PTA: 0.220703125, Test ACC: 0.6935483870967742\n",
      "166, total loss = -6.340734481811523, reconstruct loss = 0.08283974975347519, cluster loss = 0.039833638817071915, calm loss = 0.8272727727890015, pilot loss = 8.347332954406738, max interval = -24.590110778808594, \n",
      "Train ACC: 0.8, PTA: 0.2138671875, Test ACC: 0.6935483870967742\n",
      "167, total loss = -6.373430252075195, reconstruct loss = 0.08388690650463104, cluster loss = 0.03933184966444969, calm loss = 0.8304686546325684, pilot loss = 8.382573127746582, max interval = -24.692655563354492, \n",
      "Train ACC: 0.8, PTA: 0.232421875, Test ACC: 0.6935483870967742\n",
      "168, total loss = -6.41478157043457, reconstruct loss = 0.07820180058479309, cluster loss = 0.039165399968624115, calm loss = 0.833020806312561, pilot loss = 8.41814136505127, max interval = -24.797975540161133, \n",
      "Train ACC: 0.8, PTA: 0.2197265625, Test ACC: 0.6935483870967742\n",
      "169, total loss = -6.448086738586426, reconstruct loss = 0.08033060282468796, cluster loss = 0.03927076980471611, calm loss = 0.835899829864502, pilot loss = 8.452530860900879, max interval = -24.902137756347656, \n",
      "Train ACC: 0.8, PTA: 0.2119140625, Test ACC: 0.6935483870967742\n",
      "170, total loss = -6.480728626251221, reconstruct loss = 0.08227209746837616, cluster loss = 0.03873148187994957, calm loss = 0.8390213251113892, pilot loss = 8.481851577758789, max interval = -24.997268676757812, \n",
      "Train ACC: 0.8, PTA: 0.2275390625, Test ACC: 0.6935483870967742\n",
      "171, total loss = -6.511483192443848, reconstruct loss = 0.08594174683094025, cluster loss = 0.03893929347395897, calm loss = 0.8417472839355469, pilot loss = 8.514366149902344, max interval = -25.09723472595215, \n",
      "Train ACC: 0.8, PTA: 0.2216796875, Test ACC: 0.6935483870967742\n",
      "172, total loss = -6.547865867614746, reconstruct loss = 0.08448348939418793, cluster loss = 0.039512261748313904, calm loss = 0.8437210321426392, pilot loss = 8.548139572143555, max interval = -25.19916534423828, \n",
      "Train ACC: 0.8, PTA: 0.2265625, Test ACC: 0.6935483870967742\n",
      "173, total loss = -6.584677219390869, reconstruct loss = 0.0835292637348175, cluster loss = 0.03950734809041023, calm loss = 0.8449975848197937, pilot loss = 8.582182884216309, max interval = -25.30099105834961, \n",
      "Train ACC: 0.8, PTA: 0.2275390625, Test ACC: 0.6935483870967742\n",
      "174, total loss = -6.621592998504639, reconstruct loss = 0.08346720039844513, cluster loss = 0.03918645158410072, calm loss = 0.845770001411438, pilot loss = 8.619184494018555, max interval = -25.40729522705078, \n",
      "Train ACC: 0.8, PTA: 0.2138671875, Test ACC: 0.6935483870967742\n",
      "175, total loss = -6.655394077301025, reconstruct loss = 0.08333629369735718, cluster loss = 0.04042718932032585, calm loss = 0.8480854034423828, pilot loss = 8.65701961517334, max interval = -25.514677047729492, \n",
      "Train ACC: 0.8, PTA: 0.2099609375, Test ACC: 0.6935483870967742\n",
      "176, total loss = -6.688591957092285, reconstruct loss = 0.0894361212849617, cluster loss = 0.03781960904598236, calm loss = 0.8497848510742188, pilot loss = 8.688101768493652, max interval = -25.614072799682617, \n",
      "Train ACC: 0.8, PTA: 0.2333984375, Test ACC: 0.6935483870967742\n",
      "177, total loss = -6.728795051574707, reconstruct loss = 0.08230121433734894, cluster loss = 0.039604537189006805, calm loss = 0.8530085682868958, pilot loss = 8.716763496398926, max interval = -25.70956802368164, \n",
      "Train ACC: 0.8, PTA: 0.2119140625, Test ACC: 0.6935483870967742\n",
      "178, total loss = -6.75975227355957, reconstruct loss = 0.08594729751348495, cluster loss = 0.03940919041633606, calm loss = 0.8566969037055969, pilot loss = 8.748028755187988, max interval = -25.808809280395508, \n",
      "Train ACC: 0.8, PTA: 0.2099609375, Test ACC: 0.6935483870967742\n",
      "179, total loss = -6.802940845489502, reconstruct loss = 0.0763588696718216, cluster loss = 0.038781724870204926, calm loss = 0.8613816499710083, pilot loss = 8.782220840454102, max interval = -25.911603927612305, \n",
      "Train ACC: 0.8, PTA: 0.201171875, Test ACC: 0.6935483870967742\n",
      "180, total loss = -6.840024948120117, reconstruct loss = 0.0770205482840538, cluster loss = 0.039647750556468964, calm loss = 0.8642902374267578, pilot loss = 8.820413589477539, max interval = -26.025632858276367, \n",
      "Train ACC: 0.8, PTA: 0.208984375, Test ACC: 0.6935483870967742\n",
      "181, total loss = -6.877664089202881, reconstruct loss = 0.08067356795072556, cluster loss = 0.03960902616381645, calm loss = 0.8662117123603821, pilot loss = 8.861814498901367, max interval = -26.146608352661133, \n",
      "Train ACC: 0.8, PTA: 0.22265625, Test ACC: 0.6935483870967742\n",
      "182, total loss = -6.909725189208984, reconstruct loss = 0.08926192671060562, cluster loss = 0.03900080919265747, calm loss = 0.8686686754226685, pilot loss = 8.906137466430664, max interval = -26.270793914794922, \n",
      "Train ACC: 0.8, PTA: 0.2041015625, Test ACC: 0.6935483870967742\n",
      "183, total loss = -6.955605983734131, reconstruct loss = 0.0827941745519638, cluster loss = 0.03970823064446449, calm loss = 0.8717989921569824, pilot loss = 8.951363563537598, max interval = -26.3973445892334, \n",
      "Train ACC: 0.8, PTA: 0.2099609375, Test ACC: 0.6935483870967742\n",
      "184, total loss = -7.001891136169434, reconstruct loss = 0.07635080814361572, cluster loss = 0.039374466985464096, calm loss = 0.8752454519271851, pilot loss = 8.989473342895508, max interval = -26.513307571411133, \n",
      "Train ACC: 0.8, PTA: 0.19921875, Test ACC: 0.6935483870967742\n",
      "185, total loss = -7.041189670562744, reconstruct loss = 0.07684183865785599, cluster loss = 0.038795918226242065, calm loss = 0.8782106637954712, pilot loss = 9.0214204788208, max interval = -26.619356155395508, \n",
      "Train ACC: 0.8, PTA: 0.1923828125, Test ACC: 0.6935483870967742\n",
      "186, total loss = -7.0781636238098145, reconstruct loss = 0.07639770209789276, cluster loss = 0.039176251739263535, calm loss = 0.8831273317337036, pilot loss = 9.0574951171875, max interval = -26.730798721313477, \n",
      "Train ACC: 0.8, PTA: 0.1923828125, Test ACC: 0.6935483870967742\n",
      "187, total loss = -7.110365867614746, reconstruct loss = 0.08003143966197968, cluster loss = 0.0384516678750515, calm loss = 0.8883811831474304, pilot loss = 9.09359073638916, max interval = -26.840187072753906, \n",
      "Train ACC: 0.8, PTA: 0.1943359375, Test ACC: 0.6935483870967742\n",
      "188, total loss = -7.145440578460693, reconstruct loss = 0.07711737602949142, cluster loss = 0.03933112323284149, calm loss = 0.8948538899421692, pilot loss = 9.128582954406738, max interval = -26.94677734375, \n",
      "Train ACC: 0.8, PTA: 0.1962890625, Test ACC: 0.6935483870967742\n",
      "189, total loss = -7.177921295166016, reconstruct loss = 0.08144859969615936, cluster loss = 0.038630180060863495, calm loss = 0.898525059223175, pilot loss = 9.161242485046387, max interval = -27.05042266845703, \n",
      "Train ACC: 0.8, PTA: 0.2119140625, Test ACC: 0.6935483870967742\n",
      "190, total loss = -7.219997406005859, reconstruct loss = 0.07729183882474899, cluster loss = 0.03863739222288132, calm loss = 0.8997412919998169, pilot loss = 9.192426681518555, max interval = -27.151044845581055, \n",
      "Train ACC: 0.8, PTA: 0.2060546875, Test ACC: 0.6935483870967742\n",
      "191, total loss = -7.251728057861328, reconstruct loss = 0.08239994943141937, cluster loss = 0.03704092651605606, calm loss = 0.9022325277328491, pilot loss = 9.225378036499023, max interval = -27.252182006835938, \n",
      "Train ACC: 0.8, PTA: 0.2158203125, Test ACC: 0.6935483870967742\n",
      "192, total loss = -7.285584449768066, reconstruct loss = 0.08243472874164581, cluster loss = 0.04009063169360161, calm loss = 0.9035037755966187, pilot loss = 9.251585006713867, max interval = -27.3443660736084, \n",
      "Train ACC: 0.8, PTA: 0.21875, Test ACC: 0.6935483870967742\n",
      "193, total loss = -7.322572708129883, reconstruct loss = 0.08426826447248459, cluster loss = 0.037993721663951874, calm loss = 0.9044163823127747, pilot loss = 9.275117874145508, max interval = -27.431909561157227, \n",
      "Train ACC: 0.8, PTA: 0.203125, Test ACC: 0.6774193548387096\n",
      "194, total loss = -7.368139266967773, reconstruct loss = 0.07551319152116776, cluster loss = 0.039416030049324036, calm loss = 0.9043806791305542, pilot loss = 9.29875373840332, max interval = -27.520402908325195, \n",
      "Train ACC: 0.8, PTA: 0.189453125, Test ACC: 0.6774193548387096\n",
      "195, total loss = -7.40115213394165, reconstruct loss = 0.0823998674750328, cluster loss = 0.038401439785957336, calm loss = 0.904050350189209, pilot loss = 9.32404899597168, max interval = -27.611772537231445, \n",
      "Train ACC: 0.8, PTA: 0.20703125, Test ACC: 0.6774193548387096\n",
      "196, total loss = -7.440475940704346, reconstruct loss = 0.08083852380514145, cluster loss = 0.038690172135829926, calm loss = 0.9044414758682251, pilot loss = 9.35303020477295, max interval = -27.708251953125, \n",
      "Train ACC: 0.8, PTA: 0.2138671875, Test ACC: 0.6774193548387096\n",
      "197, total loss = -7.47507905960083, reconstruct loss = 0.08352198451757431, cluster loss = 0.038585491478443146, calm loss = 0.9064370393753052, pilot loss = 9.385377883911133, max interval = -27.810590744018555, \n",
      "Train ACC: 0.8, PTA: 0.201171875, Test ACC: 0.6774193548387096\n",
      "198, total loss = -7.516557693481445, reconstruct loss = 0.08164004236459732, cluster loss = 0.037126537412405014, calm loss = 0.9079925417900085, pilot loss = 9.41858959197998, max interval = -27.914899826049805, \n",
      "Train ACC: 0.8, PTA: 0.2138671875, Test ACC: 0.6774193548387096\n",
      "199, total loss = -7.552836894989014, reconstruct loss = 0.08130812644958496, cluster loss = 0.038929086178541183, calm loss = 0.9090408086776733, pilot loss = 9.447372436523438, max interval = -28.011606216430664, \n",
      "Train ACC: 0.8, PTA: 0.220703125, Test ACC: 0.6774193548387096\n",
      "200, total loss = -7.583535194396973, reconstruct loss = 0.08837683498859406, cluster loss = 0.03844577446579933, calm loss = 0.91026771068573, pilot loss = 9.475049018859863, max interval = -28.106321334838867, \n",
      "Train ACC: 0.8, PTA: 0.1982421875, Test ACC: 0.6774193548387096\n",
      "201, total loss = -7.628248691558838, reconstruct loss = 0.08165974169969559, cluster loss = 0.03863636404275894, calm loss = 0.9114214777946472, pilot loss = 9.50859260559082, max interval = -28.210607528686523, \n",
      "Train ACC: 0.8, PTA: 0.1982421875, Test ACC: 0.6774193548387096\n",
      "202, total loss = -7.668210029602051, reconstruct loss = 0.08064475655555725, cluster loss = 0.038256943225860596, calm loss = 0.9132623672485352, pilot loss = 9.546041488647461, max interval = -28.32199478149414, \n",
      "Train ACC: 0.8, PTA: 0.20703125, Test ACC: 0.6612903225806451\n",
      "203, total loss = -7.704414367675781, reconstruct loss = 0.08175738900899887, cluster loss = 0.039428479969501495, calm loss = 0.9164975881576538, pilot loss = 9.586654663085938, max interval = -28.439783096313477, \n",
      "Train ACC: 0.8, PTA: 0.2158203125, Test ACC: 0.6612903225806451\n",
      "204, total loss = -7.740612506866455, reconstruct loss = 0.08228988945484161, cluster loss = 0.04163061082363129, calm loss = 0.9210756421089172, pilot loss = 9.63068962097168, max interval = -28.565013885498047, \n",
      "Train ACC: 0.8, PTA: 0.2099609375, Test ACC: 0.6612903225806451\n",
      "205, total loss = -7.791456699371338, reconstruct loss = 0.07467406243085861, cluster loss = 0.03784920647740364, calm loss = 0.9259583353996277, pilot loss = 9.679429054260254, max interval = -28.698135375976562, \n",
      "Train ACC: 0.8, PTA: 0.1787109375, Test ACC: 0.6612903225806451\n",
      "206, total loss = -7.826590061187744, reconstruct loss = 0.07787314057350159, cluster loss = 0.038853492587804794, calm loss = 0.9301900863647461, pilot loss = 9.727581024169922, max interval = -28.829326629638672, \n",
      "Train ACC: 0.8, PTA: 0.1943359375, Test ACC: 0.6612903225806451\n",
      "207, total loss = -7.85869026184082, reconstruct loss = 0.08278929442167282, cluster loss = 0.038979656994342804, calm loss = 0.9345241785049438, pilot loss = 9.77289867401123, max interval = -28.9534854888916, \n",
      "Train ACC: 0.8, PTA: 0.205078125, Test ACC: 0.6612903225806451\n",
      "208, total loss = -7.903545379638672, reconstruct loss = 0.07837816327810287, cluster loss = 0.03674856573343277, calm loss = 0.9367367625236511, pilot loss = 9.807685852050781, max interval = -29.061098098754883, \n",
      "Train ACC: 0.8, PTA: 0.1865234375, Test ACC: 0.6612903225806451\n",
      "209, total loss = -7.937784194946289, reconstruct loss = 0.0820850059390068, cluster loss = 0.03755537047982216, calm loss = 0.939215362071991, pilot loss = 9.838815689086914, max interval = -29.164636611938477, \n",
      "Train ACC: 0.8, PTA: 0.20703125, Test ACC: 0.6612903225806451\n",
      "210, total loss = -7.9754743576049805, reconstruct loss = 0.08135158568620682, cluster loss = 0.040424589067697525, calm loss = 0.9414995312690735, pilot loss = 9.870843887329102, max interval = -29.270713806152344, \n",
      "Train ACC: 0.8, PTA: 0.1962890625, Test ACC: 0.6612903225806451\n",
      "211, total loss = -8.014659881591797, reconstruct loss = 0.08212471008300781, cluster loss = 0.039439186453819275, calm loss = 0.9449040293693542, pilot loss = 9.905035972595215, max interval = -29.380268096923828, \n",
      "Train ACC: 0.8, PTA: 0.193359375, Test ACC: 0.6612903225806451\n",
      "212, total loss = -8.05173397064209, reconstruct loss = 0.08678478002548218, cluster loss = 0.036749109625816345, calm loss = 0.9480674862861633, pilot loss = 9.938094139099121, max interval = -29.487958908081055, \n",
      "Train ACC: 0.8, PTA: 0.2001953125, Test ACC: 0.6612903225806451\n",
      "213, total loss = -8.098390579223633, reconstruct loss = 0.07836917042732239, cluster loss = 0.03911551088094711, calm loss = 0.950447678565979, pilot loss = 9.972387313842773, max interval = -29.598529815673828, \n",
      "Train ACC: 0.8, PTA: 0.181640625, Test ACC: 0.6612903225806451\n",
      "214, total loss = -8.138104438781738, reconstruct loss = 0.07843480259180069, cluster loss = 0.039270807057619095, calm loss = 0.9533418416976929, pilot loss = 10.010640144348145, max interval = -29.714529037475586, \n",
      "Train ACC: 0.8, PTA: 0.19140625, Test ACC: 0.6612903225806451\n",
      "215, total loss = -8.180747985839844, reconstruct loss = 0.07767322659492493, cluster loss = 0.038973014801740646, calm loss = 0.9564617276191711, pilot loss = 10.05258560180664, max interval = -29.838485717773438, \n",
      "Train ACC: 0.8, PTA: 0.1904296875, Test ACC: 0.6612903225806451\n",
      "216, total loss = -8.220124244689941, reconstruct loss = 0.08066686242818832, cluster loss = 0.03738272935152054, calm loss = 0.9607551693916321, pilot loss = 10.092784881591797, max interval = -29.960474014282227, \n",
      "Train ACC: 0.8, PTA: 0.1923828125, Test ACC: 0.6612903225806451\n",
      "217, total loss = -8.261093139648438, reconstruct loss = 0.07994198799133301, cluster loss = 0.038234345614910126, calm loss = 0.9649012684822083, pilot loss = 10.130815505981445, max interval = -30.079605102539062, \n",
      "Train ACC: 0.8, PTA: 0.197265625, Test ACC: 0.6612903225806451\n",
      "218, total loss = -8.302226066589355, reconstruct loss = 0.08141935616731644, cluster loss = 0.03555939346551895, calm loss = 0.9703046679496765, pilot loss = 10.17234992980957, max interval = -30.203880310058594, \n",
      "Train ACC: 0.8, PTA: 0.1826171875, Test ACC: 0.6612903225806451\n",
      "219, total loss = -8.340883255004883, reconstruct loss = 0.0834193006157875, cluster loss = 0.03722644969820976, calm loss = 0.9742473363876343, pilot loss = 10.215934753417969, max interval = -30.332408905029297, \n",
      "Train ACC: 0.8, PTA: 0.17578125, Test ACC: 0.6612903225806451\n",
      "220, total loss = -8.386021614074707, reconstruct loss = 0.07781312614679337, cluster loss = 0.039417814463377, calm loss = 0.9783056974411011, pilot loss = 10.260272026062012, max interval = -30.461320877075195, \n",
      "Train ACC: 0.8, PTA: 0.216796875, Test ACC: 0.6612903225806451\n",
      "221, total loss = -8.429821968078613, reconstruct loss = 0.07922765612602234, cluster loss = 0.036566440016031265, calm loss = 0.9820097088813782, pilot loss = 10.304069519042969, max interval = -30.589866638183594, \n",
      "Train ACC: 0.8, PTA: 0.1875, Test ACC: 0.6612903225806451\n",
      "222, total loss = -8.469832420349121, reconstruct loss = 0.07980569452047348, cluster loss = 0.03736516088247299, calm loss = 0.9859148263931274, pilot loss = 10.348883628845215, max interval = -30.718759536743164, \n",
      "Train ACC: 0.8, PTA: 0.1953125, Test ACC: 0.6612903225806451\n",
      "223, total loss = -8.50718879699707, reconstruct loss = 0.08371064066886902, cluster loss = 0.03750593215227127, calm loss = 0.9895078539848328, pilot loss = 10.39416790008545, max interval = -30.847898483276367, \n",
      "Train ACC: 0.8, PTA: 0.2001953125, Test ACC: 0.6612903225806451\n",
      "224, total loss = -8.559310913085938, reconstruct loss = 0.07251386344432831, cluster loss = 0.039001770317554474, calm loss = 0.9929715991020203, pilot loss = 10.43893814086914, max interval = -30.977577209472656, \n",
      "Train ACC: 0.8, PTA: 0.1748046875, Test ACC: 0.6612903225806451\n",
      "225, total loss = -8.593375205993652, reconstruct loss = 0.08223548531532288, cluster loss = 0.03734959661960602, calm loss = 0.9966691136360168, pilot loss = 10.483491897583008, max interval = -31.10686683654785, \n",
      "Train ACC: 0.8, PTA: 0.19140625, Test ACC: 0.6612903225806451\n",
      "226, total loss = -8.640914916992188, reconstruct loss = 0.07721152901649475, cluster loss = 0.036766692996025085, calm loss = 1.0002182722091675, pilot loss = 10.525054931640625, max interval = -31.23139190673828, \n",
      "Train ACC: 0.8, PTA: 0.201171875, Test ACC: 0.6612903225806451\n",
      "227, total loss = -8.681295394897461, reconstruct loss = 0.07929947227239609, cluster loss = 0.037088602781295776, calm loss = 1.0034430027008057, pilot loss = 10.563555717468262, max interval = -31.35230255126953, \n",
      "Train ACC: 0.8, PTA: 0.177734375, Test ACC: 0.6612903225806451\n",
      "228, total loss = -8.719867706298828, reconstruct loss = 0.08058926463127136, cluster loss = 0.03794030100107193, calm loss = 1.007997989654541, pilot loss = 10.604784965515137, max interval = -31.476041793823242, \n",
      "Train ACC: 0.8, PTA: 0.1962890625, Test ACC: 0.6612903225806451\n",
      "229, total loss = -8.771040916442871, reconstruct loss = 0.07636753469705582, cluster loss = 0.03499492257833481, calm loss = 1.0108314752578735, pilot loss = 10.648236274719238, max interval = -31.605205535888672, \n",
      "Train ACC: 0.8, PTA: 0.1728515625, Test ACC: 0.6612903225806451\n",
      "230, total loss = -8.807459831237793, reconstruct loss = 0.08146322518587112, cluster loss = 0.0368199460208416, calm loss = 1.013839602470398, pilot loss = 10.69285774230957, max interval = -31.735336303710938, \n",
      "Train ACC: 0.8, PTA: 0.185546875, Test ACC: 0.6612903225806451\n",
      "231, total loss = -8.848482131958008, reconstruct loss = 0.08111678063869476, cluster loss = 0.03841795027256012, calm loss = 1.01810884475708, pilot loss = 10.737972259521484, max interval = -31.8664493560791, \n",
      "Train ACC: 0.8, PTA: 0.185546875, Test ACC: 0.6612903225806451\n",
      "232, total loss = -8.896116256713867, reconstruct loss = 0.07701185345649719, cluster loss = 0.03735223039984703, calm loss = 1.0222704410552979, pilot loss = 10.784589767456055, max interval = -31.999826431274414, \n",
      "Train ACC: 0.8, PTA: 0.17578125, Test ACC: 0.6612903225806451\n",
      "233, total loss = -8.938401222229004, reconstruct loss = 0.07849942147731781, cluster loss = 0.03661153092980385, calm loss = 1.0259482860565186, pilot loss = 10.833093643188477, max interval = -32.13602066040039, \n",
      "Train ACC: 0.8, PTA: 0.1748046875, Test ACC: 0.6612903225806451\n",
      "234, total loss = -8.981115341186523, reconstruct loss = 0.0791018009185791, cluster loss = 0.03683781996369362, calm loss = 1.0293776988983154, pilot loss = 10.881689071655273, max interval = -32.27272033691406, \n",
      "Train ACC: 0.8, PTA: 0.189453125, Test ACC: 0.6612903225806451\n",
      "235, total loss = -9.021035194396973, reconstruct loss = 0.07969379425048828, cluster loss = 0.039375778287649155, calm loss = 1.0330839157104492, pilot loss = 10.923752784729004, max interval = -32.3997802734375, \n",
      "Train ACC: 0.8, PTA: 0.185546875, Test ACC: 0.6612903225806451\n",
      "236, total loss = -9.065597534179688, reconstruct loss = 0.07998587936162949, cluster loss = 0.03845594823360443, calm loss = 1.0387604236602783, pilot loss = 10.972898483276367, max interval = -32.541038513183594, \n",
      "Train ACC: 0.8, PTA: 0.2021484375, Test ACC: 0.6612903225806451\n",
      "237, total loss = -9.115026473999023, reconstruct loss = 0.07517100870609283, cluster loss = 0.03794967383146286, calm loss = 1.0445098876953125, pilot loss = 11.021998405456543, max interval = -32.682586669921875, \n",
      "Train ACC: 0.8, PTA: 0.181640625, Test ACC: 0.6612903225806451\n",
      "238, total loss = -9.152287483215332, reconstruct loss = 0.07744664698839188, cluster loss = 0.038095664232969284, calm loss = 1.052286148071289, pilot loss = 11.072439193725586, max interval = -32.8226203918457, \n",
      "Train ACC: 0.8, PTA: 0.1943359375, Test ACC: 0.6612903225806451\n",
      "239, total loss = -9.194437026977539, reconstruct loss = 0.07868178188800812, cluster loss = 0.037851482629776, calm loss = 1.0570756196975708, pilot loss = 11.1218900680542, max interval = -32.961917877197266, \n",
      "Train ACC: 0.8, PTA: 0.1787109375, Test ACC: 0.6612903225806451\n",
      "240, total loss = -9.241735458374023, reconstruct loss = 0.0766175165772438, cluster loss = 0.03911161422729492, calm loss = 1.0602142810821533, pilot loss = 11.16910171508789, max interval = -33.10044860839844, \n",
      "Train ACC: 0.8, PTA: 0.197265625, Test ACC: 0.6612903225806451\n",
      "241, total loss = -9.28687572479248, reconstruct loss = 0.07601144164800644, cluster loss = 0.0381542444229126, calm loss = 1.0643088817596436, pilot loss = 11.214554786682129, max interval = -33.233665466308594, \n",
      "Train ACC: 0.8, PTA: 0.169921875, Test ACC: 0.6612903225806451\n",
      "242, total loss = -9.32267951965332, reconstruct loss = 0.08115128427743912, cluster loss = 0.039628107100725174, calm loss = 1.0690895318984985, pilot loss = 11.259561538696289, max interval = -33.365570068359375, \n",
      "Train ACC: 0.8, PTA: 0.1796875, Test ACC: 0.6612903225806451\n",
      "243, total loss = -9.374002456665039, reconstruct loss = 0.07615447789430618, cluster loss = 0.03761067986488342, calm loss = 1.0733048915863037, pilot loss = 11.303945541381836, max interval = -33.498477935791016, \n",
      "Train ACC: 0.8, PTA: 0.185546875, Test ACC: 0.6612903225806451\n",
      "244, total loss = -9.414981842041016, reconstruct loss = 0.07809329032897949, cluster loss = 0.03962991014122963, calm loss = 1.0769037008285522, pilot loss = 11.344810485839844, max interval = -33.626380920410156, \n",
      "Train ACC: 0.8, PTA: 0.1884765625, Test ACC: 0.6612903225806451\n",
      "245, total loss = -9.460577964782715, reconstruct loss = 0.07740801572799683, cluster loss = 0.03887777402997017, calm loss = 1.0808417797088623, pilot loss = 11.38499641418457, max interval = -33.752681732177734, \n",
      "Train ACC: 0.8, PTA: 0.1884765625, Test ACC: 0.6612903225806451\n",
      "246, total loss = -9.507637977600098, reconstruct loss = 0.07511475682258606, cluster loss = 0.03589041531085968, calm loss = 1.0861228704452515, pilot loss = 11.426247596740723, max interval = -33.8790283203125, \n",
      "Train ACC: 0.8, PTA: 0.1611328125, Test ACC: 0.6612903225806451\n",
      "247, total loss = -9.545702934265137, reconstruct loss = 0.07886407524347305, cluster loss = 0.03962957113981247, calm loss = 1.0899888277053833, pilot loss = 11.469271659851074, max interval = -34.01127624511719, \n",
      "Train ACC: 0.8, PTA: 0.1982421875, Test ACC: 0.6612903225806451\n",
      "248, total loss = -9.59011459350586, reconstruct loss = 0.08392448723316193, cluster loss = 0.03612412512302399, calm loss = 1.093449354171753, pilot loss = 11.515901565551758, max interval = -34.14868927001953, \n",
      "Train ACC: 0.8, PTA: 0.17578125, Test ACC: 0.6612903225806451\n",
      "249, total loss = -9.634513854980469, reconstruct loss = 0.08105580508708954, cluster loss = 0.03879036009311676, calm loss = 1.0985145568847656, pilot loss = 11.5650053024292, max interval = -34.289398193359375, \n",
      "Train ACC: 0.8, PTA: 0.1748046875, Test ACC: 0.6612903225806451\n",
      "250, total loss = -9.687912940979004, reconstruct loss = 0.07241141051054001, cluster loss = 0.03878598287701607, calm loss = 1.1044763326644897, pilot loss = 11.613302230834961, max interval = -34.431026458740234, \n",
      "Train ACC: 0.8, PTA: 0.17578125, Test ACC: 0.6612903225806451\n",
      "251, total loss = -9.73145866394043, reconstruct loss = 0.07396477460861206, cluster loss = 0.038358159363269806, calm loss = 1.1103861331939697, pilot loss = 11.662272453308105, max interval = -34.573429107666016, \n",
      "Train ACC: 0.8, PTA: 0.1826171875, Test ACC: 0.6612903225806451\n",
      "252, total loss = -9.779526710510254, reconstruct loss = 0.07193976640701294, cluster loss = 0.03731770068407059, calm loss = 1.116018533706665, pilot loss = 11.712512969970703, max interval = -34.71772766113281, \n",
      "Train ACC: 0.8, PTA: 0.1591796875, Test ACC: 0.6612903225806451\n",
      "253, total loss = -9.82011890411377, reconstruct loss = 0.07872732728719711, cluster loss = 0.036477286368608475, calm loss = 1.11963951587677, pilot loss = 11.755387306213379, max interval = -34.85082244873047, \n",
      "Train ACC: 0.8, PTA: 0.1875, Test ACC: 0.6612903225806451\n",
      "254, total loss = -9.869379997253418, reconstruct loss = 0.07705477625131607, cluster loss = 0.035852253437042236, calm loss = 1.1221787929534912, pilot loss = 11.791942596435547, max interval = -34.97394943237305, \n",
      "Train ACC: 0.8, PTA: 0.1669921875, Test ACC: 0.6612903225806451\n",
      "255, total loss = -9.910152435302734, reconstruct loss = 0.08137074112892151, cluster loss = 0.03630286082625389, calm loss = 1.1259925365447998, pilot loss = 11.83092212677002, max interval = -35.10032653808594, \n",
      "Train ACC: 0.8, PTA: 0.189453125, Test ACC: 0.6612903225806451\n",
      "256, total loss = -9.95526123046875, reconstruct loss = 0.08115454763174057, cluster loss = 0.038497962057590485, calm loss = 1.1292555332183838, pilot loss = 11.872846603393555, max interval = -35.23233413696289, \n",
      "Train ACC: 0.8, PTA: 0.177734375, Test ACC: 0.6612903225806451\n",
      "257, total loss = -10.006187438964844, reconstruct loss = 0.07582850009202957, cluster loss = 0.0386500284075737, calm loss = 1.1329452991485596, pilot loss = 11.918418884277344, max interval = -35.368255615234375, \n",
      "Train ACC: 0.8, PTA: 0.1708984375, Test ACC: 0.6612903225806451\n",
      "258, total loss = -10.053060531616211, reconstruct loss = 0.07451003044843674, cluster loss = 0.03932084143161774, calm loss = 1.1374543905258179, pilot loss = 11.966832160949707, max interval = -35.51008224487305, \n",
      "Train ACC: 0.8, PTA: 0.177734375, Test ACC: 0.6612903225806451\n",
      "259, total loss = -10.09959888458252, reconstruct loss = 0.07543914020061493, cluster loss = 0.03730057179927826, calm loss = 1.1443490982055664, pilot loss = 12.018199920654297, max interval = -35.65842819213867, \n",
      "Train ACC: 0.8, PTA: 0.181640625, Test ACC: 0.6612903225806451\n",
      "260, total loss = -10.141451835632324, reconstruct loss = 0.08076844364404678, cluster loss = 0.036720726639032364, calm loss = 1.1498539447784424, pilot loss = 12.060847282409668, max interval = -35.79397964477539, \n",
      "Train ACC: 0.8, PTA: 0.1689453125, Test ACC: 0.6612903225806451\n",
      "261, total loss = -10.190593719482422, reconstruct loss = 0.07808250933885574, cluster loss = 0.03744443878531456, calm loss = 1.1544173955917358, pilot loss = 12.097773551940918, max interval = -35.920841217041016, \n",
      "Train ACC: 0.8, PTA: 0.18359375, Test ACC: 0.6612903225806451\n",
      "262, total loss = -10.237520217895508, reconstruct loss = 0.07792738080024719, cluster loss = 0.0381786972284317, calm loss = 1.1582396030426025, pilot loss = 12.135698318481445, max interval = -36.04853439331055, \n",
      "Train ACC: 0.8, PTA: 0.154296875, Test ACC: 0.6612903225806451\n",
      "263, total loss = -10.287742614746094, reconstruct loss = 0.07429880648851395, cluster loss = 0.03851807117462158, calm loss = 1.1624929904937744, pilot loss = 12.178747177124023, max interval = -36.183349609375, \n",
      "Train ACC: 0.8, PTA: 0.1669921875, Test ACC: 0.6612903225806451\n",
      "264, total loss = -10.33864974975586, reconstruct loss = 0.0708012655377388, cluster loss = 0.036246925592422485, calm loss = 1.168609619140625, pilot loss = 12.228120803833008, max interval = -36.327301025390625, \n",
      "Train ACC: 0.8, PTA: 0.1669921875, Test ACC: 0.6612903225806451\n",
      "265, total loss = -10.383408546447754, reconstruct loss = 0.07314257323741913, cluster loss = 0.03818001598119736, calm loss = 1.1724042892456055, pilot loss = 12.278009414672852, max interval = -36.4742317199707, \n",
      "Train ACC: 0.8, PTA: 0.181640625, Test ACC: 0.6612903225806451\n",
      "266, total loss = -10.433320045471191, reconstruct loss = 0.07445256412029266, cluster loss = 0.036161333322525024, calm loss = 1.1759517192840576, pilot loss = 12.32814884185791, max interval = -36.62141036987305, \n",
      "Train ACC: 0.8, PTA: 0.154296875, Test ACC: 0.6612903225806451\n",
      "267, total loss = -10.480561256408691, reconstruct loss = 0.07251729816198349, cluster loss = 0.038542721420526505, calm loss = 1.1806970834732056, pilot loss = 12.37914752960205, max interval = -36.76936340332031, \n",
      "Train ACC: 0.8, PTA: 0.150390625, Test ACC: 0.6612903225806451\n",
      "268, total loss = -10.527750968933105, reconstruct loss = 0.07485565543174744, cluster loss = 0.03736227750778198, calm loss = 1.1854182481765747, pilot loss = 12.430540084838867, max interval = -36.91878890991211, \n",
      "Train ACC: 0.8, PTA: 0.171875, Test ACC: 0.6612903225806451\n",
      "269, total loss = -10.572185516357422, reconstruct loss = 0.07830581068992615, cluster loss = 0.03714127093553543, calm loss = 1.1915504932403564, pilot loss = 12.48266887664795, max interval = -37.0703010559082, \n",
      "Train ACC: 0.8, PTA: 0.177734375, Test ACC: 0.6612903225806451\n",
      "270, total loss = -10.622138023376465, reconstruct loss = 0.07742926478385925, cluster loss = 0.03771287202835083, calm loss = 1.1974289417266846, pilot loss = 12.532108306884766, max interval = -37.2204475402832, \n",
      "Train ACC: 0.8, PTA: 0.1943359375, Test ACC: 0.6612903225806451\n",
      "271, total loss = -10.674328804016113, reconstruct loss = 0.0746212899684906, cluster loss = 0.03835168853402138, calm loss = 1.2018826007843018, pilot loss = 12.5770263671875, max interval = -37.36263656616211, \n",
      "Train ACC: 0.8, PTA: 0.1689453125, Test ACC: 0.6612903225806451\n",
      "272, total loss = -10.724047660827637, reconstruct loss = 0.07540114223957062, cluster loss = 0.03670143336057663, calm loss = 1.2068517208099365, pilot loss = 12.626155853271484, max interval = -37.5098991394043, \n",
      "Train ACC: 0.8, PTA: 0.166015625, Test ACC: 0.6612903225806451\n",
      "273, total loss = -10.775097846984863, reconstruct loss = 0.07125217467546463, cluster loss = 0.03883449733257294, calm loss = 1.21158766746521, pilot loss = 12.676950454711914, max interval = -37.65947723388672, \n",
      "Train ACC: 0.8, PTA: 0.1640625, Test ACC: 0.6612903225806451\n",
      "274, total loss = -10.827898979187012, reconstruct loss = 0.06957848370075226, cluster loss = 0.03795129805803299, calm loss = 1.2148449420928955, pilot loss = 12.726415634155273, max interval = -37.80677032470703, \n",
      "Train ACC: 0.8, PTA: 0.1552734375, Test ACC: 0.6612903225806451\n",
      "275, total loss = -10.874553680419922, reconstruct loss = 0.0725768581032753, cluster loss = 0.0377194918692112, calm loss = 1.218559980392456, pilot loss = 12.778430938720703, max interval = -37.95718765258789, \n",
      "Train ACC: 0.8, PTA: 0.171875, Test ACC: 0.6612903225806451\n",
      "276, total loss = -10.924309730529785, reconstruct loss = 0.07359321415424347, cluster loss = 0.03686242923140526, calm loss = 1.2225805521011353, pilot loss = 12.830767631530762, max interval = -38.10920715332031, \n",
      "Train ACC: 0.8, PTA: 0.171875, Test ACC: 0.6612903225806451\n",
      "277, total loss = -10.973742485046387, reconstruct loss = 0.07168805599212646, cluster loss = 0.038751229643821716, calm loss = 1.2276897430419922, pilot loss = 12.88366985321045, max interval = -38.26287841796875, \n",
      "Train ACC: 0.8, PTA: 0.158203125, Test ACC: 0.6612903225806451\n",
      "278, total loss = -11.025965690612793, reconstruct loss = 0.0714813843369484, cluster loss = 0.03804631903767586, calm loss = 1.2314293384552002, pilot loss = 12.93055534362793, max interval = -38.4087028503418, \n",
      "Train ACC: 0.8, PTA: 0.16015625, Test ACC: 0.6612903225806451\n",
      "279, total loss = -11.074134826660156, reconstruct loss = 0.07433221489191055, cluster loss = 0.037441082298755646, calm loss = 1.236342430114746, pilot loss = 12.981330871582031, max interval = -38.560482025146484, \n",
      "Train ACC: 0.8, PTA: 0.1708984375, Test ACC: 0.6612903225806451\n",
      "280, total loss = -11.123018264770508, reconstruct loss = 0.07659240067005157, cluster loss = 0.038079019635915756, calm loss = 1.242032766342163, pilot loss = 13.037256240844727, max interval = -38.722679138183594, \n",
      "Train ACC: 0.8, PTA: 0.162109375, Test ACC: 0.6612903225806451\n",
      "281, total loss = -11.174141883850098, reconstruct loss = 0.07724294066429138, cluster loss = 0.03835535794496536, calm loss = 1.2471497058868408, pilot loss = 13.096392631530762, max interval = -38.88903045654297, \n",
      "Train ACC: 0.8, PTA: 0.173828125, Test ACC: 0.6612903225806451\n",
      "282, total loss = -11.230939865112305, reconstruct loss = 0.07364051043987274, cluster loss = 0.03671886399388313, calm loss = 1.2508617639541626, pilot loss = 13.149317741394043, max interval = -39.043800354003906, \n",
      "Train ACC: 0.8, PTA: 0.1669921875, Test ACC: 0.6612903225806451\n",
      "283, total loss = -11.283068656921387, reconstruct loss = 0.07221513241529465, cluster loss = 0.03783361241221428, calm loss = 1.2547353506088257, pilot loss = 13.203173637390137, max interval = -39.20050048828125, \n",
      "Train ACC: 0.8, PTA: 0.1650390625, Test ACC: 0.6612903225806451\n",
      "284, total loss = -11.333106994628906, reconstruct loss = 0.07267557084560394, cluster loss = 0.03825313597917557, calm loss = 1.2591615915298462, pilot loss = 13.258041381835938, max interval = -39.358154296875, \n",
      "Train ACC: 0.8, PTA: 0.1591796875, Test ACC: 0.6612903225806451\n",
      "285, total loss = -11.387319564819336, reconstruct loss = 0.07220617681741714, cluster loss = 0.03588123247027397, calm loss = 1.2635987997055054, pilot loss = 13.313196182250977, max interval = -39.516876220703125, \n",
      "Train ACC: 0.8, PTA: 0.166015625, Test ACC: 0.6612903225806451\n",
      "286, total loss = -11.433589935302734, reconstruct loss = 0.07734929025173187, cluster loss = 0.03653395548462868, calm loss = 1.2685236930847168, pilot loss = 13.36237907409668, max interval = -39.668758392333984, \n",
      "Train ACC: 0.8, PTA: 0.171875, Test ACC: 0.6612903225806451\n",
      "287, total loss = -11.491593360900879, reconstruct loss = 0.06984210759401321, cluster loss = 0.03828936070203781, calm loss = 1.2750205993652344, pilot loss = 13.41749095916748, max interval = -39.83162307739258, \n",
      "Train ACC: 0.8, PTA: 0.15234375, Test ACC: 0.6612903225806451\n",
      "288, total loss = -11.547574996948242, reconstruct loss = 0.0677265077829361, cluster loss = 0.037459325045347214, calm loss = 1.2814326286315918, pilot loss = 13.475973129272461, max interval = -40.000301361083984, \n",
      "Train ACC: 0.8, PTA: 0.1611328125, Test ACC: 0.6612903225806451\n",
      "289, total loss = -11.596712112426758, reconstruct loss = 0.06985712796449661, cluster loss = 0.038863975554704666, calm loss = 1.2883517742156982, pilot loss = 13.538287162780762, max interval = -40.174659729003906, \n",
      "Train ACC: 0.8, PTA: 0.181640625, Test ACC: 0.6612903225806451\n",
      "290, total loss = -11.65288257598877, reconstruct loss = 0.06880105286836624, cluster loss = 0.038134511560201645, calm loss = 1.293395757675171, pilot loss = 13.600605964660645, max interval = -40.348793029785156, \n",
      "Train ACC: 0.8, PTA: 0.15234375, Test ACC: 0.6612903225806451\n",
      "291, total loss = -11.701693534851074, reconstruct loss = 0.0710553377866745, cluster loss = 0.038323841989040375, calm loss = 1.2994762659072876, pilot loss = 13.6549711227417, max interval = -40.50857162475586, \n",
      "Train ACC: 0.8, PTA: 0.1513671875, Test ACC: 0.6612903225806451\n",
      "292, total loss = -11.756546974182129, reconstruct loss = 0.07409999519586563, cluster loss = 0.034666698426008224, calm loss = 1.303490400314331, pilot loss = 13.710891723632812, max interval = -40.6718864440918, \n",
      "Train ACC: 0.8, PTA: 0.1611328125, Test ACC: 0.6612903225806451\n",
      "293, total loss = -11.808767318725586, reconstruct loss = 0.07322419434785843, cluster loss = 0.037674907594919205, calm loss = 1.3082162141799927, pilot loss = 13.770090103149414, max interval = -40.841060638427734, \n",
      "Train ACC: 0.8, PTA: 0.166015625, Test ACC: 0.6612903225806451\n",
      "294, total loss = -11.86166000366211, reconstruct loss = 0.07380709797143936, cluster loss = 0.036964718252420425, calm loss = 1.3150209188461304, pilot loss = 13.836685180664062, max interval = -41.02150344848633, \n",
      "Train ACC: 0.8, PTA: 0.1572265625, Test ACC: 0.6612903225806451\n",
      "295, total loss = -11.91573429107666, reconstruct loss = 0.07258744537830353, cluster loss = 0.03816914185881615, calm loss = 1.3209340572357178, pilot loss = 13.896589279174805, max interval = -41.192962646484375, \n",
      "Train ACC: 0.8, PTA: 0.162109375, Test ACC: 0.6612903225806451\n",
      "296, total loss = -11.970321655273438, reconstruct loss = 0.07114604115486145, cluster loss = 0.03896138444542885, calm loss = 1.3265825510025024, pilot loss = 13.95747184753418, max interval = -41.36526870727539, \n",
      "Train ACC: 0.8, PTA: 0.1640625, Test ACC: 0.6612903225806451\n",
      "297, total loss = -12.027459144592285, reconstruct loss = 0.0693807303905487, cluster loss = 0.038482457399368286, calm loss = 1.3321914672851562, pilot loss = 14.019943237304688, max interval = -41.54115676879883, \n",
      "Train ACC: 0.8, PTA: 0.1455078125, Test ACC: 0.6612903225806451\n",
      "298, total loss = -12.078348159790039, reconstruct loss = 0.07338736951351166, cluster loss = 0.03861948102712631, calm loss = 1.3387113809585571, pilot loss = 14.087170600891113, max interval = -41.725337982177734, \n",
      "Train ACC: 0.8, PTA: 0.142578125, Test ACC: 0.6612903225806451\n",
      "299, total loss = -12.137870788574219, reconstruct loss = 0.07112743705511093, cluster loss = 0.037215523421764374, calm loss = 1.345022439956665, pilot loss = 14.149169921875, max interval = -41.90293502807617, \n",
      "Train ACC: 0.8, PTA: 0.1689453125, Test ACC: 0.6612903225806451\n",
      "300, total loss = -12.19093132019043, reconstruct loss = 0.0716269314289093, cluster loss = 0.035443585366010666, calm loss = 1.3531756401062012, pilot loss = 14.210655212402344, max interval = -42.07661437988281, \n",
      "Train ACC: 0.8, PTA: 0.150390625, Test ACC: 0.6612903225806451\n",
      "301, total loss = -12.244515419006348, reconstruct loss = 0.07053351402282715, cluster loss = 0.03836089000105858, calm loss = 1.3585522174835205, pilot loss = 14.273045539855957, max interval = -42.25278854370117, \n",
      "Train ACC: 0.8, PTA: 0.1552734375, Test ACC: 0.6612903225806451\n",
      "302, total loss = -12.302010536193848, reconstruct loss = 0.07422926276922226, cluster loss = 0.035353999584913254, calm loss = 1.3624681234359741, pilot loss = 14.337362289428711, max interval = -42.433597564697266, \n",
      "Train ACC: 0.8, PTA: 0.1748046875, Test ACC: 0.6612903225806451\n",
      "303, total loss = -12.357177734375, reconstruct loss = 0.07237756252288818, cluster loss = 0.037027668207883835, calm loss = 1.3688856363296509, pilot loss = 14.40429401397705, max interval = -42.61715316772461, \n",
      "Train ACC: 0.8, PTA: 0.15234375, Test ACC: 0.6612903225806451\n",
      "304, total loss = -12.413215637207031, reconstruct loss = 0.07277709990739822, cluster loss = 0.037098173052072525, calm loss = 1.3745520114898682, pilot loss = 14.464628219604492, max interval = -42.79237747192383, \n",
      "Train ACC: 0.8, PTA: 0.1640625, Test ACC: 0.6612903225806451\n",
      "305, total loss = -12.474315643310547, reconstruct loss = 0.06846129894256592, cluster loss = 0.036517415195703506, calm loss = 1.3812534809112549, pilot loss = 14.527804374694824, max interval = -42.97270584106445, \n",
      "Train ACC: 0.8, PTA: 0.1494140625, Test ACC: 0.6612903225806451\n",
      "306, total loss = -12.523377418518066, reconstruct loss = 0.07621236890554428, cluster loss = 0.036434002220630646, calm loss = 1.3881142139434814, pilot loss = 14.596056938171387, max interval = -43.1612663269043, \n",
      "Train ACC: 0.8, PTA: 0.1650390625, Test ACC: 0.6612903225806451\n",
      "307, total loss = -12.581417083740234, reconstruct loss = 0.07554269582033157, cluster loss = 0.035931386053562164, calm loss = 1.3955073356628418, pilot loss = 14.667012214660645, max interval = -43.35464859008789, \n",
      "Train ACC: 0.8, PTA: 0.169921875, Test ACC: 0.6612903225806451\n",
      "308, total loss = -12.641342163085938, reconstruct loss = 0.07118985801935196, cluster loss = 0.037107255309820175, calm loss = 1.4015592336654663, pilot loss = 14.72953987121582, max interval = -43.53390121459961, \n",
      "Train ACC: 0.8, PTA: 0.1591796875, Test ACC: 0.6612903225806451\n",
      "309, total loss = -12.704523086547852, reconstruct loss = 0.06885826587677002, cluster loss = 0.03448629751801491, calm loss = 1.4054845571517944, pilot loss = 14.793540954589844, max interval = -43.71433639526367, \n",
      "Train ACC: 0.8, PTA: 0.15234375, Test ACC: 0.6612903225806451\n",
      "310, total loss = -12.757109642028809, reconstruct loss = 0.0716235563158989, cluster loss = 0.03618645668029785, calm loss = 1.4104268550872803, pilot loss = 14.858708381652832, max interval = -43.896209716796875, \n",
      "Train ACC: 0.8, PTA: 0.1591796875, Test ACC: 0.6612903225806451\n",
      "311, total loss = -12.810361862182617, reconstruct loss = 0.07354234904050827, cluster loss = 0.03749151900410652, calm loss = 1.4176712036132812, pilot loss = 14.930081367492676, max interval = -44.089412689208984, \n",
      "Train ACC: 0.8, PTA: 0.1640625, Test ACC: 0.6612903225806451\n",
      "312, total loss = -12.869913101196289, reconstruct loss = 0.07470071315765381, cluster loss = 0.035351693630218506, calm loss = 1.4240975379943848, pilot loss = 14.994653701782227, max interval = -44.27472686767578, \n",
      "Train ACC: 0.8, PTA: 0.16796875, Test ACC: 0.6612903225806451\n",
      "313, total loss = -12.928526878356934, reconstruct loss = 0.07319433987140656, cluster loss = 0.03735893592238426, calm loss = 1.4313881397247314, pilot loss = 15.062350273132324, max interval = -44.466514587402344, \n",
      "Train ACC: 0.8, PTA: 0.1455078125, Test ACC: 0.6612903225806451\n",
      "314, total loss = -12.994772911071777, reconstruct loss = 0.0658477172255516, cluster loss = 0.03669986128807068, calm loss = 1.4394326210021973, pilot loss = 15.132963180541992, max interval = -44.66230010986328, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.6612903225806451\n",
      "315, total loss = -13.044316291809082, reconstruct loss = 0.07438304275274277, cluster loss = 0.03826155513525009, calm loss = 1.4466359615325928, pilot loss = 15.207300186157227, max interval = -44.864200592041016, \n",
      "Train ACC: 0.8, PTA: 0.1611328125, Test ACC: 0.6612903225806451\n",
      "316, total loss = -13.112503051757812, reconstruct loss = 0.06802864372730255, cluster loss = 0.036861106753349304, calm loss = 1.4520263671875, pilot loss = 15.272863388061523, max interval = -45.05210876464844, \n",
      "Train ACC: 0.8, PTA: 0.1494140625, Test ACC: 0.6612903225806451\n",
      "317, total loss = -13.165040969848633, reconstruct loss = 0.07715354859828949, cluster loss = 0.03615499660372734, calm loss = 1.45774245262146, pilot loss = 15.344064712524414, max interval = -45.24928665161133, \n",
      "Train ACC: 0.8, PTA: 0.1484375, Test ACC: 0.6612903225806451\n",
      "318, total loss = -13.226743698120117, reconstruct loss = 0.0750458836555481, cluster loss = 0.03664599359035492, calm loss = 1.4626907110214233, pilot loss = 15.418164253234863, max interval = -45.448265075683594, \n",
      "Train ACC: 0.8, PTA: 0.1455078125, Test ACC: 0.6612903225806451\n",
      "319, total loss = -13.291964530944824, reconstruct loss = 0.07074446976184845, cluster loss = 0.035489462316036224, calm loss = 1.4691765308380127, pilot loss = 15.494695663452148, max interval = -45.6524543762207, \n",
      "Train ACC: 0.8, PTA: 0.1513671875, Test ACC: 0.6612903225806451\n",
      "320, total loss = -13.348957061767578, reconstruct loss = 0.07145971059799194, cluster loss = 0.03705168515443802, calm loss = 1.4770804643630981, pilot loss = 15.57379150390625, max interval = -45.861629486083984, \n",
      "Train ACC: 0.8, PTA: 0.1455078125, Test ACC: 0.6612903225806451\n",
      "321, total loss = -13.410135269165039, reconstruct loss = 0.0741073489189148, cluster loss = 0.033916205167770386, calm loss = 1.4838314056396484, pilot loss = 15.646041870117188, max interval = -46.061405181884766, \n",
      "Train ACC: 0.8, PTA: 0.1552734375, Test ACC: 0.6612903225806451\n",
      "322, total loss = -13.4747953414917, reconstruct loss = 0.06438405066728592, cluster loss = 0.039246540516614914, calm loss = 1.4909708499908447, pilot loss = 15.718330383300781, max interval = -46.261192321777344, \n",
      "Train ACC: 0.8, PTA: 0.1533203125, Test ACC: 0.6612903225806451\n",
      "323, total loss = -13.530271530151367, reconstruct loss = 0.07163882255554199, cluster loss = 0.03774212300777435, calm loss = 1.4979232549667358, pilot loss = 15.791206359863281, max interval = -46.462921142578125, \n",
      "Train ACC: 0.8, PTA: 0.14453125, Test ACC: 0.6612903225806451\n",
      "324, total loss = -13.59454345703125, reconstruct loss = 0.06846268475055695, cluster loss = 0.03812812641263008, calm loss = 1.5056684017181396, pilot loss = 15.866630554199219, max interval = -46.6697883605957, \n",
      "Train ACC: 0.8, PTA: 0.1435546875, Test ACC: 0.6612903225806451\n",
      "325, total loss = -13.658491134643555, reconstruct loss = 0.06728809326887131, cluster loss = 0.0370253250002861, calm loss = 1.5122671127319336, pilot loss = 15.938990592956543, max interval = -46.870906829833984, \n",
      "Train ACC: 0.8, PTA: 0.15625, Test ACC: 0.6612903225806451\n",
      "326, total loss = -13.713164329528809, reconstruct loss = 0.07443134486675262, cluster loss = 0.0366155244410038, calm loss = 1.5177726745605469, pilot loss = 16.012218475341797, max interval = -47.071327209472656, \n",
      "Train ACC: 0.8, PTA: 0.16796875, Test ACC: 0.6612903225806451\n",
      "327, total loss = -13.78364086151123, reconstruct loss = 0.06564957648515701, cluster loss = 0.03692464530467987, calm loss = 1.5225551128387451, pilot loss = 16.08561897277832, max interval = -47.271812438964844, \n",
      "Train ACC: 0.8, PTA: 0.1611328125, Test ACC: 0.6612903225806451\n",
      "328, total loss = -13.840736389160156, reconstruct loss = 0.07240542024374008, cluster loss = 0.03506343811750412, calm loss = 1.5275466442108154, pilot loss = 16.159420013427734, max interval = -47.473148345947266, \n",
      "Train ACC: 0.8, PTA: 0.14453125, Test ACC: 0.6612903225806451\n",
      "329, total loss = -13.903426170349121, reconstruct loss = 0.0720457136631012, cluster loss = 0.03449590504169464, calm loss = 1.532738447189331, pilot loss = 16.232906341552734, max interval = -47.67399978637695, \n",
      "Train ACC: 0.8, PTA: 0.14453125, Test ACC: 0.6612903225806451\n",
      "330, total loss = -13.965819358825684, reconstruct loss = 0.06957036256790161, cluster loss = 0.03770940750837326, calm loss = 1.5372986793518066, pilot loss = 16.300098419189453, max interval = -47.866912841796875, \n",
      "Train ACC: 0.8, PTA: 0.1640625, Test ACC: 0.6612903225806451\n",
      "331, total loss = -14.022432327270508, reconstruct loss = 0.07684540003538132, cluster loss = 0.036886412650346756, calm loss = 1.5438239574432373, pilot loss = 16.37441635131836, max interval = -48.072723388671875, \n",
      "Train ACC: 0.8, PTA: 0.1845703125, Test ACC: 0.6612903225806451\n",
      "332, total loss = -14.093645095825195, reconstruct loss = 0.06852010637521744, cluster loss = 0.037490539252758026, calm loss = 1.5521717071533203, pilot loss = 16.455520629882812, max interval = -48.291439056396484, \n",
      "Train ACC: 0.8, PTA: 0.1513671875, Test ACC: 0.6612903225806451\n",
      "333, total loss = -14.158252716064453, reconstruct loss = 0.06897782534360886, cluster loss = 0.035751428455114365, calm loss = 1.5612143278121948, pilot loss = 16.54092025756836, max interval = -48.51705551147461, \n",
      "Train ACC: 0.8, PTA: 0.142578125, Test ACC: 0.6612903225806451\n",
      "334, total loss = -14.217362403869629, reconstruct loss = 0.07169388234615326, cluster loss = 0.03590724989771843, calm loss = 1.5699937343597412, pilot loss = 16.616994857788086, max interval = -48.727046966552734, \n",
      "Train ACC: 0.8, PTA: 0.15234375, Test ACC: 0.6612903225806451\n",
      "335, total loss = -14.281166076660156, reconstruct loss = 0.07261906564235687, cluster loss = 0.03647376224398613, calm loss = 1.5768382549285889, pilot loss = 16.69357681274414, max interval = -48.939735412597656, \n",
      "Train ACC: 0.8, PTA: 0.1474609375, Test ACC: 0.6612903225806451\n",
      "336, total loss = -14.347930908203125, reconstruct loss = 0.07091155648231506, cluster loss = 0.03545950725674629, calm loss = 1.5837345123291016, pilot loss = 16.76963996887207, max interval = -49.149967193603516, \n",
      "Train ACC: 0.8, PTA: 0.1416015625, Test ACC: 0.6612903225806451\n",
      "337, total loss = -14.410592079162598, reconstruct loss = 0.07258067280054092, cluster loss = 0.03585172817111015, calm loss = 1.590078592300415, pilot loss = 16.847368240356445, max interval = -49.362762451171875, \n",
      "Train ACC: 0.8, PTA: 0.158203125, Test ACC: 0.6612903225806451\n",
      "338, total loss = -14.476802825927734, reconstruct loss = 0.07070154696702957, cluster loss = 0.03609529882669449, calm loss = 1.5961980819702148, pilot loss = 16.926645278930664, max interval = -49.577232360839844, \n",
      "Train ACC: 0.8, PTA: 0.1416015625, Test ACC: 0.6612903225806451\n",
      "339, total loss = -14.54403018951416, reconstruct loss = 0.07080521434545517, cluster loss = 0.03474530950188637, calm loss = 1.6021473407745361, pilot loss = 17.000436782836914, max interval = -49.785640716552734, \n",
      "Train ACC: 0.8, PTA: 0.1435546875, Test ACC: 0.6612903225806451\n",
      "340, total loss = -14.608661651611328, reconstruct loss = 0.06951046735048294, cluster loss = 0.037515681236982346, calm loss = 1.608694076538086, pilot loss = 17.068674087524414, max interval = -49.987144470214844, \n",
      "Train ACC: 0.8, PTA: 0.1328125, Test ACC: 0.6612903225806451\n",
      "341, total loss = -14.675223350524902, reconstruct loss = 0.06996873766183853, cluster loss = 0.037748102098703384, calm loss = 1.6163743734359741, pilot loss = 17.142078399658203, max interval = -50.19928741455078, \n",
      "Train ACC: 0.8, PTA: 0.1376953125, Test ACC: 0.6612903225806451\n",
      "342, total loss = -14.745628356933594, reconstruct loss = 0.06884747743606567, cluster loss = 0.03636269271373749, calm loss = 1.6250145435333252, pilot loss = 17.221019744873047, max interval = -50.421630859375, \n",
      "Train ACC: 0.8, PTA: 0.1572265625, Test ACC: 0.6612903225806451\n",
      "343, total loss = -14.811606407165527, reconstruct loss = 0.07127556204795837, cluster loss = 0.03470918536186218, calm loss = 1.6346076726913452, pilot loss = 17.300830841064453, max interval = -50.64494323730469, \n",
      "Train ACC: 0.8, PTA: 0.12890625, Test ACC: 0.6612903225806451\n",
      "344, total loss = -14.882221221923828, reconstruct loss = 0.06701964139938354, cluster loss = 0.036494385451078415, calm loss = 1.6425483226776123, pilot loss = 17.379772186279297, max interval = -50.866634368896484, \n",
      "Train ACC: 0.8, PTA: 0.1396484375, Test ACC: 0.6612903225806451\n",
      "345, total loss = -14.946924209594727, reconstruct loss = 0.07253681123256683, cluster loss = 0.03451136127114296, calm loss = 1.6502504348754883, pilot loss = 17.45743179321289, max interval = -51.08628845214844, \n",
      "Train ACC: 0.8, PTA: 0.154296875, Test ACC: 0.6612903225806451\n",
      "346, total loss = -15.0135498046875, reconstruct loss = 0.07333410531282425, cluster loss = 0.03544105216860771, calm loss = 1.6583398580551147, pilot loss = 17.53701400756836, max interval = -51.309417724609375, \n",
      "Train ACC: 0.8, PTA: 0.1318359375, Test ACC: 0.6612903225806451\n",
      "347, total loss = -15.092270851135254, reconstruct loss = 0.06433488428592682, cluster loss = 0.03462580591440201, calm loss = 1.6663398742675781, pilot loss = 17.618730545043945, max interval = -51.536251068115234, \n",
      "Train ACC: 0.8, PTA: 0.142578125, Test ACC: 0.6612903225806451\n",
      "348, total loss = -15.152534484863281, reconstruct loss = 0.07186146825551987, cluster loss = 0.03567030653357506, calm loss = 1.6748015880584717, pilot loss = 17.70305824279785, max interval = -51.767372131347656, \n",
      "Train ACC: 0.8, PTA: 0.150390625, Test ACC: 0.6612903225806451\n",
      "349, total loss = -15.225761413574219, reconstruct loss = 0.07091868668794632, cluster loss = 0.03359856456518173, calm loss = 1.681903600692749, pilot loss = 17.780197143554688, max interval = -51.98824691772461, \n",
      "Train ACC: 0.8, PTA: 0.140625, Test ACC: 0.6612903225806451\n",
      "350, total loss = -15.293932914733887, reconstruct loss = 0.07025090605020523, cluster loss = 0.03619330748915672, calm loss = 1.689664602279663, pilot loss = 17.85853385925293, max interval = -52.211612701416016, \n",
      "Train ACC: 0.8, PTA: 0.1357421875, Test ACC: 0.6612903225806451\n",
      "351, total loss = -15.367959022521973, reconstruct loss = 0.0677073746919632, cluster loss = 0.03490770608186722, calm loss = 1.6980499029159546, pilot loss = 17.94033432006836, max interval = -52.44096755981445, \n",
      "Train ACC: 0.8, PTA: 0.1318359375, Test ACC: 0.6612903225806451\n",
      "352, total loss = -15.432332992553711, reconstruct loss = 0.07164044678211212, cluster loss = 0.036656226962804794, calm loss = 1.7043602466583252, pilot loss = 18.010587692260742, max interval = -52.65065383911133, \n",
      "Train ACC: 0.8, PTA: 0.1611328125, Test ACC: 0.6612903225806451\n",
      "353, total loss = -15.506641387939453, reconstruct loss = 0.07122407853603363, cluster loss = 0.03379962965846062, calm loss = 1.7098987102508545, pilot loss = 18.08470916748047, max interval = -52.86616516113281, \n",
      "Train ACC: 0.8, PTA: 0.146484375, Test ACC: 0.6612903225806451\n",
      "354, total loss = -15.576525688171387, reconstruct loss = 0.06865375488996506, cluster loss = 0.03699735179543495, calm loss = 1.7154948711395264, pilot loss = 18.16046905517578, max interval = -53.083351135253906, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.6612903225806451\n",
      "355, total loss = -15.65499210357666, reconstruct loss = 0.06462636590003967, cluster loss = 0.0341288186609745, calm loss = 1.7221940755844116, pilot loss = 18.240558624267578, max interval = -53.309814453125, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6612903225806451\n",
      "356, total loss = -15.722549438476562, reconstruct loss = 0.06900535523891449, cluster loss = 0.03663387894630432, calm loss = 1.7295576333999634, pilot loss = 18.326053619384766, max interval = -53.549041748046875, \n",
      "Train ACC: 0.8, PTA: 0.140625, Test ACC: 0.6612903225806451\n",
      "357, total loss = -15.795112609863281, reconstruct loss = 0.07437711954116821, cluster loss = 0.03566271439194679, calm loss = 1.7348006963729858, pilot loss = 18.40028953552246, max interval = -53.772769927978516, \n",
      "Train ACC: 0.8, PTA: 0.1533203125, Test ACC: 0.6612903225806451\n",
      "358, total loss = -15.879546165466309, reconstruct loss = 0.06717954576015472, cluster loss = 0.03607438877224922, calm loss = 1.7405544519424438, pilot loss = 18.474231719970703, max interval = -53.99778366088867, \n",
      "Train ACC: 0.8, PTA: 0.1396484375, Test ACC: 0.6612903225806451\n",
      "359, total loss = -15.956329345703125, reconstruct loss = 0.06752648204565048, cluster loss = 0.03546743094921112, calm loss = 1.7484285831451416, pilot loss = 18.555179595947266, max interval = -54.234222412109375, \n",
      "Train ACC: 0.8, PTA: 0.154296875, Test ACC: 0.6612903225806451\n",
      "360, total loss = -16.030616760253906, reconstruct loss = 0.07098055630922318, cluster loss = 0.03725310042500496, calm loss = 1.7558715343475342, pilot loss = 18.630985260009766, max interval = -54.46699523925781, \n",
      "Train ACC: 0.8, PTA: 0.140625, Test ACC: 0.6612903225806451\n",
      "361, total loss = -16.110532760620117, reconstruct loss = 0.071711465716362, cluster loss = 0.03491976112127304, calm loss = 1.7642844915390015, pilot loss = 18.710567474365234, max interval = -54.70481491088867, \n",
      "Train ACC: 0.8, PTA: 0.1494140625, Test ACC: 0.6612903225806451\n",
      "362, total loss = -16.19515037536621, reconstruct loss = 0.06564594060182571, cluster loss = 0.036050084978342056, calm loss = 1.7742265462875366, pilot loss = 18.801462173461914, max interval = -54.96294021606445, \n",
      "Train ACC: 0.8, PTA: 0.1396484375, Test ACC: 0.6612903225806451\n",
      "363, total loss = -16.27145004272461, reconstruct loss = 0.06927117705345154, cluster loss = 0.0355362631380558, calm loss = 1.786110281944275, pilot loss = 18.90148162841797, max interval = -55.236480712890625, \n",
      "Train ACC: 0.8, PTA: 0.1337890625, Test ACC: 0.6612903225806451\n",
      "364, total loss = -16.35369873046875, reconstruct loss = 0.07001610100269318, cluster loss = 0.034440185874700546, calm loss = 1.7955982685089111, pilot loss = 18.99246597290039, max interval = -55.49724578857422, \n",
      "Train ACC: 0.8, PTA: 0.1416015625, Test ACC: 0.6451612903225806\n",
      "365, total loss = -16.441347122192383, reconstruct loss = 0.06172473356127739, cluster loss = 0.03764283284544945, calm loss = 1.8031667470932007, pilot loss = 19.076915740966797, max interval = -55.74687957763672, \n",
      "Train ACC: 0.8, PTA: 0.1328125, Test ACC: 0.6290322580645161\n",
      "366, total loss = -16.521238327026367, reconstruct loss = 0.06614810228347778, cluster loss = 0.03262380138039589, calm loss = 1.810675859451294, pilot loss = 19.169225692749023, max interval = -56.002994537353516, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.6290322580645161\n",
      "367, total loss = -16.600170135498047, reconstruct loss = 0.061451736837625504, cluster loss = 0.0379338338971138, calm loss = 1.8195598125457764, pilot loss = 19.272541046142578, max interval = -56.27715301513672, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6290322580645161\n",
      "368, total loss = -16.67178726196289, reconstruct loss = 0.07275177538394928, cluster loss = 0.036553096026182175, calm loss = 1.8299062252044678, pilot loss = 19.38109588623047, max interval = -56.563724517822266, \n",
      "Train ACC: 0.8, PTA: 0.140625, Test ACC: 0.6290322580645161\n",
      "369, total loss = -16.759431838989258, reconstruct loss = 0.06745851784944534, cluster loss = 0.03525041788816452, calm loss = 1.8403478860855103, pilot loss = 19.492719650268555, max interval = -56.854122161865234, \n",
      "Train ACC: 0.8, PTA: 0.1357421875, Test ACC: 0.6290322580645161\n",
      "370, total loss = -16.845855712890625, reconstruct loss = 0.06788414716720581, cluster loss = 0.03516210615634918, calm loss = 1.8481388092041016, pilot loss = 19.59829330444336, max interval = -57.1402587890625, \n",
      "Train ACC: 0.8, PTA: 0.1357421875, Test ACC: 0.6290322580645161\n",
      "371, total loss = -16.92867088317871, reconstruct loss = 0.07277735322713852, cluster loss = 0.03652257099747658, calm loss = 1.8546819686889648, pilot loss = 19.706432342529297, max interval = -57.43156814575195, \n",
      "Train ACC: 0.8, PTA: 0.1376953125, Test ACC: 0.6290322580645161\n",
      "372, total loss = -17.029430389404297, reconstruct loss = 0.06704604625701904, cluster loss = 0.03240107372403145, calm loss = 1.8596700429916382, pilot loss = 19.818584442138672, max interval = -57.72902297973633, \n",
      "Train ACC: 0.8, PTA: 0.12890625, Test ACC: 0.6129032258064516\n",
      "373, total loss = -17.118389129638672, reconstruct loss = 0.06427018344402313, cluster loss = 0.03332402929663658, calm loss = 1.8641631603240967, pilot loss = 19.92535400390625, max interval = -58.01264953613281, \n",
      "Train ACC: 0.8, PTA: 0.13671875, Test ACC: 0.6129032258064516\n",
      "374, total loss = -17.198822021484375, reconstruct loss = 0.0686977282166481, cluster loss = 0.0359446182847023, calm loss = 1.8694477081298828, pilot loss = 20.034528732299805, max interval = -58.3013801574707, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.6129032258064516\n",
      "375, total loss = -17.28429412841797, reconstruct loss = 0.06798024475574493, cluster loss = 0.03661438077688217, calm loss = 1.8742883205413818, pilot loss = 20.14156150817871, max interval = -58.58347702026367, \n",
      "Train ACC: 0.8, PTA: 0.13671875, Test ACC: 0.6129032258064516\n",
      "376, total loss = -17.372024536132812, reconstruct loss = 0.06731909513473511, cluster loss = 0.035836804658174515, calm loss = 1.875928521156311, pilot loss = 20.234106063842773, max interval = -58.841548919677734, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.6129032258064516\n",
      "377, total loss = -17.45524787902832, reconstruct loss = 0.07040522992610931, cluster loss = 0.034910086542367935, calm loss = 1.8768177032470703, pilot loss = 20.31717872619629, max interval = -59.083717346191406, \n",
      "Train ACC: 0.8, PTA: 0.1396484375, Test ACC: 0.6129032258064516\n",
      "378, total loss = -17.545265197753906, reconstruct loss = 0.06469281762838364, cluster loss = 0.03634043410420418, calm loss = 1.8780090808868408, pilot loss = 20.401653289794922, max interval = -59.328819274902344, \n",
      "Train ACC: 0.8, PTA: 0.1328125, Test ACC: 0.6129032258064516\n",
      "379, total loss = -17.6309871673584, reconstruct loss = 0.06763313710689545, cluster loss = 0.034918107092380524, calm loss = 1.8802413940429688, pilot loss = 20.49054527282715, max interval = -59.5838737487793, \n",
      "Train ACC: 0.8, PTA: 0.140625, Test ACC: 0.6129032258064516\n",
      "380, total loss = -17.718395233154297, reconstruct loss = 0.0659339427947998, cluster loss = 0.03624477609992027, calm loss = 1.8830963373184204, pilot loss = 20.580060958862305, max interval = -59.840415954589844, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.6129032258064516\n",
      "381, total loss = -17.80658721923828, reconstruct loss = 0.06666024029254913, cluster loss = 0.03566238656640053, calm loss = 1.8872658014297485, pilot loss = 20.672107696533203, max interval = -60.104312896728516, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.6129032258064516\n",
      "382, total loss = -17.897201538085938, reconstruct loss = 0.0698665902018547, cluster loss = 0.032285723835229874, calm loss = 1.8897758722305298, pilot loss = 20.763935089111328, max interval = -60.368534088134766, \n",
      "Train ACC: 0.8, PTA: 0.1416015625, Test ACC: 0.6129032258064516\n",
      "383, total loss = -17.991188049316406, reconstruct loss = 0.06895837187767029, cluster loss = 0.03366946056485176, calm loss = 1.8942941427230835, pilot loss = 20.86135482788086, max interval = -60.649356842041016, \n",
      "Train ACC: 0.8, PTA: 0.1533203125, Test ACC: 0.6129032258064516\n",
      "384, total loss = -18.09221649169922, reconstruct loss = 0.06656777113676071, cluster loss = 0.03629150241613388, calm loss = 1.896205186843872, pilot loss = 20.961856842041016, max interval = -60.9405632019043, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.6129032258064516\n",
      "385, total loss = -18.202428817749023, reconstruct loss = 0.06705691665410995, cluster loss = 0.036435507237911224, calm loss = 1.8969430923461914, pilot loss = 21.07620620727539, max interval = -61.263572692871094, \n",
      "Train ACC: 0.8, PTA: 0.1455078125, Test ACC: 0.6129032258064516\n",
      "386, total loss = -18.314987182617188, reconstruct loss = 0.06683750450611115, cluster loss = 0.035003505647182465, calm loss = 1.9003465175628662, pilot loss = 21.200328826904297, max interval = -61.60443878173828, \n",
      "Train ACC: 0.8, PTA: 0.140625, Test ACC: 0.5967741935483871\n",
      "387, total loss = -18.429092407226562, reconstruct loss = 0.06274924427270889, cluster loss = 0.03689834475517273, calm loss = 1.904240369796753, pilot loss = 21.329891204833984, max interval = -61.95521545410156, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "388, total loss = -18.541189193725586, reconstruct loss = 0.06733796000480652, cluster loss = 0.03491656109690666, calm loss = 1.907117247581482, pilot loss = 21.455310821533203, max interval = -62.3026123046875, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "389, total loss = -18.660696029663086, reconstruct loss = 0.06452243775129318, cluster loss = 0.03394126892089844, calm loss = 1.9103939533233643, pilot loss = 21.582454681396484, max interval = -62.65448760986328, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "390, total loss = -18.776153564453125, reconstruct loss = 0.06464768201112747, cluster loss = 0.03249220922589302, calm loss = 1.9153919219970703, pilot loss = 21.719898223876953, max interval = -63.02127456665039, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "391, total loss = -18.88357162475586, reconstruct loss = 0.06981071829795837, cluster loss = 0.03682493790984154, calm loss = 1.9194990396499634, pilot loss = 21.864299774169922, max interval = -63.40070724487305, \n",
      "Train ACC: 0.8, PTA: 0.1337890625, Test ACC: 0.5967741935483871\n",
      "392, total loss = -19.00507354736328, reconstruct loss = 0.06783367693424225, cluster loss = 0.03450251370668411, calm loss = 1.9227075576782227, pilot loss = 22.01633071899414, max interval = -63.790164947509766, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "393, total loss = -19.11992073059082, reconstruct loss = 0.06741124391555786, cluster loss = 0.03698723390698433, calm loss = 1.9259960651397705, pilot loss = 22.166175842285156, max interval = -64.17620086669922, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "394, total loss = -19.243528366088867, reconstruct loss = 0.06681202352046967, cluster loss = 0.033990852534770966, calm loss = 1.9276288747787476, pilot loss = 22.3172664642334, max interval = -64.56608581542969, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "395, total loss = -19.3647403717041, reconstruct loss = 0.06335509568452835, cluster loss = 0.033095166087150574, calm loss = 1.9314206838607788, pilot loss = 22.469562530517578, max interval = -64.9562759399414, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "396, total loss = -19.482040405273438, reconstruct loss = 0.06512653827667236, cluster loss = 0.032768361270427704, calm loss = 1.932822585105896, pilot loss = 22.611530303955078, max interval = -65.33098602294922, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "397, total loss = -19.59334373474121, reconstruct loss = 0.07184286415576935, cluster loss = 0.033149540424346924, calm loss = 1.9337794780731201, pilot loss = 22.752336502075195, max interval = -65.70291137695312, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.5967741935483871\n",
      "398, total loss = -19.71782875061035, reconstruct loss = 0.06885908544063568, cluster loss = 0.03316732868552208, calm loss = 1.9315154552459717, pilot loss = 22.887563705444336, max interval = -66.06672668457031, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.5967741935483871\n",
      "399, total loss = -19.8347225189209, reconstruct loss = 0.06719080358743668, cluster loss = 0.036998771131038666, calm loss = 1.9281173944473267, pilot loss = 23.026063919067383, max interval = -66.43008422851562, \n",
      "Train ACC: 0.8, PTA: 0.138671875, Test ACC: 0.5967741935483871\n",
      "400, total loss = -19.959043502807617, reconstruct loss = 0.06564424932003021, cluster loss = 0.033388443291187286, calm loss = 1.9255075454711914, pilot loss = 23.171268463134766, max interval = -66.80429077148438, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.5967741935483871\n",
      "401, total loss = -20.078582763671875, reconstruct loss = 0.06686883419752121, cluster loss = 0.03385384380817413, calm loss = 1.9225448369979858, pilot loss = 23.315677642822266, max interval = -67.17981719970703, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "402, total loss = -20.201282501220703, reconstruct loss = 0.06705344468355179, cluster loss = 0.03383086249232292, calm loss = 1.9196159839630127, pilot loss = 23.45566749572754, max interval = -67.55140686035156, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "403, total loss = -20.324186325073242, reconstruct loss = 0.06822497397661209, cluster loss = 0.03387269005179405, calm loss = 1.9164698123931885, pilot loss = 23.59933090209961, max interval = -67.92973327636719, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "404, total loss = -20.44657325744629, reconstruct loss = 0.06981909275054932, cluster loss = 0.032264914363622665, calm loss = 1.913104772567749, pilot loss = 23.734392166137695, max interval = -68.29296112060547, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "405, total loss = -20.55974769592285, reconstruct loss = 0.07152466475963593, cluster loss = 0.033094048500061035, calm loss = 1.911954641342163, pilot loss = 23.870555877685547, max interval = -68.65141296386719, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.5967741935483871\n",
      "406, total loss = -20.683683395385742, reconstruct loss = 0.06734469532966614, cluster loss = 0.03248513862490654, calm loss = 1.912623643875122, pilot loss = 24.01853370666504, max interval = -69.03425598144531, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "407, total loss = -20.798986434936523, reconstruct loss = 0.06889864057302475, cluster loss = 0.033486660569906235, calm loss = 1.91372549533844, pilot loss = 24.170230865478516, max interval = -69.42118835449219, \n",
      "Train ACC: 0.8, PTA: 0.12890625, Test ACC: 0.5967741935483871\n",
      "408, total loss = -20.912397384643555, reconstruct loss = 0.0693758875131607, cluster loss = 0.0354483388364315, calm loss = 1.915866494178772, pilot loss = 24.32084083557129, max interval = -69.80518341064453, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.5967741935483871\n",
      "409, total loss = -21.033275604248047, reconstruct loss = 0.06658072769641876, cluster loss = 0.034517861902713776, calm loss = 1.918371558189392, pilot loss = 24.473018646240234, max interval = -70.19380187988281, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.5967741935483871\n",
      "410, total loss = -21.149545669555664, reconstruct loss = 0.06876085698604584, cluster loss = 0.034681741148233414, calm loss = 1.9219720363616943, pilot loss = 24.631351470947266, max interval = -70.5948715209961, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "411, total loss = -21.269243240356445, reconstruct loss = 0.06744079291820526, cluster loss = 0.033138781785964966, calm loss = 1.9268763065338135, pilot loss = 24.790536880493164, max interval = -70.99647521972656, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "412, total loss = -21.382850646972656, reconstruct loss = 0.06853300333023071, cluster loss = 0.034567881375551224, calm loss = 1.9307193756103516, pilot loss = 24.93991470336914, max interval = -71.38154602050781, \n",
      "Train ACC: 0.8, PTA: 0.1328125, Test ACC: 0.5967741935483871\n",
      "413, total loss = -21.49215316772461, reconstruct loss = 0.0682566910982132, cluster loss = 0.03297622501850128, calm loss = 1.9385846853256226, pilot loss = 25.07471466064453, max interval = -71.73912048339844, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.5967741935483871\n",
      "414, total loss = -21.5960750579834, reconstruct loss = 0.06801304221153259, cluster loss = 0.03305312991142273, calm loss = 1.9487909078598022, pilot loss = 25.21230697631836, max interval = -72.0987777709961, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.5967741935483871\n",
      "415, total loss = -21.703399658203125, reconstruct loss = 0.06498681753873825, cluster loss = 0.03363440930843353, calm loss = 1.957824468612671, pilot loss = 25.349544525146484, max interval = -72.45785522460938, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.5967741935483871\n",
      "416, total loss = -21.799888610839844, reconstruct loss = 0.06776615977287292, cluster loss = 0.03318283334374428, calm loss = 1.9702632427215576, pilot loss = 25.488422393798828, max interval = -72.81547546386719, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "417, total loss = -21.896879196166992, reconstruct loss = 0.06607901304960251, cluster loss = 0.03345604985952377, calm loss = 1.9831113815307617, pilot loss = 25.627384185791016, max interval = -73.16918182373047, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "418, total loss = -21.993391036987305, reconstruct loss = 0.06712587922811508, cluster loss = 0.03328892961144447, calm loss = 1.9929330348968506, pilot loss = 25.759979248046875, max interval = -73.5120620727539, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.5967741935483871\n",
      "419, total loss = -22.095460891723633, reconstruct loss = 0.06645310670137405, cluster loss = 0.032951485365629196, calm loss = 2.001711368560791, pilot loss = 25.881322860717773, max interval = -73.84262084960938, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "420, total loss = -22.195220947265625, reconstruct loss = 0.06812314689159393, cluster loss = 0.032790835946798325, calm loss = 2.009877920150757, pilot loss = 26.00283432006836, max interval = -74.17284393310547, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "421, total loss = -22.297698974609375, reconstruct loss = 0.06591688096523285, cluster loss = 0.03567890822887421, calm loss = 2.019129991531372, pilot loss = 26.1328067779541, max interval = -74.51940155029297, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "422, total loss = -22.400768280029297, reconstruct loss = 0.06774219870567322, cluster loss = 0.03367055952548981, calm loss = 2.0292341709136963, pilot loss = 26.274169921875, max interval = -74.88306427001953, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "423, total loss = -22.50739288330078, reconstruct loss = 0.06797861307859421, cluster loss = 0.033261802047491074, calm loss = 2.03841495513916, pilot loss = 26.4169864654541, max interval = -75.25257873535156, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "424, total loss = -22.610118865966797, reconstruct loss = 0.06998638808727264, cluster loss = 0.036420758813619614, calm loss = 2.0467183589935303, pilot loss = 26.557363510131836, max interval = -75.61941528320312, \n",
      "Train ACC: 0.8, PTA: 0.1298828125, Test ACC: 0.5967741935483871\n",
      "425, total loss = -22.725812911987305, reconstruct loss = 0.0645952820777893, cluster loss = 0.03389967232942581, calm loss = 2.054582118988037, pilot loss = 26.6966552734375, max interval = -75.98391723632812, \n",
      "Train ACC: 0.8, PTA: 0.1298828125, Test ACC: 0.5967741935483871\n",
      "426, total loss = -22.830669403076172, reconstruct loss = 0.06698226183652878, cluster loss = 0.034418653696775436, calm loss = 2.0622024536132812, pilot loss = 26.830785751342773, max interval = -76.34066772460938, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "427, total loss = -22.95183563232422, reconstruct loss = 0.06341083347797394, cluster loss = 0.03235691413283348, calm loss = 2.065584182739258, pilot loss = 26.92657470703125, max interval = -76.64768981933594, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "428, total loss = -23.066333770751953, reconstruct loss = 0.06848457455635071, cluster loss = 0.03203146904706955, calm loss = 2.0656790733337402, pilot loss = 27.001922607421875, max interval = -76.92611694335938, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "429, total loss = -23.183645248413086, reconstruct loss = 0.06651338934898376, cluster loss = 0.035397253930568695, calm loss = 2.066479206085205, pilot loss = 27.078296661376953, max interval = -77.20625305175781, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "430, total loss = -23.309776306152344, reconstruct loss = 0.06656161695718765, cluster loss = 0.03075259178876877, calm loss = 2.0671212673187256, pilot loss = 27.154712677001953, max interval = -77.49026489257812, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "431, total loss = -23.42848014831543, reconstruct loss = 0.06889401376247406, cluster loss = 0.03205537796020508, calm loss = 2.0699169635772705, pilot loss = 27.2379207611084, max interval = -77.78820037841797, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "432, total loss = -23.554475784301758, reconstruct loss = 0.06656081229448318, cluster loss = 0.033675819635391235, calm loss = 2.0748953819274902, pilot loss = 27.330150604248047, max interval = -78.10635375976562, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "433, total loss = -23.679853439331055, reconstruct loss = 0.06626160442829132, cluster loss = 0.03495471924543381, calm loss = 2.080592155456543, pilot loss = 27.4267635345459, max interval = -78.4333267211914, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "434, total loss = -23.803363800048828, reconstruct loss = 0.06666530668735504, cluster loss = 0.03542661294341087, calm loss = 2.0890960693359375, pilot loss = 27.523662567138672, max interval = -78.76190185546875, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "435, total loss = -23.933883666992188, reconstruct loss = 0.06516857445240021, cluster loss = 0.0345136821269989, calm loss = 2.093379020690918, pilot loss = 27.60434341430664, max interval = -79.06659698486328, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "436, total loss = -24.063343048095703, reconstruct loss = 0.06504416465759277, cluster loss = 0.03470034524798393, calm loss = 2.0956757068634033, pilot loss = 27.67544174194336, max interval = -79.3567886352539, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "437, total loss = -24.192764282226562, reconstruct loss = 0.06519551575183868, cluster loss = 0.032473303377628326, calm loss = 2.099618673324585, pilot loss = 27.752246856689453, max interval = -79.65437316894531, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.5967741935483871\n",
      "438, total loss = -24.31777572631836, reconstruct loss = 0.06657858192920685, cluster loss = 0.03522350266575813, calm loss = 2.1015896797180176, pilot loss = 27.829421997070312, max interval = -79.95223999023438, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "439, total loss = -24.44417953491211, reconstruct loss = 0.06650137156248093, cluster loss = 0.036377206444740295, calm loss = 2.1044087409973145, pilot loss = 27.910785675048828, max interval = -80.25492858886719, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.5967741935483871\n",
      "440, total loss = -24.569215774536133, reconstruct loss = 0.069322869181633, cluster loss = 0.03390907868742943, calm loss = 2.1053833961486816, pilot loss = 27.9847412109375, max interval = -80.5414047241211, \n",
      "Train ACC: 0.8, PTA: 0.14453125, Test ACC: 0.5967741935483871\n",
      "441, total loss = -24.694660186767578, reconstruct loss = 0.06673553586006165, cluster loss = 0.03485982492566109, calm loss = 2.1057467460632324, pilot loss = 28.053104400634766, max interval = -80.81676483154297, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "442, total loss = -24.819591522216797, reconstruct loss = 0.06777232140302658, cluster loss = 0.03187505155801773, calm loss = 2.108063220977783, pilot loss = 28.13199806213379, max interval = -81.10877990722656, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "443, total loss = -24.93548011779785, reconstruct loss = 0.07014573365449905, cluster loss = 0.03407495096325874, calm loss = 2.114060878753662, pilot loss = 28.2330322265625, max interval = -81.43408966064453, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "444, total loss = -25.05967140197754, reconstruct loss = 0.06559103727340698, cluster loss = 0.03450772911310196, calm loss = 2.122765302658081, pilot loss = 28.352375030517578, max interval = -81.78884887695312, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.5967741935483871\n",
      "445, total loss = -25.18227195739746, reconstruct loss = 0.06616583466529846, cluster loss = 0.03117479756474495, calm loss = 2.1361215114593506, pilot loss = 28.499258041381836, max interval = -82.18927764892578, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "446, total loss = -25.301475524902344, reconstruct loss = 0.06978940218687057, cluster loss = 0.03260233998298645, calm loss = 2.1507277488708496, pilot loss = 28.64786148071289, max interval = -82.60025024414062, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.5967741935483871\n",
      "447, total loss = -25.429290771484375, reconstruct loss = 0.06807103008031845, cluster loss = 0.03281862661242485, calm loss = 2.164889097213745, pilot loss = 28.789047241210938, max interval = -83.00293731689453, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "448, total loss = -25.548419952392578, reconstruct loss = 0.07228794693946838, cluster loss = 0.035260144621133804, calm loss = 2.17913556098938, pilot loss = 28.913681030273438, max interval = -83.38134765625, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "449, total loss = -25.686298370361328, reconstruct loss = 0.06648397445678711, cluster loss = 0.03290124610066414, calm loss = 2.1923420429229736, pilot loss = 29.035629272460938, max interval = -83.76004791259766, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "450, total loss = -25.81212615966797, reconstruct loss = 0.0727204978466034, cluster loss = 0.031711019575595856, calm loss = 2.2032113075256348, pilot loss = 29.153539657592773, max interval = -84.13130187988281, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "451, total loss = -25.944766998291016, reconstruct loss = 0.06922423839569092, cluster loss = 0.032640594989061356, calm loss = 2.214153528213501, pilot loss = 29.26540184020996, max interval = -84.49288177490234, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "452, total loss = -26.074378967285156, reconstruct loss = 0.06995686888694763, cluster loss = 0.03186346963047981, calm loss = 2.2235641479492188, pilot loss = 29.373769760131836, max interval = -84.84654998779297, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.5967741935483871\n",
      "453, total loss = -26.205284118652344, reconstruct loss = 0.07181712239980698, cluster loss = 0.031100288033485413, calm loss = 2.2294936180114746, pilot loss = 29.47674560546875, max interval = -85.19103240966797, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "454, total loss = -26.34342384338379, reconstruct loss = 0.06689172238111496, cluster loss = 0.031725794076919556, calm loss = 2.232231378555298, pilot loss = 29.570178985595703, max interval = -85.51994323730469, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "455, total loss = -26.475950241088867, reconstruct loss = 0.06827661395072937, cluster loss = 0.03267354145646095, calm loss = 2.2338738441467285, pilot loss = 29.66022300720215, max interval = -85.84390258789062, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "456, total loss = -26.604598999023438, reconstruct loss = 0.07145164906978607, cluster loss = 0.03340216726064682, calm loss = 2.237602710723877, pilot loss = 29.756134033203125, max interval = -86.17593383789062, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "457, total loss = -26.74149513244629, reconstruct loss = 0.06802382320165634, cluster loss = 0.032500945031642914, calm loss = 2.242457866668701, pilot loss = 29.857370376586914, max interval = -86.51720428466797, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "458, total loss = -26.86555290222168, reconstruct loss = 0.07416088134050369, cluster loss = 0.03519809991121292, calm loss = 2.2492213249206543, pilot loss = 29.9643497467041, max interval = -86.86986541748047, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "459, total loss = -26.993228912353516, reconstruct loss = 0.07213008403778076, cluster loss = 0.03246501088142395, calm loss = 2.2577271461486816, pilot loss = 30.07875633239746, max interval = -87.22137451171875, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "460, total loss = -27.109521865844727, reconstruct loss = 0.076814666390419, cluster loss = 0.03187995404005051, calm loss = 2.2662253379821777, pilot loss = 30.188884735107422, max interval = -87.56316375732422, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "461, total loss = -27.229999542236328, reconstruct loss = 0.0777011513710022, cluster loss = 0.034925900399684906, calm loss = 2.270967483520508, pilot loss = 30.278371810913086, max interval = -87.8758316040039, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "462, total loss = -27.361934661865234, reconstruct loss = 0.06928262114524841, cluster loss = 0.03443700075149536, calm loss = 2.2750253677368164, pilot loss = 30.361059188842773, max interval = -88.17584228515625, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "463, total loss = -27.481159210205078, reconstruct loss = 0.07501103729009628, cluster loss = 0.03283114358782768, calm loss = 2.2844038009643555, pilot loss = 30.46915626525879, max interval = -88.52020263671875, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "464, total loss = -27.6082706451416, reconstruct loss = 0.07238663733005524, cluster loss = 0.03221975266933441, calm loss = 2.2969069480895996, pilot loss = 30.596118927001953, max interval = -88.89673614501953, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "465, total loss = -27.733009338378906, reconstruct loss = 0.07006846368312836, cluster loss = 0.03363875299692154, calm loss = 2.3111507892608643, pilot loss = 30.72849464416504, max interval = -89.28343963623047, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "466, total loss = -27.861154556274414, reconstruct loss = 0.06756048649549484, cluster loss = 0.03379525616765022, calm loss = 2.3217005729675293, pilot loss = 30.860332489013672, max interval = -89.66688537597656, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "467, total loss = -27.984355926513672, reconstruct loss = 0.07210026681423187, cluster loss = 0.031743571162223816, calm loss = 2.3333311080932617, pilot loss = 30.999765396118164, max interval = -90.06256866455078, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "468, total loss = -28.112674713134766, reconstruct loss = 0.06892069429159164, cluster loss = 0.03225887566804886, calm loss = 2.3467776775360107, pilot loss = 31.150787353515625, max interval = -90.47735595703125, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.5967741935483871\n",
      "469, total loss = -28.23260498046875, reconstruct loss = 0.07285300642251968, cluster loss = 0.03210536018013954, calm loss = 2.3641517162323, pilot loss = 31.309280395507812, max interval = -90.90564727783203, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "470, total loss = -28.360843658447266, reconstruct loss = 0.06965360045433044, cluster loss = 0.03315964341163635, calm loss = 2.377708911895752, pilot loss = 31.449859619140625, max interval = -91.30630493164062, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.5967741935483871\n",
      "471, total loss = -28.48540496826172, reconstruct loss = 0.07419919222593307, cluster loss = 0.03097398765385151, calm loss = 2.388793468475342, pilot loss = 31.56911849975586, max interval = -91.67414855957031, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.5967741935483871\n",
      "472, total loss = -28.614858627319336, reconstruct loss = 0.06825943291187286, cluster loss = 0.03289823979139328, calm loss = 2.398369073867798, pilot loss = 31.689599990844727, max interval = -92.03948211669922, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.5967741935483871\n",
      "473, total loss = -28.736204147338867, reconstruct loss = 0.07092003524303436, cluster loss = 0.034271638840436935, calm loss = 2.406369686126709, pilot loss = 31.814029693603516, max interval = -92.40811157226562, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "474, total loss = -28.865921020507812, reconstruct loss = 0.07186879962682724, cluster loss = 0.031008029356598854, calm loss = 2.413231372833252, pilot loss = 31.93890380859375, max interval = -92.77864074707031, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "475, total loss = -28.991649627685547, reconstruct loss = 0.07114008814096451, cluster loss = 0.03333699330687523, calm loss = 2.4208245277404785, pilot loss = 32.0653076171875, max interval = -93.15229797363281, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.5967741935483871\n",
      "476, total loss = -29.115453720092773, reconstruct loss = 0.07706260681152344, cluster loss = 0.03131870925426483, calm loss = 2.4251773357391357, pilot loss = 32.188899993896484, max interval = -93.51785278320312, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.5967741935483871\n",
      "477, total loss = -29.252178192138672, reconstruct loss = 0.07039390504360199, cluster loss = 0.030060317367315292, calm loss = 2.4292240142822266, pilot loss = 32.31829833984375, max interval = -93.89281463623047, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "478, total loss = -29.37563133239746, reconstruct loss = 0.0724971666932106, cluster loss = 0.03295135498046875, calm loss = 2.4347400665283203, pilot loss = 32.45343780517578, max interval = -94.27758026123047, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "479, total loss = -29.501853942871094, reconstruct loss = 0.07312971353530884, cluster loss = 0.0326237827539444, calm loss = 2.441974401473999, pilot loss = 32.598060607910156, max interval = -94.67561340332031, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.5967741935483871\n",
      "480, total loss = -29.63580322265625, reconstruct loss = 0.06706016510725021, cluster loss = 0.033603958785533905, calm loss = 2.448038101196289, pilot loss = 32.73513412475586, max interval = -95.06451416015625, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "481, total loss = -29.76329803466797, reconstruct loss = 0.06991566717624664, cluster loss = 0.03236977756023407, calm loss = 2.4540858268737793, pilot loss = 32.86835479736328, max interval = -95.4482650756836, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.5967741935483871\n",
      "482, total loss = -29.89666748046875, reconstruct loss = 0.06761854887008667, cluster loss = 0.030427373945713043, calm loss = 2.4588284492492676, pilot loss = 32.991458892822266, max interval = -95.81570434570312, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "483, total loss = -30.017820358276367, reconstruct loss = 0.07410439103841782, cluster loss = 0.03368372470140457, calm loss = 2.4594719409942627, pilot loss = 33.08808898925781, max interval = -96.14199829101562, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "484, total loss = -30.15129852294922, reconstruct loss = 0.07054431736469269, cluster loss = 0.03383273258805275, calm loss = 2.461888074874878, pilot loss = 33.19061279296875, max interval = -96.47806549072266, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "485, total loss = -30.282686233520508, reconstruct loss = 0.06879812479019165, cluster loss = 0.034700483083724976, calm loss = 2.4655306339263916, pilot loss = 33.30305862426758, max interval = -96.83069610595703, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "486, total loss = -30.416776657104492, reconstruct loss = 0.06848524510860443, cluster loss = 0.0324263721704483, calm loss = 2.4722824096679688, pilot loss = 33.429603576660156, max interval = -97.20932006835938, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "487, total loss = -30.54690933227539, reconstruct loss = 0.06958198547363281, cluster loss = 0.031620968133211136, calm loss = 2.481644868850708, pilot loss = 33.57118225097656, max interval = -97.61161804199219, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "488, total loss = -30.6773738861084, reconstruct loss = 0.07073385268449783, cluster loss = 0.030391890555620193, calm loss = 2.4854917526245117, pilot loss = 33.70420455932617, max interval = -97.99376678466797, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "489, total loss = -30.80155372619629, reconstruct loss = 0.07296320050954819, cluster loss = 0.030952122062444687, calm loss = 2.4893851280212402, pilot loss = 33.838356018066406, max interval = -98.37269592285156, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "490, total loss = -30.937397003173828, reconstruct loss = 0.0669686421751976, cluster loss = 0.031450893729925156, calm loss = 2.492723226547241, pilot loss = 33.97279357910156, max interval = -98.75607299804688, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "491, total loss = -31.064300537109375, reconstruct loss = 0.0706271305680275, cluster loss = 0.03189989551901817, calm loss = 2.495421886444092, pilot loss = 34.10474395751953, max interval = -99.13594055175781, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "492, total loss = -31.19932746887207, reconstruct loss = 0.06867355108261108, cluster loss = 0.03261876851320267, calm loss = 2.4981582164764404, pilot loss = 34.24525833129883, max interval = -99.53205871582031, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "493, total loss = -31.329587936401367, reconstruct loss = 0.07095863670110703, cluster loss = 0.033857304602861404, calm loss = 2.5044312477111816, pilot loss = 34.3928337097168, max interval = -99.94331359863281, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "494, total loss = -31.463380813598633, reconstruct loss = 0.06928834319114685, cluster loss = 0.033756423741579056, calm loss = 2.51334547996521, pilot loss = 34.545555114746094, max interval = -100.36316680908203, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "495, total loss = -31.596446990966797, reconstruct loss = 0.07189151644706726, cluster loss = 0.03135860711336136, calm loss = 2.5218868255615234, pilot loss = 34.6971549987793, max interval = -100.78268432617188, \n",
      "Train ACC: 0.8, PTA: 0.134765625, Test ACC: 0.5967741935483871\n",
      "496, total loss = -31.730131149291992, reconstruct loss = 0.071006640791893, cluster loss = 0.032023120671510696, calm loss = 2.5279088020324707, pilot loss = 34.83586120605469, max interval = -101.18045806884766, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "497, total loss = -31.864036560058594, reconstruct loss = 0.07010645419359207, cluster loss = 0.0320182740688324, calm loss = 2.5329384803771973, pilot loss = 34.966819763183594, max interval = -101.56507873535156, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.5967741935483871\n",
      "498, total loss = -31.998037338256836, reconstruct loss = 0.06755990535020828, cluster loss = 0.03458966314792633, calm loss = 2.5371251106262207, pilot loss = 35.07939147949219, max interval = -101.9236831665039, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "499, total loss = -32.12822341918945, reconstruct loss = 0.07104379683732986, cluster loss = 0.0337066650390625, calm loss = 2.5442943572998047, pilot loss = 35.20283889770508, max interval = -102.30033111572266, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "500, total loss = -32.263145446777344, reconstruct loss = 0.07401999831199646, cluster loss = 0.031414225697517395, calm loss = 2.5544731616973877, pilot loss = 35.340110778808594, max interval = -102.70504760742188, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.5967741935483871\n",
      "501, total loss = -32.409332275390625, reconstruct loss = 0.06343274563550949, cluster loss = 0.03219643980264664, calm loss = 2.5682294368743896, pilot loss = 35.49782180786133, max interval = -103.14518737792969, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "502, total loss = -32.531410217285156, reconstruct loss = 0.07566655427217484, cluster loss = 0.0338393859565258, calm loss = 2.583595037460327, pilot loss = 35.66061019897461, max interval = -103.59426879882812, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "503, total loss = -32.6722412109375, reconstruct loss = 0.07229291647672653, cluster loss = 0.033180851489305496, calm loss = 2.598057985305786, pilot loss = 35.821781158447266, max interval = -104.04093933105469, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "504, total loss = -32.80765151977539, reconstruct loss = 0.07309427857398987, cluster loss = 0.03476870059967041, calm loss = 2.6104817390441895, pilot loss = 35.9791374206543, max interval = -104.48070526123047, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "505, total loss = -32.950111389160156, reconstruct loss = 0.07109208405017853, cluster loss = 0.03195521980524063, calm loss = 2.623181104660034, pilot loss = 36.125144958496094, max interval = -104.90440368652344, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "506, total loss = -33.087158203125, reconstruct loss = 0.0699646845459938, cluster loss = 0.03418143838644028, calm loss = 2.633296251296997, pilot loss = 36.26804733276367, max interval = -105.32070922851562, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "507, total loss = -33.22224426269531, reconstruct loss = 0.07618161290884018, cluster loss = 0.031831465661525726, calm loss = 2.6399893760681152, pilot loss = 36.405052185058594, max interval = -105.72484588623047, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "508, total loss = -33.369163513183594, reconstruct loss = 0.06787902116775513, cluster loss = 0.03180597350001335, calm loss = 2.6463160514831543, pilot loss = 36.54204559326172, max interval = -106.12793731689453, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "509, total loss = -33.50305938720703, reconstruct loss = 0.07363243401050568, cluster loss = 0.03232806921005249, calm loss = 2.6512932777404785, pilot loss = 36.67744064331055, max interval = -106.5290756225586, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "510, total loss = -33.643314361572266, reconstruct loss = 0.07083159685134888, cluster loss = 0.030446114018559456, calm loss = 2.6579713821411133, pilot loss = 36.807838439941406, max interval = -106.9189224243164, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "511, total loss = -33.78160858154297, reconstruct loss = 0.07209683954715729, cluster loss = 0.03356647491455078, calm loss = 2.661324977874756, pilot loss = 36.93285369873047, max interval = -107.30650329589844, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "512, total loss = -33.92724609375, reconstruct loss = 0.06597646325826645, cluster loss = 0.03218735381960869, calm loss = 2.672074794769287, pilot loss = 37.08428192138672, max interval = -107.73587799072266, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "513, total loss = -34.0640983581543, reconstruct loss = 0.06965672224760056, cluster loss = 0.03097393922507763, calm loss = 2.6844258308410645, pilot loss = 37.229942321777344, max interval = -108.16100311279297, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "514, total loss = -34.20438766479492, reconstruct loss = 0.07017695903778076, cluster loss = 0.030087724328041077, calm loss = 2.6987388134002686, pilot loss = 37.385135650634766, max interval = -108.60340118408203, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "515, total loss = -34.34296417236328, reconstruct loss = 0.07094595581293106, cluster loss = 0.03102988749742508, calm loss = 2.7101731300354004, pilot loss = 37.532928466796875, max interval = -109.0316390991211, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.5967741935483871\n",
      "516, total loss = -34.48558807373047, reconstruct loss = 0.06827408820390701, cluster loss = 0.03106205351650715, calm loss = 2.724956512451172, pilot loss = 37.680076599121094, max interval = -109.46330261230469, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "517, total loss = -34.62181091308594, reconstruct loss = 0.06844338029623032, cluster loss = 0.03659623861312866, calm loss = 2.7440593242645264, pilot loss = 37.84349822998047, max interval = -109.92717742919922, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "518, total loss = -34.76533126831055, reconstruct loss = 0.07033119350671768, cluster loss = 0.031665682792663574, calm loss = 2.763744831085205, pilot loss = 38.006187438964844, max interval = -110.38874816894531, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "519, total loss = -34.90852737426758, reconstruct loss = 0.0733037143945694, cluster loss = 0.027853580191731453, calm loss = 2.7823455333709717, pilot loss = 38.17501449584961, max interval = -110.86023712158203, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "520, total loss = -35.05167007446289, reconstruct loss = 0.06822378933429718, cluster loss = 0.03051699697971344, calm loss = 2.801952362060547, pilot loss = 38.348876953125, max interval = -111.33802032470703, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "521, total loss = -35.19880294799805, reconstruct loss = 0.06603998690843582, cluster loss = 0.028922636061906815, calm loss = 2.815418243408203, pilot loss = 38.4900016784668, max interval = -111.76402282714844, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.5967741935483871\n",
      "522, total loss = -35.33045196533203, reconstruct loss = 0.0729617103934288, cluster loss = 0.032032907009124756, calm loss = 2.8274025917053223, pilot loss = 38.63565444946289, max interval = -112.1919937133789, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "523, total loss = -35.48075485229492, reconstruct loss = 0.06616640836000443, cluster loss = 0.03228483349084854, calm loss = 2.837448835372925, pilot loss = 38.78294372558594, max interval = -112.62248229980469, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.5967741935483871\n",
      "524, total loss = -35.619083404541016, reconstruct loss = 0.07281162589788437, cluster loss = 0.030597934499382973, calm loss = 2.845663547515869, pilot loss = 38.92086410522461, max interval = -113.03631591796875, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "525, total loss = -35.76422882080078, reconstruct loss = 0.06791401654481888, cluster loss = 0.03252255544066429, calm loss = 2.8564324378967285, pilot loss = 39.06668472290039, max interval = -113.46348571777344, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "526, total loss = -35.914730072021484, reconstruct loss = 0.06548528373241425, cluster loss = 0.031216297298669815, calm loss = 2.8647170066833496, pilot loss = 39.20051193237305, max interval = -113.87653350830078, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.5967741935483871\n",
      "527, total loss = -36.05691146850586, reconstruct loss = 0.06914688646793365, cluster loss = 0.028680138289928436, calm loss = 2.8725597858428955, pilot loss = 39.31812286376953, max interval = -114.26084899902344, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "528, total loss = -36.19940948486328, reconstruct loss = 0.06867386400699615, cluster loss = 0.03151161968708038, calm loss = 2.8878817558288574, pilot loss = 39.470157623291016, max interval = -114.70722961425781, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "529, total loss = -36.34413146972656, reconstruct loss = 0.06732021272182465, cluster loss = 0.034897059202194214, calm loss = 2.90474534034729, pilot loss = 39.633872985839844, max interval = -115.17523193359375, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "530, total loss = -36.489837646484375, reconstruct loss = 0.0692892000079155, cluster loss = 0.03110138140618801, calm loss = 2.9261586666107178, pilot loss = 39.807044982910156, max interval = -115.65911865234375, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "531, total loss = -36.627925872802734, reconstruct loss = 0.0743565484881401, cluster loss = 0.03333304449915886, calm loss = 2.9477272033691406, pilot loss = 39.98773193359375, max interval = -116.15611267089844, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "532, total loss = -36.778221130371094, reconstruct loss = 0.06913357973098755, cluster loss = 0.0326843336224556, calm loss = 2.9671249389648438, pilot loss = 40.16709518432617, max interval = -116.6467514038086, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "533, total loss = -36.92860412597656, reconstruct loss = 0.07069553434848785, cluster loss = 0.031299687922000885, calm loss = 2.9767258167266846, pilot loss = 40.31209182739258, max interval = -117.08306884765625, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "534, total loss = -37.07868576049805, reconstruct loss = 0.06896709650754929, cluster loss = 0.030537456274032593, calm loss = 2.980140447616577, pilot loss = 40.42580032348633, max interval = -117.46160125732422, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "535, total loss = -37.22051239013672, reconstruct loss = 0.0718424916267395, cluster loss = 0.03368544578552246, calm loss = 2.9832284450531006, pilot loss = 40.545555114746094, max interval = -117.84867858886719, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "536, total loss = -37.36906051635742, reconstruct loss = 0.0725349560379982, cluster loss = 0.03227374702692032, calm loss = 2.98796010017395, pilot loss = 40.677223205566406, max interval = -118.25508880615234, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "537, total loss = -37.51821517944336, reconstruct loss = 0.07351693511009216, cluster loss = 0.03106708824634552, calm loss = 2.998059034347534, pilot loss = 40.83170700073242, max interval = -118.70333862304688, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "538, total loss = -37.67885971069336, reconstruct loss = 0.06457408517599106, cluster loss = 0.031685493886470795, calm loss = 3.0110878944396973, pilot loss = 41.003684997558594, max interval = -119.18561553955078, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.5967741935483871\n",
      "539, total loss = -37.82110595703125, reconstruct loss = 0.07001596689224243, cluster loss = 0.03140570968389511, calm loss = 3.026700019836426, pilot loss = 41.172889709472656, max interval = -119.66060638427734, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "540, total loss = -37.97407531738281, reconstruct loss = 0.06669255346059799, cluster loss = 0.03168501704931259, calm loss = 3.0398993492126465, pilot loss = 41.32765197753906, max interval = -120.11510467529297, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "541, total loss = -38.120399475097656, reconstruct loss = 0.0718352422118187, cluster loss = 0.03205319866538048, calm loss = 3.048246383666992, pilot loss = 41.459720611572266, max interval = -120.53298950195312, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.5967741935483871\n",
      "542, total loss = -38.27053451538086, reconstruct loss = 0.07260149717330933, cluster loss = 0.031114663928747177, calm loss = 3.063429832458496, pilot loss = 41.61363983154297, max interval = -120.98918151855469, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "543, total loss = -38.423492431640625, reconstruct loss = 0.06805837899446487, cluster loss = 0.031730156391859055, calm loss = 3.0815834999084473, pilot loss = 41.78697967529297, max interval = -121.47602844238281, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.5967741935483871\n",
      "544, total loss = -38.57868194580078, reconstruct loss = 0.0663864016532898, cluster loss = 0.03149455040693283, calm loss = 3.094425678253174, pilot loss = 41.950965881347656, max interval = -121.94799041748047, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "545, total loss = -38.72393035888672, reconstruct loss = 0.07412229478359222, cluster loss = 0.031009916216135025, calm loss = 3.106837749481201, pilot loss = 42.10641098022461, max interval = -122.4060287475586, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "546, total loss = -38.87337875366211, reconstruct loss = 0.07096701860427856, cluster loss = 0.03220003843307495, calm loss = 3.124176263809204, pilot loss = 42.272987365722656, max interval = -122.87983703613281, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "547, total loss = -39.02855682373047, reconstruct loss = 0.07096720486879349, cluster loss = 0.0319291390478611, calm loss = 3.139923334121704, pilot loss = 42.43006134033203, max interval = -123.34839630126953, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "548, total loss = -39.19215393066406, reconstruct loss = 0.0684649869799614, cluster loss = 0.03077741339802742, calm loss = 3.1468002796173096, pilot loss = 42.5703010559082, max interval = -123.78744506835938, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "549, total loss = -39.328285217285156, reconstruct loss = 0.07936912775039673, cluster loss = 0.03154416009783745, calm loss = 3.1606242656707764, pilot loss = 42.71923065185547, max interval = -124.23148345947266, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.5967741935483871\n",
      "550, total loss = -39.49502944946289, reconstruct loss = 0.0679774284362793, cluster loss = 0.031204763799905777, calm loss = 3.170170545578003, pilot loss = 42.8662223815918, max interval = -124.67694091796875, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "551, total loss = -39.6512336730957, reconstruct loss = 0.0704614520072937, cluster loss = 0.03300680220127106, calm loss = 3.178968906402588, pilot loss = 43.02128601074219, max interval = -125.14070129394531, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.5967741935483871\n",
      "552, total loss = -39.81945037841797, reconstruct loss = 0.06299413740634918, cluster loss = 0.0326712466776371, calm loss = 3.1884472370147705, pilot loss = 43.18764877319336, max interval = -125.62145233154297, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "553, total loss = -39.97190856933594, reconstruct loss = 0.06797564029693604, cluster loss = 0.0315571166574955, calm loss = 3.2080161571502686, pilot loss = 43.3736572265625, max interval = -126.13885498046875, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "554, total loss = -40.13232421875, reconstruct loss = 0.065484419465065, cluster loss = 0.032277945429086685, calm loss = 3.224815845489502, pilot loss = 43.545570373535156, max interval = -126.63546752929688, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "555, total loss = -40.293357849121094, reconstruct loss = 0.0648667961359024, cluster loss = 0.02903595194220543, calm loss = 3.243549346923828, pilot loss = 43.723880767822266, max interval = -127.14188385009766, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.5967741935483871\n",
      "556, total loss = -40.44661331176758, reconstruct loss = 0.06859221309423447, cluster loss = 0.0313129685819149, calm loss = 3.2587203979492188, pilot loss = 43.89165496826172, max interval = -127.63114929199219, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "557, total loss = -40.60068893432617, reconstruct loss = 0.06975531578063965, cluster loss = 0.03303663432598114, calm loss = 3.2679989337921143, pilot loss = 44.030006408691406, max interval = -128.06666564941406, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "558, total loss = -40.756072998046875, reconstruct loss = 0.07240241020917892, cluster loss = 0.03291404992341995, calm loss = 3.28253436088562, pilot loss = 44.189414978027344, max interval = -128.5411376953125, \n",
      "Train ACC: 0.8, PTA: 0.1357421875, Test ACC: 0.5967741935483871\n",
      "559, total loss = -40.92195129394531, reconstruct loss = 0.06582961976528168, cluster loss = 0.03130524232983589, calm loss = 3.300835371017456, pilot loss = 44.36843490600586, max interval = -129.0487060546875, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.5967741935483871\n",
      "560, total loss = -41.0831184387207, reconstruct loss = 0.06621848046779633, cluster loss = 0.030700137838721275, calm loss = 3.31640887260437, pilot loss = 44.5513916015625, max interval = -129.56265258789062, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "561, total loss = -41.24458694458008, reconstruct loss = 0.06915628910064697, cluster loss = 0.029052145779132843, calm loss = 3.3294334411621094, pilot loss = 44.7332649230957, max interval = -130.07398986816406, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "562, total loss = -41.39622116088867, reconstruct loss = 0.07013960927724838, cluster loss = 0.034262098371982574, calm loss = 3.3475842475891113, pilot loss = 44.9285774230957, max interval = -130.60479736328125, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "563, total loss = -41.565547943115234, reconstruct loss = 0.06626342236995697, cluster loss = 0.030242856591939926, calm loss = 3.3570613861083984, pilot loss = 45.10072708129883, max interval = -131.0952911376953, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "564, total loss = -41.72693634033203, reconstruct loss = 0.06903289258480072, cluster loss = 0.030739620327949524, calm loss = 3.365086078643799, pilot loss = 45.25153350830078, max interval = -131.55780029296875, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "565, total loss = -41.900691986083984, reconstruct loss = 0.06332022696733475, cluster loss = 0.031826987862586975, calm loss = 3.3770294189453125, pilot loss = 45.42977523803711, max interval = -132.07151794433594, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "566, total loss = -42.072471618652344, reconstruct loss = 0.067250557243824, cluster loss = 0.03042244166135788, calm loss = 3.3950438499450684, pilot loss = 45.63866424560547, max interval = -132.6450653076172, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.5967741935483871\n",
      "567, total loss = -42.24566650390625, reconstruct loss = 0.06880924850702286, cluster loss = 0.0303499735891819, calm loss = 3.4162487983703613, pilot loss = 45.867130279541016, max interval = -133.25169372558594, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.5967741935483871\n",
      "568, total loss = -42.42609786987305, reconstruct loss = 0.0676584541797638, cluster loss = 0.031114613637328148, calm loss = 3.4278056621551514, pilot loss = 46.07731246948242, max interval = -133.82608032226562, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "569, total loss = -42.60341262817383, reconstruct loss = 0.067557193338871, cluster loss = 0.03341958299279213, calm loss = 3.432751178741455, pilot loss = 46.26165008544922, max interval = -134.35333251953125, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.5967741935483871\n",
      "570, total loss = -42.78257751464844, reconstruct loss = 0.06965818256139755, cluster loss = 0.03309918940067291, calm loss = 3.4371895790100098, pilot loss = 46.445106506347656, max interval = -134.8806610107422, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.5967741935483871\n",
      "571, total loss = -42.96628952026367, reconstruct loss = 0.06883370131254196, cluster loss = 0.03228704258799553, calm loss = 3.4418036937713623, pilot loss = 46.642494201660156, max interval = -135.42974853515625, \n",
      "Train ACC: 0.8, PTA: 0.091796875, Test ACC: 0.5967741935483871\n",
      "572, total loss = -43.15509033203125, reconstruct loss = 0.06750207394361496, cluster loss = 0.03220590949058533, calm loss = 3.443974256515503, pilot loss = 46.83032989501953, max interval = -135.96929931640625, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "573, total loss = -43.3396110534668, reconstruct loss = 0.06761245429515839, cluster loss = 0.031729958951473236, calm loss = 3.4536170959472656, pilot loss = 47.041969299316406, max interval = -136.5489044189453, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.5967741935483871\n",
      "574, total loss = -43.523468017578125, reconstruct loss = 0.06874235719442368, cluster loss = 0.030129902064800262, calm loss = 3.4602482318878174, pilot loss = 47.250755310058594, max interval = -137.11903381347656, \n",
      "Train ACC: 0.8, PTA: 0.12890625, Test ACC: 0.5967741935483871\n",
      "575, total loss = -43.70171356201172, reconstruct loss = 0.06712518632411957, cluster loss = 0.031525369733572006, calm loss = 3.4624714851379395, pilot loss = 47.43433380126953, max interval = -137.63919067382812, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "576, total loss = -43.87050247192383, reconstruct loss = 0.06846155226230621, cluster loss = 0.029850300401449203, calm loss = 3.4630424976348877, pilot loss = 47.58490753173828, max interval = -138.09617614746094, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "577, total loss = -44.04020690917969, reconstruct loss = 0.06831865012645721, cluster loss = 0.030019719153642654, calm loss = 3.466817855834961, pilot loss = 47.73908233642578, max interval = -138.564697265625, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "578, total loss = -44.21603775024414, reconstruct loss = 0.0675356388092041, cluster loss = 0.03219620883464813, calm loss = 3.4810805320739746, pilot loss = 47.93723678588867, max interval = -139.12173461914062, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "579, total loss = -44.3879280090332, reconstruct loss = 0.07202749699354172, cluster loss = 0.029626348987221718, calm loss = 3.5053863525390625, pilot loss = 48.16386795043945, max interval = -139.72894287109375, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "580, total loss = -44.548362731933594, reconstruct loss = 0.07246949523687363, cluster loss = 0.03097659721970558, calm loss = 3.5330650806427, pilot loss = 48.39118957519531, max interval = -140.3253936767578, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "581, total loss = -44.72286605834961, reconstruct loss = 0.06900183856487274, cluster loss = 0.028820930048823357, calm loss = 3.544618606567383, pilot loss = 48.55208206176758, max interval = -140.8134307861328, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "582, total loss = -44.890663146972656, reconstruct loss = 0.07040118426084518, cluster loss = 0.03058473952114582, calm loss = 3.5490944385528564, pilot loss = 48.7046012878418, max interval = -141.2823486328125, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "583, total loss = -45.07095718383789, reconstruct loss = 0.06587584316730499, cluster loss = 0.030541881918907166, calm loss = 3.552286148071289, pilot loss = 48.86494827270508, max interval = -141.76742553710938, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "584, total loss = -45.23393630981445, reconstruct loss = 0.06747212260961533, cluster loss = 0.0340837724506855, calm loss = 3.562950611114502, pilot loss = 49.03830337524414, max interval = -142.27090454101562, \n",
      "Train ACC: 0.8, PTA: 0.0927734375, Test ACC: 0.5967741935483871\n",
      "585, total loss = -45.408573150634766, reconstruct loss = 0.06707905977964401, cluster loss = 0.03144561126828194, calm loss = 3.5872485637664795, pilot loss = 49.252662658691406, max interval = -142.857421875, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.5967741935483871\n",
      "586, total loss = -45.58781814575195, reconstruct loss = 0.062440622597932816, cluster loss = 0.033668551594018936, calm loss = 3.6143569946289062, pilot loss = 49.44926834106445, max interval = -143.43003845214844, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.5967741935483871\n",
      "587, total loss = -45.75613784790039, reconstruct loss = 0.0700395330786705, cluster loss = 0.030333103612065315, calm loss = 3.649458408355713, pilot loss = 49.65373611450195, max interval = -144.01925659179688, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.5967741935483871\n",
      "588, total loss = -45.92982864379883, reconstruct loss = 0.06778985261917114, cluster loss = 0.03164461627602577, calm loss = 3.6748504638671875, pilot loss = 49.834922790527344, max interval = -144.5615692138672, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "589, total loss = -46.10343551635742, reconstruct loss = 0.07248863577842712, cluster loss = 0.031137827783823013, calm loss = 3.6891632080078125, pilot loss = 49.99978256225586, max interval = -145.07196044921875, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.5967741935483871\n",
      "590, total loss = -46.28826141357422, reconstruct loss = 0.06762037426233292, cluster loss = 0.030325956642627716, calm loss = 3.699904203414917, pilot loss = 50.170440673828125, max interval = -145.5874481201172, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "591, total loss = -46.46289825439453, reconstruct loss = 0.06352400779724121, cluster loss = 0.03166409209370613, calm loss = 3.716578960418701, pilot loss = 50.355770111083984, max interval = -146.1219940185547, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "592, total loss = -46.635650634765625, reconstruct loss = 0.06986969709396362, cluster loss = 0.02886071242392063, calm loss = 3.7440223693847656, pilot loss = 50.584632873535156, max interval = -146.74041748046875, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "593, total loss = -46.81783676147461, reconstruct loss = 0.06548610329627991, cluster loss = 0.029749613255262375, calm loss = 3.773508071899414, pilot loss = 50.82461166381836, max interval = -147.3810577392578, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "594, total loss = -46.992164611816406, reconstruct loss = 0.06856102496385574, cluster loss = 0.03146808594465256, calm loss = 3.799466609954834, pilot loss = 51.048274993896484, max interval = -147.99398803710938, \n",
      "Train ACC: 0.8, PTA: 0.1240234375, Test ACC: 0.5967741935483871\n",
      "595, total loss = -47.17633056640625, reconstruct loss = 0.06427314877510071, cluster loss = 0.03150606155395508, calm loss = 3.8134217262268066, pilot loss = 51.19786834716797, max interval = -148.48507690429688, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.5967741935483871\n",
      "596, total loss = -47.353267669677734, reconstruct loss = 0.06724359095096588, cluster loss = 0.03126426786184311, calm loss = 3.8236777782440186, pilot loss = 51.33256149291992, max interval = -148.94923400878906, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "597, total loss = -47.524017333984375, reconstruct loss = 0.07053714990615845, cluster loss = 0.031804271042346954, calm loss = 3.836369037628174, pilot loss = 51.48179244995117, max interval = -149.43038940429688, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.5967741935483871\n",
      "598, total loss = -47.707210540771484, reconstruct loss = 0.07066459953784943, cluster loss = 0.028773583471775055, calm loss = 3.8582777976989746, pilot loss = 51.66481399536133, max interval = -149.98114013671875, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "599, total loss = -47.89028549194336, reconstruct loss = 0.06609391421079636, cluster loss = 0.03244533762335777, calm loss = 3.8913235664367676, pilot loss = 51.8853874206543, max interval = -150.6041259765625, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.5967741935483871\n",
      "600, total loss = -48.07136917114258, reconstruct loss = 0.06794679164886475, cluster loss = 0.027478612959384918, calm loss = 3.916724443435669, pilot loss = 52.09980392456055, max interval = -151.20140075683594, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.5967741935483871\n",
      "601, total loss = -48.240684509277344, reconstruct loss = 0.07113426923751831, cluster loss = 0.03161392733454704, calm loss = 3.9502480030059814, pilot loss = 52.33936309814453, max interval = -151.84429931640625, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "602, total loss = -48.41928482055664, reconstruct loss = 0.06977064907550812, cluster loss = 0.03302193433046341, calm loss = 3.9652016162872314, pilot loss = 52.541358947753906, max interval = -152.4098663330078, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.5967741935483871\n",
      "603, total loss = -48.611148834228516, reconstruct loss = 0.06833919137716293, cluster loss = 0.03080548346042633, calm loss = 3.9645557403564453, pilot loss = 52.694908142089844, max interval = -152.89761352539062, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.5967741935483871\n",
      "604, total loss = -48.77555847167969, reconstruct loss = 0.06429730355739594, cluster loss = 0.03257333114743233, calm loss = 3.9578864574432373, pilot loss = 52.8372688293457, max interval = -153.32351684570312, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.5967741935483871\n",
      "605, total loss = -48.951290130615234, reconstruct loss = 0.06874853372573853, cluster loss = 0.035376038402318954, calm loss = 3.9725890159606934, pilot loss = 53.01253128051758, max interval = -153.85675048828125, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "606, total loss = -49.14840316772461, reconstruct loss = 0.07140509784221649, cluster loss = 0.0305815190076828, calm loss = 4.00800085067749, pilot loss = 53.214210510253906, max interval = -154.47442626953125, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.5967741935483871\n",
      "607, total loss = -49.3194580078125, reconstruct loss = 0.07382658123970032, cluster loss = 0.03428412601351738, calm loss = 4.03423547744751, pilot loss = 53.402557373046875, max interval = -155.03453063964844, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "608, total loss = -49.51068878173828, reconstruct loss = 0.06690390408039093, cluster loss = 0.033295974135398865, calm loss = 4.048086643218994, pilot loss = 53.55750274658203, max interval = -155.53799438476562, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.5967741935483871\n",
      "609, total loss = -49.683773040771484, reconstruct loss = 0.07566827535629272, cluster loss = 0.03004663996398449, calm loss = 4.0535688400268555, pilot loss = 53.7088737487793, max interval = -156.0176544189453, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "610, total loss = -49.8726692199707, reconstruct loss = 0.06895536929368973, cluster loss = 0.0334492102265358, calm loss = 4.075624465942383, pilot loss = 53.89423370361328, max interval = -156.57952880859375, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "611, total loss = -50.055843353271484, reconstruct loss = 0.06901124119758606, cluster loss = 0.02959827333688736, calm loss = 4.110114574432373, pilot loss = 54.1201171875, max interval = -157.20819091796875, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "612, total loss = -50.231937408447266, reconstruct loss = 0.07115212827920914, cluster loss = 0.031154360622167587, calm loss = 4.130993843078613, pilot loss = 54.316650390625, max interval = -157.77606201171875, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.5967741935483871\n",
      "613, total loss = -50.421329498291016, reconstruct loss = 0.07090803980827332, cluster loss = 0.031077099964022636, calm loss = 4.139119625091553, pilot loss = 54.485382080078125, max interval = -158.2992706298828, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.5967741935483871\n",
      "614, total loss = -50.60284423828125, reconstruct loss = 0.07129884511232376, cluster loss = 0.033204834908246994, calm loss = 4.139909744262695, pilot loss = 54.64630126953125, max interval = -158.79364013671875, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "615, total loss = -50.79122543334961, reconstruct loss = 0.07023769617080688, cluster loss = 0.02969723753631115, calm loss = 4.158836841583252, pilot loss = 54.85768508911133, max interval = -159.3856964111328, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.5967741935483871\n",
      "616, total loss = -50.972023010253906, reconstruct loss = 0.07281332463026047, cluster loss = 0.03437003493309021, calm loss = 4.191929340362549, pilot loss = 55.087562561035156, max interval = -160.03045654296875, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.5967741935483871\n",
      "617, total loss = -51.16368865966797, reconstruct loss = 0.07012835144996643, cluster loss = 0.03022591397166252, calm loss = 4.211063385009766, pilot loss = 55.27348709106445, max interval = -160.58790588378906, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.5967741935483871\n",
      "618, total loss = -51.35332489013672, reconstruct loss = 0.07117892056703568, cluster loss = 0.030258577316999435, calm loss = 4.216093063354492, pilot loss = 55.419830322265625, max interval = -161.07705688476562, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.5967741935483871\n",
      "619, total loss = -51.529598236083984, reconstruct loss = 0.06805209070444107, cluster loss = 0.02891707606613636, calm loss = 4.2174272537231445, pilot loss = 55.58220672607422, max interval = -161.55682373046875, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.5967741935483871\n",
      "620, total loss = -51.71443176269531, reconstruct loss = 0.07100851833820343, cluster loss = 0.03213224560022354, calm loss = 4.245777606964111, pilot loss = 55.789329528808594, max interval = -162.16653442382812, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.5967741935483871\n",
      "621, total loss = -51.91383743286133, reconstruct loss = 0.07128638029098511, cluster loss = 0.03099844977259636, calm loss = 4.290677070617676, pilot loss = 56.032745361328125, max interval = -162.8625030517578, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.5967741935483871\n",
      "622, total loss = -52.07764434814453, reconstruct loss = 0.07436976581811905, cluster loss = 0.03240293264389038, calm loss = 4.335999488830566, pilot loss = 56.288970947265625, max interval = -163.5341796875, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.5967741935483871\n",
      "623, total loss = -52.26258850097656, reconstruct loss = 0.07353635132312775, cluster loss = 0.031402040272951126, calm loss = 4.355100631713867, pilot loss = 56.474830627441406, max interval = -164.08901977539062, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.5967741935483871\n",
      "624, total loss = -52.46031951904297, reconstruct loss = 0.07104542851448059, cluster loss = 0.031371861696243286, calm loss = 4.354968070983887, pilot loss = 56.593955993652344, max interval = -164.53834533691406, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.5967741935483871\n",
      "625, total loss = -52.65648651123047, reconstruct loss = 0.07175540179014206, cluster loss = 0.031853239983320236, calm loss = 4.342677116394043, pilot loss = 56.68852615356445, max interval = -164.93829345703125, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6129032258064516\n",
      "626, total loss = -52.8372688293457, reconstruct loss = 0.07256952673196793, cluster loss = 0.029672250151634216, calm loss = 4.339500904083252, pilot loss = 56.84288787841797, max interval = -165.41104125976562, \n",
      "Train ACC: 0.8, PTA: 0.091796875, Test ACC: 0.6129032258064516\n",
      "627, total loss = -53.02743148803711, reconstruct loss = 0.07935681194067001, cluster loss = 0.0289361160248518, calm loss = 4.371821403503418, pilot loss = 57.08137130737305, max interval = -166.07867431640625, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "628, total loss = -53.234580993652344, reconstruct loss = 0.07523554563522339, cluster loss = 0.030740734189748764, calm loss = 4.424365520477295, pilot loss = 57.36838912963867, max interval = -166.8568572998047, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "629, total loss = -53.42212677001953, reconstruct loss = 0.07756049185991287, cluster loss = 0.028581418097019196, calm loss = 4.461023807525635, pilot loss = 57.622764587402344, max interval = -167.54124450683594, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "630, total loss = -53.60725021362305, reconstruct loss = 0.08226747810840607, cluster loss = 0.03331474959850311, calm loss = 4.47812557220459, pilot loss = 57.81573486328125, max interval = -168.11976623535156, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "631, total loss = -53.8139762878418, reconstruct loss = 0.07387469708919525, cluster loss = 0.03095041587948799, calm loss = 4.497342109680176, pilot loss = 57.99666213989258, max interval = -168.6861114501953, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "632, total loss = -53.99886703491211, reconstruct loss = 0.07645458728075027, cluster loss = 0.03033246099948883, calm loss = 4.519455909729004, pilot loss = 58.18408203125, max interval = -169.2528533935547, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "633, total loss = -54.19414138793945, reconstruct loss = 0.07467930763959885, cluster loss = 0.03269042819738388, calm loss = 4.519835472106934, pilot loss = 58.351776123046875, max interval = -169.7732391357422, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "634, total loss = -54.39015579223633, reconstruct loss = 0.07893916219472885, cluster loss = 0.03092595562338829, calm loss = 4.517932415008545, pilot loss = 58.518211364746094, max interval = -170.29234313964844, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "635, total loss = -54.57868957519531, reconstruct loss = 0.07630877196788788, cluster loss = 0.03215743601322174, calm loss = 4.519343852996826, pilot loss = 58.71497344970703, max interval = -170.84326171875, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.6129032258064516\n",
      "636, total loss = -54.76523971557617, reconstruct loss = 0.08483827859163284, cluster loss = 0.031686797738075256, calm loss = 4.549911975860596, pilot loss = 58.969207763671875, max interval = -171.5286102294922, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6129032258064516\n",
      "637, total loss = -54.96669006347656, reconstruct loss = 0.07769870012998581, cluster loss = 0.028864968568086624, calm loss = 4.590728759765625, pilot loss = 59.231285095214844, max interval = -172.2353515625, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "638, total loss = -55.16575241088867, reconstruct loss = 0.07627280801534653, cluster loss = 0.030126191675662994, calm loss = 4.6157755851745605, pilot loss = 59.440460205078125, max interval = -172.8545684814453, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.6129032258064516\n",
      "639, total loss = -55.379695892333984, reconstruct loss = 0.07389649748802185, cluster loss = 0.029705416411161423, calm loss = 4.629599571228027, pilot loss = 59.61394119262695, max interval = -173.4242706298828, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "640, total loss = -55.57253646850586, reconstruct loss = 0.08362741768360138, cluster loss = 0.03206971287727356, calm loss = 4.638527870178223, pilot loss = 59.77497482299805, max interval = -173.96031188964844, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.6129032258064516\n",
      "641, total loss = -55.787498474121094, reconstruct loss = 0.07859814167022705, cluster loss = 0.03319351002573967, calm loss = 4.673061847686768, pilot loss = 60.00836181640625, max interval = -174.6450653076172, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "642, total loss = -55.99314880371094, reconstruct loss = 0.08351282775402069, cluster loss = 0.03174004703760147, calm loss = 4.7270402908325195, pilot loss = 60.30278396606445, max interval = -175.44198608398438, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.6129032258064516\n",
      "643, total loss = -56.20078659057617, reconstruct loss = 0.08497171103954315, cluster loss = 0.031033078208565712, calm loss = 4.77000617980957, pilot loss = 60.57155227661133, max interval = -176.1855010986328, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "644, total loss = -56.42301940917969, reconstruct loss = 0.07730793207883835, cluster loss = 0.031263697892427444, calm loss = 4.798613548278809, pilot loss = 60.792091369628906, max interval = -176.8487548828125, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "645, total loss = -56.644737243652344, reconstruct loss = 0.08036316931247711, cluster loss = 0.03155652433633804, calm loss = 4.802203178405762, pilot loss = 60.97746658325195, max interval = -177.4407196044922, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "646, total loss = -56.86166763305664, reconstruct loss = 0.08337508141994476, cluster loss = 0.029149921610951424, calm loss = 4.812191009521484, pilot loss = 61.201011657714844, max interval = -178.08560180664062, \n",
      "Train ACC: 0.8, PTA: 0.12890625, Test ACC: 0.6129032258064516\n",
      "647, total loss = -57.08328628540039, reconstruct loss = 0.07787241786718369, cluster loss = 0.0333557054400444, calm loss = 4.828700065612793, pilot loss = 61.43217849731445, max interval = -178.75465393066406, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "648, total loss = -57.30258560180664, reconstruct loss = 0.08650456368923187, cluster loss = 0.029353149235248566, calm loss = 4.834980010986328, pilot loss = 61.62746047973633, max interval = -179.36297607421875, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "649, total loss = -57.5181770324707, reconstruct loss = 0.08554419875144958, cluster loss = 0.030864650383591652, calm loss = 4.83323335647583, pilot loss = 61.796844482421875, max interval = -179.9117431640625, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "650, total loss = -57.745323181152344, reconstruct loss = 0.08508199453353882, cluster loss = 0.028616202995181084, calm loss = 4.845010280609131, pilot loss = 62.00214767456055, max interval = -180.54296875, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "651, total loss = -57.97270202636719, reconstruct loss = 0.08150739222764969, cluster loss = 0.030170772224664688, calm loss = 4.8694658279418945, pilot loss = 62.23591995239258, max interval = -181.2342987060547, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "652, total loss = -58.18722915649414, reconstruct loss = 0.08962832391262054, cluster loss = 0.030543416738510132, calm loss = 4.876187324523926, pilot loss = 62.4381103515625, max interval = -181.85183715820312, \n",
      "Train ACC: 0.8, PTA: 0.1318359375, Test ACC: 0.6129032258064516\n",
      "653, total loss = -58.42416763305664, reconstruct loss = 0.0829615667462349, cluster loss = 0.030504759401082993, calm loss = 4.867087364196777, pilot loss = 62.606285095214844, max interval = -182.4084930419922, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "654, total loss = -58.65216064453125, reconstruct loss = 0.07958439737558365, cluster loss = 0.03081136755645275, calm loss = 4.869793891906738, pilot loss = 62.818397521972656, max interval = -183.03720092773438, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "655, total loss = -58.87222671508789, reconstruct loss = 0.08901333063840866, cluster loss = 0.02873888984322548, calm loss = 4.866819381713867, pilot loss = 63.013465881347656, max interval = -183.6370086669922, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "656, total loss = -59.09467315673828, reconstruct loss = 0.08495108783245087, cluster loss = 0.0326487198472023, calm loss = 4.881824493408203, pilot loss = 63.25068283081055, max interval = -184.3153839111328, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "657, total loss = -59.326194763183594, reconstruct loss = 0.07888095825910568, cluster loss = 0.03267499804496765, calm loss = 4.893185615539551, pilot loss = 63.47442626953125, max interval = -184.97386169433594, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "658, total loss = -59.54491424560547, reconstruct loss = 0.08159990608692169, cluster loss = 0.03285566717386246, calm loss = 4.899351596832275, pilot loss = 63.6747932434082, max interval = -185.5860137939453, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "659, total loss = -59.75678634643555, reconstruct loss = 0.09362535178661346, cluster loss = 0.030144203454256058, calm loss = 4.916807651519775, pilot loss = 63.89897537231445, max interval = -186.24769592285156, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.6129032258064516\n",
      "660, total loss = -59.969886779785156, reconstruct loss = 0.08837144076824188, cluster loss = 0.029409589245915413, calm loss = 4.944272994995117, pilot loss = 64.14586639404297, max interval = -186.93601989746094, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "661, total loss = -60.18089294433594, reconstruct loss = 0.09171230345964432, cluster loss = 0.03102714940905571, calm loss = 4.954375267028809, pilot loss = 64.35511016845703, max interval = -187.55841064453125, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "662, total loss = -60.40644073486328, reconstruct loss = 0.0871262326836586, cluster loss = 0.03075660578906536, calm loss = 4.950870990753174, pilot loss = 64.5186996459961, max interval = -188.10287475585938, \n",
      "Train ACC: 0.8, PTA: 0.083984375, Test ACC: 0.6129032258064516\n",
      "663, total loss = -60.59451675415039, reconstruct loss = 0.10054750740528107, cluster loss = 0.03070691041648388, calm loss = 4.948997497558594, pilot loss = 64.71302795410156, max interval = -188.66610717773438, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "664, total loss = -60.81766128540039, reconstruct loss = 0.09868736565113068, cluster loss = 0.029164552688598633, calm loss = 4.976975440979004, pilot loss = 64.9766845703125, max interval = -189.39715576171875, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "665, total loss = -61.03608322143555, reconstruct loss = 0.09559624642133713, cluster loss = 0.0319468155503273, calm loss = 5.023571491241455, pilot loss = 65.27388763427734, max interval = -190.2003936767578, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.6129032258064516\n",
      "666, total loss = -61.2536506652832, reconstruct loss = 0.09346382319927216, cluster loss = 0.02947920747101307, calm loss = 5.052555084228516, pilot loss = 65.5163345336914, max interval = -190.89291381835938, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "667, total loss = -61.474205017089844, reconstruct loss = 0.10024534165859222, cluster loss = 0.026971351355314255, calm loss = 5.064602851867676, pilot loss = 65.68102264404297, max interval = -191.46710205078125, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "668, total loss = -61.681697845458984, reconstruct loss = 0.09547404944896698, cluster loss = 0.030394256114959717, calm loss = 5.06580924987793, pilot loss = 65.83854675292969, max interval = -191.98886108398438, \n",
      "Train ACC: 0.8, PTA: 0.091796875, Test ACC: 0.6129032258064516\n",
      "669, total loss = -61.90263366699219, reconstruct loss = 0.09268757700920105, cluster loss = 0.030067432671785355, calm loss = 5.093365669250488, pilot loss = 66.07049560546875, max interval = -192.6712646484375, \n",
      "Train ACC: 0.8, PTA: 0.12890625, Test ACC: 0.6129032258064516\n",
      "670, total loss = -62.1309700012207, reconstruct loss = 0.09135952591896057, cluster loss = 0.031531523913145065, calm loss = 5.1382598876953125, pilot loss = 66.34346008300781, max interval = -193.4522705078125, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "671, total loss = -62.34632110595703, reconstruct loss = 0.09533139318227768, cluster loss = 0.02971343696117401, calm loss = 5.166012763977051, pilot loss = 66.59693908691406, max interval = -194.16525268554688, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6129032258064516\n",
      "672, total loss = -62.561973571777344, reconstruct loss = 0.095363087952137, cluster loss = 0.03108835220336914, calm loss = 5.174353122711182, pilot loss = 66.81673431396484, max interval = -194.80177307128906, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.6129032258064516\n",
      "673, total loss = -62.78470993041992, reconstruct loss = 0.09256697446107864, cluster loss = 0.030969414860010147, calm loss = 5.187010288238525, pilot loss = 67.02925109863281, max interval = -195.43800354003906, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "674, total loss = -62.9964599609375, reconstruct loss = 0.09983395785093307, cluster loss = 0.02882743999361992, calm loss = 5.207854270935059, pilot loss = 67.25064086914062, max interval = -196.09437561035156, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "675, total loss = -63.232967376708984, reconstruct loss = 0.08828596025705338, cluster loss = 0.02781856060028076, calm loss = 5.221439838409424, pilot loss = 67.44822692871094, max interval = -196.7165069580078, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "676, total loss = -63.44249725341797, reconstruct loss = 0.10189791023731232, cluster loss = 0.028612112626433372, calm loss = 5.229145050048828, pilot loss = 67.6323471069336, max interval = -197.3109588623047, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "677, total loss = -63.66777420043945, reconstruct loss = 0.0948893204331398, cluster loss = 0.03263865038752556, calm loss = 5.249706745147705, pilot loss = 67.857177734375, max interval = -197.9796142578125, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "678, total loss = -63.88838577270508, reconstruct loss = 0.09608520567417145, cluster loss = 0.02912791818380356, calm loss = 5.264272212982178, pilot loss = 68.0904541015625, max interval = -198.6460418701172, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "679, total loss = -64.11144256591797, reconstruct loss = 0.09650514274835587, cluster loss = 0.0313679464161396, calm loss = 5.293687343597412, pilot loss = 68.34557342529297, max interval = -199.37550354003906, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "680, total loss = -64.33063507080078, reconstruct loss = 0.09266090393066406, cluster loss = 0.02956327795982361, calm loss = 5.328682899475098, pilot loss = 68.60881805419922, max interval = -200.10714721679688, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "681, total loss = -64.55647277832031, reconstruct loss = 0.091787189245224, cluster loss = 0.029693569988012314, calm loss = 5.344237804412842, pilot loss = 68.80686950683594, max interval = -200.73439025878906, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "682, total loss = -64.77725982666016, reconstruct loss = 0.10240431874990463, cluster loss = 0.027768898755311966, calm loss = 5.3483099937438965, pilot loss = 68.9748306274414, max interval = -201.3085174560547, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "683, total loss = -65.00310516357422, reconstruct loss = 0.09459918737411499, cluster loss = 0.031296826899051666, calm loss = 5.359017372131348, pilot loss = 69.19550323486328, max interval = -201.9561004638672, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "684, total loss = -65.24107360839844, reconstruct loss = 0.0900539755821228, cluster loss = 0.02962830290198326, calm loss = 5.400593280792236, pilot loss = 69.48721313476562, max interval = -202.76382446289062, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "685, total loss = -65.45848846435547, reconstruct loss = 0.09048499912023544, cluster loss = 0.03312325105071068, calm loss = 5.44973087310791, pilot loss = 69.80899047851562, max interval = -203.6104278564453, \n",
      "Train ACC: 0.8, PTA: 0.0888671875, Test ACC: 0.6129032258064516\n",
      "686, total loss = -65.6854476928711, reconstruct loss = 0.09309745579957962, cluster loss = 0.030098015442490578, calm loss = 5.472559928894043, pilot loss = 70.04537200927734, max interval = -204.3048858642578, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.6129032258064516\n",
      "687, total loss = -65.91395568847656, reconstruct loss = 0.09350503981113434, cluster loss = 0.029328709468245506, calm loss = 5.4702043533325195, pilot loss = 70.21104431152344, max interval = -204.86465454101562, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "688, total loss = -66.13752746582031, reconstruct loss = 0.09569863975048065, cluster loss = 0.030641719698905945, calm loss = 5.475940704345703, pilot loss = 70.39674377441406, max interval = -205.46307373046875, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "689, total loss = -66.3834457397461, reconstruct loss = 0.08723368495702744, cluster loss = 0.028172019869089127, calm loss = 5.500765800476074, pilot loss = 70.63463592529297, max interval = -206.17457580566406, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "690, total loss = -66.6081771850586, reconstruct loss = 0.09088682383298874, cluster loss = 0.02966628037393093, calm loss = 5.5209550857543945, pilot loss = 70.86158752441406, max interval = -206.85658264160156, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "691, total loss = -66.82719421386719, reconstruct loss = 0.09397421777248383, cluster loss = 0.031085271388292313, calm loss = 5.551645755767822, pilot loss = 71.12703704833984, max interval = -207.5994873046875, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "692, total loss = -67.0579605102539, reconstruct loss = 0.09580479562282562, cluster loss = 0.03103475458920002, calm loss = 5.566717147827148, pilot loss = 71.34529113769531, max interval = -208.2655487060547, \n",
      "Train ACC: 0.8, PTA: 0.1328125, Test ACC: 0.6129032258064516\n",
      "693, total loss = -67.2871322631836, reconstruct loss = 0.09600790590047836, cluster loss = 0.02923210896551609, calm loss = 5.5733747482299805, pilot loss = 71.54024505615234, max interval = -208.87921142578125, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "694, total loss = -67.52782440185547, reconstruct loss = 0.0874442607164383, cluster loss = 0.032044667750597, calm loss = 5.598689079284668, pilot loss = 71.78321838378906, max interval = -209.5986328125, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "695, total loss = -67.75619506835938, reconstruct loss = 0.09318144619464874, cluster loss = 0.03312617167830467, calm loss = 5.633096694946289, pilot loss = 72.06285858154297, max interval = -210.3837890625, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.6129032258064516\n",
      "696, total loss = -67.99673461914062, reconstruct loss = 0.08848666399717331, cluster loss = 0.03147843852639198, calm loss = 5.64786434173584, pilot loss = 72.28832244873047, max interval = -211.0620880126953, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "697, total loss = -68.22174835205078, reconstruct loss = 0.09478382766246796, cluster loss = 0.029078232124447823, calm loss = 5.649459362030029, pilot loss = 72.48197937011719, max interval = -211.6685791015625, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "698, total loss = -68.4570083618164, reconstruct loss = 0.09392769634723663, cluster loss = 0.028848109766840935, calm loss = 5.667773246765137, pilot loss = 72.70181274414062, max interval = -212.34384155273438, \n",
      "Train ACC: 0.8, PTA: 0.125, Test ACC: 0.6129032258064516\n",
      "699, total loss = -68.69607543945312, reconstruct loss = 0.0942017063498497, cluster loss = 0.03061508759856224, calm loss = 5.700020790100098, pilot loss = 72.96436309814453, max interval = -213.10995483398438, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "700, total loss = -68.93092346191406, reconstruct loss = 0.09413067251443863, cluster loss = 0.03171117976307869, calm loss = 5.719593048095703, pilot loss = 73.21640014648438, max interval = -213.83546447753906, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "701, total loss = -69.15885162353516, reconstruct loss = 0.10504835098981857, cluster loss = 0.030128763988614082, calm loss = 5.727854251861572, pilot loss = 73.43921661376953, max interval = -214.50506591796875, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "702, total loss = -69.40937042236328, reconstruct loss = 0.09431268274784088, cluster loss = 0.03154565393924713, calm loss = 5.752133846282959, pilot loss = 73.68840026855469, max interval = -215.24085998535156, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "703, total loss = -69.6446533203125, reconstruct loss = 0.09454033523797989, cluster loss = 0.031062519177794456, calm loss = 5.785219669342041, pilot loss = 73.95114135742188, max interval = -215.99974060058594, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "704, total loss = -69.88367462158203, reconstruct loss = 0.09571616351604462, cluster loss = 0.029786262661218643, calm loss = 5.802578449249268, pilot loss = 74.17283630371094, max interval = -216.68312072753906, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "705, total loss = -70.12698364257812, reconstruct loss = 0.0909184142947197, cluster loss = 0.03369468078017235, calm loss = 5.805783748626709, pilot loss = 74.37942504882812, max interval = -217.32968139648438, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "706, total loss = -70.36901092529297, reconstruct loss = 0.09001394361257553, cluster loss = 0.03159906715154648, calm loss = 5.828641891479492, pilot loss = 74.63299560546875, max interval = -218.06658935546875, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "707, total loss = -70.60310363769531, reconstruct loss = 0.0940287709236145, cluster loss = 0.0319054089486599, calm loss = 5.8563947677612305, pilot loss = 74.90936279296875, max interval = -218.8421630859375, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "708, total loss = -70.85151672363281, reconstruct loss = 0.0919049009680748, cluster loss = 0.02827008068561554, calm loss = 5.8647685050964355, pilot loss = 75.12983703613281, max interval = -219.51629638671875, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "709, total loss = -71.0916748046875, reconstruct loss = 0.09382231533527374, cluster loss = 0.027120262384414673, calm loss = 5.862354755401611, pilot loss = 75.32220458984375, max interval = -220.13238525390625, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "710, total loss = -71.3392105102539, reconstruct loss = 0.08910379558801651, cluster loss = 0.03121219016611576, calm loss = 5.877945899963379, pilot loss = 75.55259704589844, max interval = -220.83706665039062, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "711, total loss = -71.57759857177734, reconstruct loss = 0.09021976590156555, cluster loss = 0.030231956392526627, calm loss = 5.922184944152832, pilot loss = 75.83783721923828, max interval = -221.6490478515625, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "712, total loss = -71.81095886230469, reconstruct loss = 0.10338165611028671, cluster loss = 0.033187851309776306, calm loss = 5.94793701171875, pilot loss = 76.10270690917969, max interval = -222.42112731933594, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "713, total loss = -72.06204223632812, reconstruct loss = 0.09321555495262146, cluster loss = 0.029317187145352364, calm loss = 5.954049110412598, pilot loss = 76.35533142089844, max interval = -223.1299591064453, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "714, total loss = -72.28779602050781, reconstruct loss = 0.10048530250787735, cluster loss = 0.02988138608634472, calm loss = 5.972306251525879, pilot loss = 76.61121368408203, max interval = -223.85581970214844, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "715, total loss = -72.53794860839844, reconstruct loss = 0.09785415232181549, cluster loss = 0.030325084924697876, calm loss = 6.004464149475098, pilot loss = 76.87914276123047, max interval = -224.63931274414062, \n",
      "Train ACC: 0.8, PTA: 0.130859375, Test ACC: 0.6129032258064516\n",
      "716, total loss = -72.79984283447266, reconstruct loss = 0.08899769186973572, cluster loss = 0.030621305108070374, calm loss = 6.04632568359375, pilot loss = 77.1535415649414, max interval = -225.45355224609375, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "717, total loss = -73.03120422363281, reconstruct loss = 0.0925394743680954, cluster loss = 0.029482895508408546, calm loss = 6.0826735496521, pilot loss = 77.40408325195312, max interval = -226.19790649414062, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "718, total loss = -73.27584075927734, reconstruct loss = 0.09711272269487381, cluster loss = 0.02997242659330368, calm loss = 6.088679313659668, pilot loss = 77.60686492919922, max interval = -226.85342407226562, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "719, total loss = -73.51758575439453, reconstruct loss = 0.10113979876041412, cluster loss = 0.03063078038394451, calm loss = 6.076687812805176, pilot loss = 77.80859375, max interval = -227.47706604003906, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "720, total loss = -73.77142333984375, reconstruct loss = 0.09355408698320389, cluster loss = 0.030809614807367325, calm loss = 6.101384162902832, pilot loss = 78.09576416015625, max interval = -228.2751922607422, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "721, total loss = -74.0365219116211, reconstruct loss = 0.08451388031244278, cluster loss = 0.028967853635549545, calm loss = 6.152705669403076, pilot loss = 78.44356536865234, max interval = -229.20907592773438, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "722, total loss = -74.26431274414062, reconstruct loss = 0.0909646600484848, cluster loss = 0.029870009049773216, calm loss = 6.199827194213867, pilot loss = 78.77384185791016, max interval = -230.08468627929688, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.6129032258064516\n",
      "723, total loss = -74.51951599121094, reconstruct loss = 0.09319891780614853, cluster loss = 0.03072408214211464, calm loss = 6.2051920890808105, pilot loss = 78.98454284667969, max interval = -230.7628936767578, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "724, total loss = -74.76522064208984, reconstruct loss = 0.09342944622039795, cluster loss = 0.029929768294095993, calm loss = 6.19083309173584, pilot loss = 79.14226531982422, max interval = -231.31845092773438, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "725, total loss = -75.0195083618164, reconstruct loss = 0.0877552330493927, cluster loss = 0.02950248122215271, calm loss = 6.202477931976318, pilot loss = 79.35804748535156, max interval = -231.99844360351562, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "726, total loss = -75.281982421875, reconstruct loss = 0.08706027269363403, cluster loss = 0.0297695305198431, calm loss = 6.251513957977295, pilot loss = 79.64399719238281, max interval = -232.85189819335938, \n",
      "Train ACC: 0.8, PTA: 0.0947265625, Test ACC: 0.6129032258064516\n",
      "727, total loss = -75.5074462890625, reconstruct loss = 0.09380535781383514, cluster loss = 0.030453136190772057, calm loss = 6.317818641662598, pilot loss = 79.95858764648438, max interval = -233.7292938232422, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6129032258064516\n",
      "728, total loss = -75.76344299316406, reconstruct loss = 0.09210415929555893, cluster loss = 0.029150648042559624, calm loss = 6.351171493530273, pilot loss = 80.1977310180664, max interval = -234.4805450439453, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "729, total loss = -76.02328491210938, reconstruct loss = 0.09790810197591782, cluster loss = 0.030046328902244568, calm loss = 6.3521342277526855, pilot loss = 80.38328552246094, max interval = -235.12832641601562, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "730, total loss = -76.28439331054688, reconstruct loss = 0.08403809368610382, cluster loss = 0.02879326418042183, calm loss = 6.3689284324646, pilot loss = 80.62226104736328, max interval = -235.8456573486328, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "731, total loss = -76.53014373779297, reconstruct loss = 0.09810733050107956, cluster loss = 0.02784673497080803, calm loss = 6.406196594238281, pilot loss = 80.91522216796875, max interval = -236.68780517578125, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "732, total loss = -76.77806854248047, reconstruct loss = 0.09296553581953049, cluster loss = 0.031079046428203583, calm loss = 6.454658508300781, pilot loss = 81.25739288330078, max interval = -237.5978546142578, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "733, total loss = -77.03667449951172, reconstruct loss = 0.09595752507448196, cluster loss = 0.03093438409268856, calm loss = 6.471351623535156, pilot loss = 81.53489685058594, max interval = -238.39218139648438, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "734, total loss = -77.29087829589844, reconstruct loss = 0.09533146023750305, cluster loss = 0.031081492081284523, calm loss = 6.466620445251465, pilot loss = 81.75318145751953, max interval = -239.06027221679688, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "735, total loss = -77.54106140136719, reconstruct loss = 0.09269768744707108, cluster loss = 0.031246064230799675, calm loss = 6.476922035217285, pilot loss = 82.0062484741211, max interval = -239.79095458984375, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.6129032258064516\n",
      "736, total loss = -77.7980728149414, reconstruct loss = 0.09388099610805511, cluster loss = 0.03326599299907684, calm loss = 6.506746768951416, pilot loss = 82.28902435302734, max interval = -240.6098175048828, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "737, total loss = -78.07366943359375, reconstruct loss = 0.08807628601789474, cluster loss = 0.03183571621775627, calm loss = 6.559549808502197, pilot loss = 82.59198760986328, max interval = -241.5019989013672, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "738, total loss = -78.31625366210938, reconstruct loss = 0.09276487678289413, cluster loss = 0.03242207318544388, calm loss = 6.612523555755615, pilot loss = 82.89064025878906, max interval = -242.35897827148438, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "739, total loss = -78.5820541381836, reconstruct loss = 0.08950109034776688, cluster loss = 0.03001890890300274, calm loss = 6.63309383392334, pilot loss = 83.12210845947266, max interval = -243.0911865234375, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "740, total loss = -78.84895324707031, reconstruct loss = 0.09116260707378387, cluster loss = 0.03052201308310032, calm loss = 6.622806549072266, pilot loss = 83.298095703125, max interval = -243.7128448486328, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "741, total loss = -79.09547424316406, reconstruct loss = 0.097814179956913, cluster loss = 0.033220790326595306, calm loss = 6.630767822265625, pilot loss = 83.54689025878906, max interval = -244.44570922851562, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.6129032258064516\n",
      "742, total loss = -79.3680191040039, reconstruct loss = 0.09209873527288437, cluster loss = 0.03213934600353241, calm loss = 6.665165901184082, pilot loss = 83.87059020996094, max interval = -245.33749389648438, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "743, total loss = -79.62921142578125, reconstruct loss = 0.0919841080904007, cluster loss = 0.03012637048959732, calm loss = 6.706643581390381, pilot loss = 84.20149230957031, max interval = -246.24009704589844, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "744, total loss = -79.89183807373047, reconstruct loss = 0.08876154571771622, cluster loss = 0.032505761831998825, calm loss = 6.724346160888672, pilot loss = 84.46051025390625, max interval = -247.0099639892578, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "745, total loss = -80.16252136230469, reconstruct loss = 0.0884164497256279, cluster loss = 0.03040141612291336, calm loss = 6.718963623046875, pilot loss = 84.6534423828125, max interval = -247.66163635253906, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "746, total loss = -80.4258041381836, reconstruct loss = 0.09307239204645157, cluster loss = 0.028976410627365112, calm loss = 6.731940269470215, pilot loss = 84.8785171508789, max interval = -248.3830108642578, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.6129032258064516\n",
      "747, total loss = -80.68991088867188, reconstruct loss = 0.09235227853059769, cluster loss = 0.028903119266033173, calm loss = 6.771636009216309, pilot loss = 85.15994262695312, max interval = -249.21847534179688, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "748, total loss = -80.96985626220703, reconstruct loss = 0.08201703429222107, cluster loss = 0.031718019396066666, calm loss = 6.795395851135254, pilot loss = 85.41985321044922, max interval = -250.01345825195312, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "749, total loss = -81.23150634765625, reconstruct loss = 0.08686301857233047, cluster loss = 0.028971103951334953, calm loss = 6.8156328201293945, pilot loss = 85.68977355957031, max interval = -250.80532836914062, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "750, total loss = -81.49740600585938, reconstruct loss = 0.08756225556135178, cluster loss = 0.031720489263534546, calm loss = 6.850337028503418, pilot loss = 86.01498413085938, max interval = -251.70481872558594, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "751, total loss = -81.77124786376953, reconstruct loss = 0.08707369863986969, cluster loss = 0.030652562156319618, calm loss = 6.891694068908691, pilot loss = 86.34955596923828, max interval = -252.6313934326172, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "752, total loss = -82.0291519165039, reconstruct loss = 0.08662131428718567, cluster loss = 0.0319155715405941, calm loss = 6.933750152587891, pilot loss = 86.66923522949219, max interval = -253.51832580566406, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "753, total loss = -82.3065185546875, reconstruct loss = 0.09302417933940887, cluster loss = 0.03013465367257595, calm loss = 6.938652038574219, pilot loss = 86.90914154052734, max interval = -254.27146911621094, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.6129032258064516\n",
      "754, total loss = -82.57280731201172, reconstruct loss = 0.09470578283071518, cluster loss = 0.02976258099079132, calm loss = 6.927680969238281, pilot loss = 87.11742401123047, max interval = -254.93618774414062, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "755, total loss = -82.83790588378906, reconstruct loss = 0.09169909358024597, cluster loss = 0.03231564164161682, calm loss = 6.944489479064941, pilot loss = 87.3987045288086, max interval = -255.7406463623047, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "756, total loss = -83.12240600585938, reconstruct loss = 0.09170636534690857, cluster loss = 0.030503014102578163, calm loss = 6.98876953125, pilot loss = 87.72248840332031, max interval = -256.6708679199219, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "757, total loss = -83.41492462158203, reconstruct loss = 0.08766698092222214, cluster loss = 0.028977883979678154, calm loss = 7.038114070892334, pilot loss = 88.04214477539062, max interval = -257.6085205078125, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "758, total loss = -83.67963409423828, reconstruct loss = 0.08340899646282196, cluster loss = 0.03023672290146351, calm loss = 7.074606418609619, pilot loss = 88.33039855957031, max interval = -258.4468688964844, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "759, total loss = -83.95729064941406, reconstruct loss = 0.08661999553442001, cluster loss = 0.031708694994449615, calm loss = 7.085291385650635, pilot loss = 88.56353759765625, max interval = -259.1990966796875, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "760, total loss = -84.22528839111328, reconstruct loss = 0.09289886057376862, cluster loss = 0.02858307957649231, calm loss = 7.084051609039307, pilot loss = 88.79037475585938, max interval = -259.9093017578125, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "761, total loss = -84.48831939697266, reconstruct loss = 0.09671062231063843, cluster loss = 0.03092774748802185, calm loss = 7.1070146560668945, pilot loss = 89.08150482177734, max interval = -260.7431335449219, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "762, total loss = -84.77350616455078, reconstruct loss = 0.09152385592460632, cluster loss = 0.028416382148861885, calm loss = 7.148734092712402, pilot loss = 89.410400390625, max interval = -261.6695556640625, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "763, total loss = -85.05146026611328, reconstruct loss = 0.08851462602615356, cluster loss = 0.031011095270514488, calm loss = 7.196958065032959, pilot loss = 89.74429321289062, max interval = -262.61248779296875, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "764, total loss = -85.3314208984375, reconstruct loss = 0.08464392274618149, cluster loss = 0.031050607562065125, calm loss = 7.235849857330322, pilot loss = 90.05867004394531, max interval = -263.5121765136719, \n",
      "Train ACC: 0.8, PTA: 0.0908203125, Test ACC: 0.6129032258064516\n",
      "765, total loss = -85.61386108398438, reconstruct loss = 0.08609214425086975, cluster loss = 0.028048601001501083, calm loss = 7.243985176086426, pilot loss = 90.28559875488281, max interval = -264.2498474121094, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "766, total loss = -85.89704895019531, reconstruct loss = 0.08874496817588806, cluster loss = 0.028239935636520386, calm loss = 7.226321220397949, pilot loss = 90.44249725341797, max interval = -264.85791015625, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "767, total loss = -86.16838836669922, reconstruct loss = 0.08927205950021744, cluster loss = 0.029194403439760208, calm loss = 7.236030578613281, pilot loss = 90.66136169433594, max interval = -265.57476806640625, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "768, total loss = -86.43744659423828, reconstruct loss = 0.09951753914356232, cluster loss = 0.030449263751506805, calm loss = 7.282989501953125, pilot loss = 90.9739990234375, max interval = -266.4898376464844, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "769, total loss = -86.72975158691406, reconstruct loss = 0.091129370033741, cluster loss = 0.030706938356161118, calm loss = 7.320140838623047, pilot loss = 91.29425048828125, max interval = -267.40692138671875, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.6129032258064516\n",
      "770, total loss = -86.99298858642578, reconstruct loss = 0.09731686860322952, cluster loss = 0.03248453885316849, calm loss = 7.342893123626709, pilot loss = 91.59846496582031, max interval = -268.26202392578125, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.6129032258064516\n",
      "771, total loss = -87.28352355957031, reconstruct loss = 0.08934499323368073, cluster loss = 0.028439708054065704, calm loss = 7.383270263671875, pilot loss = 91.9441146850586, max interval = -269.2119445800781, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "772, total loss = -87.56465911865234, reconstruct loss = 0.09125122427940369, cluster loss = 0.030362721532583237, calm loss = 7.431990146636963, pilot loss = 92.29704284667969, max interval = -270.1933898925781, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "773, total loss = -87.84751892089844, reconstruct loss = 0.09482516348361969, cluster loss = 0.030022723600268364, calm loss = 7.4826178550720215, pilot loss = 92.62703704833984, max interval = -271.14642333984375, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "774, total loss = -88.11762237548828, reconstruct loss = 0.09037257730960846, cluster loss = 0.03211698308587074, calm loss = 7.51851749420166, pilot loss = 92.90916442871094, max interval = -271.9837951660156, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "775, total loss = -88.415283203125, reconstruct loss = 0.08730825036764145, cluster loss = 0.029878180474042892, calm loss = 7.5140700340271, pilot loss = 93.08890533447266, max interval = -272.6524353027344, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "776, total loss = -88.7005615234375, reconstruct loss = 0.08622343838214874, cluster loss = 0.03199043124914169, calm loss = 7.490332126617432, pilot loss = 93.2577896118164, max interval = -273.2693786621094, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "777, total loss = -88.98343658447266, reconstruct loss = 0.09003279358148575, cluster loss = 0.027758575975894928, calm loss = 7.512908935546875, pilot loss = 93.54010772705078, max interval = -274.1090087890625, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "778, total loss = -89.2773208618164, reconstruct loss = 0.08857178688049316, cluster loss = 0.032171718776226044, calm loss = 7.57538366317749, pilot loss = 93.91899108886719, max interval = -275.1641540527344, \n",
      "Train ACC: 0.8, PTA: 0.091796875, Test ACC: 0.6129032258064516\n",
      "779, total loss = -89.55784606933594, reconstruct loss = 0.08440407365560532, cluster loss = 0.03021707572042942, calm loss = 7.644580841064453, pilot loss = 94.32106018066406, max interval = -276.2299499511719, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "780, total loss = -89.84317779541016, reconstruct loss = 0.08880124241113663, cluster loss = 0.03022482991218567, calm loss = 7.673132419586182, pilot loss = 94.63096618652344, max interval = -277.1279602050781, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "781, total loss = -90.12360382080078, reconstruct loss = 0.09509122371673584, cluster loss = 0.031756021082401276, calm loss = 7.665886878967285, pilot loss = 94.8556900024414, max interval = -277.8509826660156, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "782, total loss = -90.41448974609375, reconstruct loss = 0.08716226369142532, cluster loss = 0.030201144516468048, calm loss = 7.676093101501465, pilot loss = 95.09895324707031, max interval = -278.61566162109375, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "783, total loss = -90.70375061035156, reconstruct loss = 0.08756521344184875, cluster loss = 0.02971765026450157, calm loss = 7.715076446533203, pilot loss = 95.41192626953125, max interval = -279.5321350097656, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "784, total loss = -91.00560760498047, reconstruct loss = 0.08719263225793839, cluster loss = 0.028462963178753853, calm loss = 7.774416923522949, pilot loss = 95.79219055175781, max interval = -280.589599609375, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "785, total loss = -91.29537963867188, reconstruct loss = 0.08688707649707794, cluster loss = 0.029121585190296173, calm loss = 7.82626485824585, pilot loss = 96.15428161621094, max interval = -281.5959777832031, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "786, total loss = -91.60045623779297, reconstruct loss = 0.09132025390863419, cluster loss = 0.03147656470537186, calm loss = 7.836298942565918, pilot loss = 96.41331481933594, max interval = -282.42645263671875, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "787, total loss = -91.9365234375, reconstruct loss = 0.08606922626495361, cluster loss = 0.03063039481639862, calm loss = 7.816876411437988, pilot loss = 96.59497833251953, max interval = -283.13018798828125, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "788, total loss = -92.22907257080078, reconstruct loss = 0.09016582369804382, cluster loss = 0.02880859375, calm loss = 7.8128204345703125, pilot loss = 96.83548736572266, max interval = -283.8897399902344, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "789, total loss = -92.55299377441406, reconstruct loss = 0.09829293936491013, cluster loss = 0.031154606491327286, calm loss = 7.874777317047119, pilot loss = 97.22884368896484, max interval = -285.0184631347656, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "790, total loss = -92.89031219482422, reconstruct loss = 0.08609684556722641, cluster loss = 0.030867839232087135, calm loss = 7.970407009124756, pilot loss = 97.7149887084961, max interval = -286.314208984375, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "791, total loss = -93.21173095703125, reconstruct loss = 0.08688784390687943, cluster loss = 0.028295625001192093, calm loss = 8.037433624267578, pilot loss = 98.1507797241211, max interval = -287.48968505859375, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "792, total loss = -93.54607391357422, reconstruct loss = 0.08753109723329544, cluster loss = 0.02973983623087406, calm loss = 8.061162948608398, pilot loss = 98.48785400390625, max interval = -288.486328125, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "793, total loss = -93.88626861572266, reconstruct loss = 0.087214894592762, cluster loss = 0.029812676832079887, calm loss = 8.059476852416992, pilot loss = 98.78345489501953, max interval = -289.3924255371094, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "794, total loss = -94.22505187988281, reconstruct loss = 0.088982492685318, cluster loss = 0.030534153804183006, calm loss = 8.057610511779785, pilot loss = 99.08216857910156, max interval = -290.3045959472656, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "795, total loss = -94.56926727294922, reconstruct loss = 0.09241486340761185, cluster loss = 0.028636950999498367, calm loss = 8.090228080749512, pilot loss = 99.46223449707031, max interval = -291.3886413574219, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "796, total loss = -94.9226303100586, reconstruct loss = 0.0928875282406807, cluster loss = 0.027585117146372795, calm loss = 8.157987594604492, pilot loss = 99.88483428955078, max interval = -292.5937194824219, \n",
      "Train ACC: 0.8, PTA: 0.0947265625, Test ACC: 0.6129032258064516\n",
      "797, total loss = -95.26200866699219, reconstruct loss = 0.08262326568365097, cluster loss = 0.029050299897789955, calm loss = 8.212493896484375, pilot loss = 100.28174591064453, max interval = -293.71142578125, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "798, total loss = -95.60151672363281, reconstruct loss = 0.0904400646686554, cluster loss = 0.031754862517118454, calm loss = 8.224648475646973, pilot loss = 100.603759765625, max interval = -294.6894226074219, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "799, total loss = -95.93734741210938, reconstruct loss = 0.09328175336122513, cluster loss = 0.032959796488285065, calm loss = 8.207707405090332, pilot loss = 100.88548278808594, max interval = -295.5538024902344, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "800, total loss = -96.30322265625, reconstruct loss = 0.08470302820205688, cluster loss = 0.031268276274204254, calm loss = 8.188619613647461, pilot loss = 101.1825180053711, max interval = -296.45947265625, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "801, total loss = -96.65501403808594, reconstruct loss = 0.0973275750875473, cluster loss = 0.029496710747480392, calm loss = 8.173713684082031, pilot loss = 101.49638366699219, max interval = -297.4051818847656, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "802, total loss = -97.03646087646484, reconstruct loss = 0.08739718794822693, cluster loss = 0.03047538921236992, calm loss = 8.166858673095703, pilot loss = 101.83338165283203, max interval = -298.4095458984375, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "803, total loss = -97.4125747680664, reconstruct loss = 0.09050481766462326, cluster loss = 0.028548765927553177, calm loss = 8.156675338745117, pilot loss = 102.16513061523438, max interval = -299.4084777832031, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "804, total loss = -97.77205657958984, reconstruct loss = 0.09464453160762787, cluster loss = 0.030036840587854385, calm loss = 8.1250638961792, pilot loss = 102.461669921875, max interval = -300.3091125488281, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "805, total loss = -98.14434814453125, reconstruct loss = 0.09117978811264038, cluster loss = 0.031098227947950363, calm loss = 8.087410926818848, pilot loss = 102.73286437988281, max interval = -301.1717224121094, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "806, total loss = -98.50274658203125, reconstruct loss = 0.09070540964603424, cluster loss = 0.028787242248654366, calm loss = 8.060967445373535, pilot loss = 103.02481842041016, max interval = -302.05963134765625, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "807, total loss = -98.88041687011719, reconstruct loss = 0.09159381687641144, cluster loss = 0.031219281256198883, calm loss = 8.093022346496582, pilot loss = 103.4050521850586, max interval = -303.1934814453125, \n",
      "Train ACC: 0.8, PTA: 0.0908203125, Test ACC: 0.6129032258064516\n",
      "808, total loss = -99.24757385253906, reconstruct loss = 0.08711213618516922, cluster loss = 0.02591385506093502, calm loss = 8.154552459716797, pilot loss = 103.84321594238281, max interval = -304.4184265136719, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "809, total loss = -99.60163116455078, reconstruct loss = 0.09156808257102966, cluster loss = 0.02994469180703163, calm loss = 8.175987243652344, pilot loss = 104.19229888916016, max interval = -305.46624755859375, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "810, total loss = -99.9803237915039, reconstruct loss = 0.09370341151952744, cluster loss = 0.02924547716975212, calm loss = 8.153450965881348, pilot loss = 104.45536804199219, max interval = -306.3534851074219, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "811, total loss = -100.35340118408203, reconstruct loss = 0.09976400434970856, cluster loss = 0.03219585120677948, calm loss = 8.102697372436523, pilot loss = 104.67085266113281, max interval = -307.1352233886719, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "812, total loss = -100.7347183227539, reconstruct loss = 0.0922432467341423, cluster loss = 0.028812620788812637, calm loss = 8.072332382202148, pilot loss = 104.9478759765625, max interval = -308.017333984375, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.6129032258064516\n",
      "813, total loss = -101.11495208740234, reconstruct loss = 0.09062765538692474, cluster loss = 0.02854320965707302, calm loss = 8.080081939697266, pilot loss = 105.2945327758789, max interval = -309.0647277832031, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "814, total loss = -101.47647857666016, reconstruct loss = 0.08752483129501343, cluster loss = 0.026214348152279854, calm loss = 8.103010177612305, pilot loss = 105.6398696899414, max interval = -310.10009765625, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "815, total loss = -101.83553314208984, reconstruct loss = 0.08383618295192719, cluster loss = 0.02778426557779312, calm loss = 8.119943618774414, pilot loss = 105.95674896240234, max interval = -311.08746337890625, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "816, total loss = -102.1664810180664, reconstruct loss = 0.09459029138088226, cluster loss = 0.030490245670080185, calm loss = 8.126408576965332, pilot loss = 106.2481689453125, max interval = -312.005615234375, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "817, total loss = -102.52135467529297, reconstruct loss = 0.09385896474123001, cluster loss = 0.030887018889188766, calm loss = 8.149682998657227, pilot loss = 106.56771087646484, max interval = -313.0024108886719, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "818, total loss = -102.87462615966797, reconstruct loss = 0.1029992625117302, cluster loss = 0.02893480658531189, calm loss = 8.184901237487793, pilot loss = 106.9009780883789, max interval = -314.0443420410156, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "819, total loss = -103.24085998535156, reconstruct loss = 0.08359267562627792, cluster loss = 0.026855748146772385, calm loss = 8.223760604858398, pilot loss = 107.2420425415039, max interval = -315.0801696777344, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "820, total loss = -103.56832122802734, reconstruct loss = 0.09684000164270401, cluster loss = 0.031184663996100426, calm loss = 8.232372283935547, pilot loss = 107.5263671875, max interval = -315.9921569824219, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "821, total loss = -103.91600799560547, reconstruct loss = 0.1002298966050148, cluster loss = 0.029762666672468185, calm loss = 8.234576225280762, pilot loss = 107.78275299072266, max interval = -316.86163330078125, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "822, total loss = -104.2667236328125, reconstruct loss = 0.09441255778074265, cluster loss = 0.031246477738022804, calm loss = 8.260730743408203, pilot loss = 108.07749938964844, max interval = -317.81549072265625, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "823, total loss = -104.61634063720703, reconstruct loss = 0.08631941676139832, cluster loss = 0.03179595619440079, calm loss = 8.278524398803711, pilot loss = 108.35860443115234, max interval = -318.73175048828125, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "824, total loss = -104.96219635009766, reconstruct loss = 0.0932246670126915, cluster loss = 0.031120315194129944, calm loss = 8.309581756591797, pilot loss = 108.66439056396484, max interval = -319.7165222167969, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.6129032258064516\n",
      "825, total loss = -105.3066177368164, reconstruct loss = 0.09632785618305206, cluster loss = 0.029916878789663315, calm loss = 8.343400001525879, pilot loss = 108.98307037353516, max interval = -320.7154235839844, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "826, total loss = -105.65910339355469, reconstruct loss = 0.09195578843355179, cluster loss = 0.028320327401161194, calm loss = 8.358685493469238, pilot loss = 109.27561950683594, max interval = -321.65081787109375, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "827, total loss = -106.01778411865234, reconstruct loss = 0.08404810726642609, cluster loss = 0.029998311772942543, calm loss = 8.358036994934082, pilot loss = 109.5523452758789, max interval = -322.5492858886719, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "828, total loss = -106.36932373046875, reconstruct loss = 0.0864386260509491, cluster loss = 0.029288295656442642, calm loss = 8.379152297973633, pilot loss = 109.893310546875, max interval = -323.5717468261719, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "829, total loss = -106.71102142333984, reconstruct loss = 0.09027048200368881, cluster loss = 0.031382542103528976, calm loss = 8.410016059875488, pilot loss = 110.27067565917969, max interval = -324.652099609375, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "830, total loss = -107.06228637695312, reconstruct loss = 0.0921584740281105, cluster loss = 0.032573021948337555, calm loss = 8.425765991210938, pilot loss = 110.6103286743164, max interval = -325.6666259765625, \n",
      "Train ACC: 0.8, PTA: 0.087890625, Test ACC: 0.6129032258064516\n",
      "831, total loss = -107.41048431396484, reconstruct loss = 0.09388920664787292, cluster loss = 0.03035488910973072, calm loss = 8.43273639678955, pilot loss = 110.92665100097656, max interval = -326.62579345703125, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "832, total loss = -107.76390075683594, reconstruct loss = 0.09105107188224792, cluster loss = 0.034272171556949615, calm loss = 8.46462345123291, pilot loss = 111.2921371459961, max interval = -327.7004699707031, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "833, total loss = -108.12791442871094, reconstruct loss = 0.09256917238235474, cluster loss = 0.02954118698835373, calm loss = 8.514302253723145, pilot loss = 111.68962097167969, max interval = -328.85528564453125, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "834, total loss = -108.470947265625, reconstruct loss = 0.09257177263498306, cluster loss = 0.030251648277044296, calm loss = 8.561408996582031, pilot loss = 112.08382415771484, max interval = -329.9773864746094, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.6129032258064516\n",
      "835, total loss = -108.83153533935547, reconstruct loss = 0.08914757519960403, cluster loss = 0.02780548483133316, calm loss = 8.587933540344238, pilot loss = 112.390380859375, max interval = -330.9605407714844, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "836, total loss = -109.19894409179688, reconstruct loss = 0.08948361873626709, cluster loss = 0.029947329312562943, calm loss = 8.597258567810059, pilot loss = 112.64569091796875, max interval = -331.8675842285156, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "837, total loss = -109.55117797851562, reconstruct loss = 0.08852281421422958, cluster loss = 0.02943679504096508, calm loss = 8.59555721282959, pilot loss = 112.90696716308594, max interval = -332.7400817871094, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "838, total loss = -109.91057586669922, reconstruct loss = 0.08536052703857422, cluster loss = 0.029149185866117477, calm loss = 8.63599967956543, pilot loss = 113.28028869628906, max interval = -333.84027099609375, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "839, total loss = -110.27674102783203, reconstruct loss = 0.08961609750986099, cluster loss = 0.02874273993074894, calm loss = 8.70740795135498, pilot loss = 113.73828125, max interval = -335.125732421875, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "840, total loss = -110.63724517822266, reconstruct loss = 0.08735287189483643, cluster loss = 0.029903527349233627, calm loss = 8.777863502502441, pilot loss = 114.21522521972656, max interval = -336.4217529296875, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "841, total loss = -110.9934310913086, reconstruct loss = 0.09560128301382065, cluster loss = 0.027116872370243073, calm loss = 8.805706024169922, pilot loss = 114.60636901855469, max interval = -337.53753662109375, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "842, total loss = -111.36894989013672, reconstruct loss = 0.09265722334384918, cluster loss = 0.030113592743873596, calm loss = 8.795012474060059, pilot loss = 114.8980712890625, max interval = -338.4761047363281, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "843, total loss = -111.73035430908203, reconstruct loss = 0.09274144470691681, cluster loss = 0.02991645596921444, calm loss = 8.785904884338379, pilot loss = 115.1914291381836, max interval = -339.3988952636719, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "844, total loss = -112.09940338134766, reconstruct loss = 0.09658099710941315, cluster loss = 0.02862275019288063, calm loss = 8.80975341796875, pilot loss = 115.51252746582031, max interval = -340.4231262207031, \n",
      "Train ACC: 0.8, PTA: 0.123046875, Test ACC: 0.6129032258064516\n",
      "845, total loss = -112.46964263916016, reconstruct loss = 0.08968993276357651, cluster loss = 0.029907595366239548, calm loss = 8.827199935913086, pilot loss = 115.8150634765625, max interval = -341.4017333984375, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "846, total loss = -112.8302001953125, reconstruct loss = 0.09921471774578094, cluster loss = 0.027966009452939034, calm loss = 8.873320579528809, pilot loss = 116.18257904052734, max interval = -342.5191650390625, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "847, total loss = -113.20467376708984, reconstruct loss = 0.09289255738258362, cluster loss = 0.027295134961605072, calm loss = 8.910847663879395, pilot loss = 116.54833984375, max interval = -343.620849609375, \n",
      "Train ACC: 0.8, PTA: 0.087890625, Test ACC: 0.6129032258064516\n",
      "848, total loss = -113.56461334228516, reconstruct loss = 0.09007798135280609, cluster loss = 0.03207296133041382, calm loss = 8.939596176147461, pilot loss = 116.9302749633789, max interval = -344.72515869140625, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "849, total loss = -113.93199157714844, reconstruct loss = 0.10123123973608017, cluster loss = 0.02964004874229431, calm loss = 8.974075317382812, pilot loss = 117.34828186035156, max interval = -345.909423828125, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "850, total loss = -114.30465698242188, reconstruct loss = 0.09715355932712555, cluster loss = 0.031353455036878586, calm loss = 9.023327827453613, pilot loss = 117.80711364746094, max interval = -347.16485595703125, \n",
      "Train ACC: 0.8, PTA: 0.1279296875, Test ACC: 0.6129032258064516\n",
      "851, total loss = -114.67423248291016, reconstruct loss = 0.09856703132390976, cluster loss = 0.028695765882730484, calm loss = 9.068897247314453, pilot loss = 118.2149887084961, max interval = -348.33941650390625, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.6129032258064516\n",
      "852, total loss = -115.05722045898438, reconstruct loss = 0.08477848768234253, cluster loss = 0.026711400598287582, calm loss = 9.099935531616211, pilot loss = 118.5638427734375, max interval = -349.4073181152344, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "853, total loss = -115.41018676757812, reconstruct loss = 0.0954010859131813, cluster loss = 0.030557677149772644, calm loss = 9.129956245422363, pilot loss = 118.9216537475586, max interval = -350.4868469238281, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.6129032258064516\n",
      "854, total loss = -115.7845687866211, reconstruct loss = 0.1002051904797554, cluster loss = 0.02798542007803917, calm loss = 9.16382884979248, pilot loss = 119.30900573730469, max interval = -351.6272277832031, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.6129032258064516\n",
      "855, total loss = -116.13691711425781, reconstruct loss = 0.0974283367395401, cluster loss = 0.02940211072564125, calm loss = 9.199579238891602, pilot loss = 119.71238708496094, max interval = -352.7565612792969, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "856, total loss = -116.50818634033203, reconstruct loss = 0.08989373594522476, cluster loss = 0.029630359262228012, calm loss = 9.218805313110352, pilot loss = 120.0679931640625, max interval = -353.8125915527344, \n",
      "Train ACC: 0.8, PTA: 0.1259765625, Test ACC: 0.6129032258064516\n",
      "857, total loss = -116.89163970947266, reconstruct loss = 0.08792240917682648, cluster loss = 0.03038046881556511, calm loss = 9.2318696975708, pilot loss = 120.40152740478516, max interval = -354.8543395996094, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "858, total loss = -117.257568359375, reconstruct loss = 0.09945070743560791, cluster loss = 0.031192215159535408, calm loss = 9.25506591796875, pilot loss = 120.7539291381836, max interval = -355.9319152832031, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "859, total loss = -117.63970184326172, reconstruct loss = 0.0911552757024765, cluster loss = 0.029721656814217567, calm loss = 9.305097579956055, pilot loss = 121.19693756103516, max interval = -357.1687927246094, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "860, total loss = -118.0169677734375, reconstruct loss = 0.09544526785612106, cluster loss = 0.02998337149620056, calm loss = 9.361224174499512, pilot loss = 121.6728515625, max interval = -358.47491455078125, \n",
      "Train ACC: 0.8, PTA: 0.1181640625, Test ACC: 0.6129032258064516\n",
      "861, total loss = -118.38279724121094, reconstruct loss = 0.09490624815225601, cluster loss = 0.030186692252755165, calm loss = 9.401593208312988, pilot loss = 122.13444519042969, max interval = -359.7147216796875, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "862, total loss = -118.76045989990234, reconstruct loss = 0.09606215357780457, cluster loss = 0.030392007902264595, calm loss = 9.395646095275879, pilot loss = 122.4663314819336, max interval = -360.722412109375, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "863, total loss = -119.13508605957031, reconstruct loss = 0.09472258388996124, cluster loss = 0.02885526418685913, calm loss = 9.390600204467773, pilot loss = 122.78660583496094, max interval = -361.70440673828125, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "864, total loss = -119.5146255493164, reconstruct loss = 0.0934147909283638, cluster loss = 0.029369976371526718, calm loss = 9.437128067016602, pilot loss = 123.2136001586914, max interval = -362.92254638671875, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "865, total loss = -119.90129089355469, reconstruct loss = 0.09033893048763275, cluster loss = 0.028506387025117874, calm loss = 9.519623756408691, pilot loss = 123.71195983886719, max interval = -364.2996826171875, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "866, total loss = -120.2718276977539, reconstruct loss = 0.09693746268749237, cluster loss = 0.029882019385695457, calm loss = 9.594803810119629, pilot loss = 124.206787109375, max interval = -365.6553039550781, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "867, total loss = -120.65757751464844, reconstruct loss = 0.09146509319543839, cluster loss = 0.03038187325000763, calm loss = 9.614066123962402, pilot loss = 124.6108627319336, max interval = -366.8046569824219, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "868, total loss = -121.04009246826172, reconstruct loss = 0.088729128241539, cluster loss = 0.0302667785435915, calm loss = 9.622407913208008, pilot loss = 124.99003601074219, max interval = -367.9012145996094, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "869, total loss = -121.42094421386719, reconstruct loss = 0.08844564855098724, cluster loss = 0.03173770383000374, calm loss = 9.648614883422852, pilot loss = 125.37834167480469, max interval = -369.03973388671875, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "870, total loss = -121.80162811279297, reconstruct loss = 0.09269450604915619, cluster loss = 0.03182484954595566, calm loss = 9.68630599975586, pilot loss = 125.76811218261719, max interval = -370.2010192871094, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "871, total loss = -122.18922424316406, reconstruct loss = 0.09138394147157669, cluster loss = 0.029179943725466728, calm loss = 9.717086791992188, pilot loss = 126.1390380859375, max interval = -371.32354736328125, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "872, total loss = -122.56346893310547, reconstruct loss = 0.09399392455816269, cluster loss = 0.03066634014248848, calm loss = 9.721071243286133, pilot loss = 126.4527359008789, max interval = -372.3184814453125, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6129032258064516\n",
      "873, total loss = -122.94816589355469, reconstruct loss = 0.09384596347808838, cluster loss = 0.02755168452858925, calm loss = 9.746306419372559, pilot loss = 126.8276596069336, max interval = -373.4356384277344, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "874, total loss = -123.3360824584961, reconstruct loss = 0.09330425411462784, cluster loss = 0.03045688383281231, calm loss = 9.801942825317383, pilot loss = 127.2850341796875, max interval = -374.7266540527344, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "875, total loss = -123.70188903808594, reconstruct loss = 0.09834086894989014, cluster loss = 0.02868867851793766, calm loss = 9.878007888793945, pilot loss = 127.78792572021484, max interval = -376.0815734863281, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "876, total loss = -124.10236358642578, reconstruct loss = 0.0923638567328453, cluster loss = 0.030266473069787025, calm loss = 9.90693187713623, pilot loss = 128.1781768798828, max interval = -377.246826171875, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "877, total loss = -124.49237060546875, reconstruct loss = 0.09394335001707077, cluster loss = 0.029204802587628365, calm loss = 9.895890235900879, pilot loss = 128.49700927734375, max interval = -378.2450256347656, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "878, total loss = -124.87647247314453, reconstruct loss = 0.09344211965799332, cluster loss = 0.027430232614278793, calm loss = 9.92646598815918, pilot loss = 128.90811157226562, max interval = -379.42205810546875, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "879, total loss = -125.27008819580078, reconstruct loss = 0.08776605129241943, cluster loss = 0.031136784702539444, calm loss = 10.005749702453613, pilot loss = 129.4209442138672, max interval = -380.8280334472656, \n",
      "Train ACC: 0.8, PTA: 0.0947265625, Test ACC: 0.6129032258064516\n",
      "880, total loss = -125.66021728515625, reconstruct loss = 0.0979464054107666, cluster loss = 0.03023592382669449, calm loss = 10.082904815673828, pilot loss = 129.9441680908203, max interval = -382.2569274902344, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "881, total loss = -126.05928802490234, reconstruct loss = 0.09991694986820221, cluster loss = 0.029794936999678612, calm loss = 10.146682739257812, pilot loss = 130.49209594726562, max interval = -383.70367431640625, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.6129032258064516\n",
      "882, total loss = -126.50672912597656, reconstruct loss = 0.0954640731215477, cluster loss = 0.02851668931543827, calm loss = 10.16131591796875, pilot loss = 130.97012329101562, max interval = -385.0390625, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "883, total loss = -126.97354888916016, reconstruct loss = 0.0976296216249466, cluster loss = 0.027936717495322227, calm loss = 10.141340255737305, pilot loss = 131.39279174804688, max interval = -386.2840881347656, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "884, total loss = -127.43672180175781, reconstruct loss = 0.0888577401638031, cluster loss = 0.030749579891562462, calm loss = 10.132898330688477, pilot loss = 131.87208557128906, max interval = -387.6105041503906, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "885, total loss = -127.90913391113281, reconstruct loss = 0.09604217857122421, cluster loss = 0.02856586128473282, calm loss = 10.135334014892578, pilot loss = 132.3870086669922, max interval = -389.0322265625, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "886, total loss = -128.3894805908203, reconstruct loss = 0.08722816407680511, cluster loss = 0.029323795810341835, calm loss = 10.146255493164062, pilot loss = 132.91477966308594, max interval = -390.4770812988281, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "887, total loss = -128.82345581054688, reconstruct loss = 0.09380678832530975, cluster loss = 0.030573315918445587, calm loss = 10.157005310058594, pilot loss = 133.400634765625, max interval = -391.8182373046875, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "888, total loss = -129.25730895996094, reconstruct loss = 0.09779910743236542, cluster loss = 0.029142403975129128, calm loss = 10.157644271850586, pilot loss = 133.87376403808594, max interval = -393.1191101074219, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "889, total loss = -129.70477294921875, reconstruct loss = 0.09122279286384583, cluster loss = 0.029233209788799286, calm loss = 10.130836486816406, pilot loss = 134.2750701904297, max interval = -394.2846984863281, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "890, total loss = -130.11708068847656, reconstruct loss = 0.08384384214878082, cluster loss = 0.029639335349202156, calm loss = 10.09752082824707, pilot loss = 134.60440063476562, max interval = -395.2872009277344, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "891, total loss = -130.5094757080078, reconstruct loss = 0.09298586845397949, cluster loss = 0.02909480594098568, calm loss = 10.09697151184082, pilot loss = 134.99688720703125, max interval = -396.42059326171875, \n",
      "Train ACC: 0.8, PTA: 0.0947265625, Test ACC: 0.6129032258064516\n",
      "892, total loss = -130.91845703125, reconstruct loss = 0.09923748672008514, cluster loss = 0.029163647443056107, calm loss = 10.133882522583008, pilot loss = 135.47396850585938, max interval = -397.748779296875, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.6129032258064516\n",
      "893, total loss = -131.33575439453125, reconstruct loss = 0.09508281946182251, cluster loss = 0.028810666874051094, calm loss = 10.206607818603516, pilot loss = 136.02047729492188, max interval = -399.2236633300781, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "894, total loss = -131.74383544921875, reconstruct loss = 0.09713302552700043, cluster loss = 0.029759250581264496, calm loss = 10.246417045593262, pilot loss = 136.49252319335938, max interval = -400.54278564453125, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "895, total loss = -132.15814208984375, reconstruct loss = 0.09454376995563507, cluster loss = 0.029701747000217438, calm loss = 10.28623104095459, pilot loss = 136.95755004882812, max interval = -401.8526916503906, \n",
      "Train ACC: 0.8, PTA: 0.126953125, Test ACC: 0.6129032258064516\n",
      "896, total loss = -132.5759735107422, reconstruct loss = 0.09351950138807297, cluster loss = 0.031090252101421356, calm loss = 10.340705871582031, pilot loss = 137.4424285888672, max interval = -403.2212219238281, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "897, total loss = -132.9975128173828, reconstruct loss = 0.09442850202322006, cluster loss = 0.03169241175055504, calm loss = 10.388738632202148, pilot loss = 137.9302520751953, max interval = -404.5916748046875, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "898, total loss = -133.43092346191406, reconstruct loss = 0.09268215298652649, cluster loss = 0.028205445036292076, calm loss = 10.420859336853027, pilot loss = 138.395263671875, max interval = -405.9141540527344, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "899, total loss = -133.8518829345703, reconstruct loss = 0.10276280343532562, cluster loss = 0.027452988550066948, calm loss = 10.4500150680542, pilot loss = 138.83631896972656, max interval = -407.2012023925781, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "900, total loss = -134.29397583007812, reconstruct loss = 0.09076163172721863, cluster loss = 0.03172023221850395, calm loss = 10.472705841064453, pilot loss = 139.2509765625, max interval = -408.4471130371094, \n",
      "Train ACC: 0.8, PTA: 0.095703125, Test ACC: 0.6129032258064516\n",
      "901, total loss = -134.71644592285156, reconstruct loss = 0.0875045508146286, cluster loss = 0.02680930681526661, calm loss = 10.483382225036621, pilot loss = 139.61502075195312, max interval = -409.57489013671875, \n",
      "Train ACC: 0.8, PTA: 0.08984375, Test ACC: 0.6129032258064516\n",
      "902, total loss = -135.12551879882812, reconstruct loss = 0.0969410091638565, cluster loss = 0.030687224119901657, calm loss = 10.514688491821289, pilot loss = 140.03965759277344, max interval = -410.83026123046875, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "903, total loss = -135.56793212890625, reconstruct loss = 0.09321688860654831, cluster loss = 0.027239665389060974, calm loss = 10.56013298034668, pilot loss = 140.4999237060547, max interval = -412.1750793457031, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "904, total loss = -136.00747680664062, reconstruct loss = 0.09306738525629044, cluster loss = 0.02696968987584114, calm loss = 10.615038871765137, pilot loss = 140.97503662109375, max interval = -413.5601806640625, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.6129032258064516\n",
      "905, total loss = -136.4162139892578, reconstruct loss = 0.09730260819196701, cluster loss = 0.029898252338171005, calm loss = 10.691120147705078, pilot loss = 141.48220825195312, max interval = -414.9881591796875, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "906, total loss = -136.8700408935547, reconstruct loss = 0.08334244787693024, cluster loss = 0.02657974138855934, calm loss = 10.73166561126709, pilot loss = 141.90635681152344, max interval = -416.2762451171875, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "907, total loss = -137.2965850830078, reconstruct loss = 0.08759777247905731, cluster loss = 0.030143985524773598, calm loss = 10.740710258483887, pilot loss = 142.26116943359375, max interval = -417.41717529296875, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "908, total loss = -137.70945739746094, reconstruct loss = 0.10046234726905823, cluster loss = 0.028221167623996735, calm loss = 10.751640319824219, pilot loss = 142.63046264648438, max interval = -418.56640625, \n",
      "Train ACC: 0.8, PTA: 0.09765625, Test ACC: 0.6129032258064516\n",
      "909, total loss = -138.14520263671875, reconstruct loss = 0.102225661277771, cluster loss = 0.028667815029621124, calm loss = 10.782072067260742, pilot loss = 143.0485382080078, max interval = -419.83343505859375, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "910, total loss = -138.59909057617188, reconstruct loss = 0.08730299025774002, cluster loss = 0.029827291145920753, calm loss = 10.841264724731445, pilot loss = 143.51327514648438, max interval = -421.21124267578125, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "911, total loss = -139.0059814453125, reconstruct loss = 0.10222606360912323, cluster loss = 0.02977641299366951, calm loss = 10.918071746826172, pilot loss = 144.02003479003906, max interval = -422.6480712890625, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "912, total loss = -139.44886779785156, reconstruct loss = 0.09662671387195587, cluster loss = 0.03009636513888836, calm loss = 10.958760261535645, pilot loss = 144.44564819335938, max interval = -423.9399719238281, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "913, total loss = -139.8999786376953, reconstruct loss = 0.09064806252717972, cluster loss = 0.027235519140958786, calm loss = 10.969627380371094, pilot loss = 144.80813598632812, max interval = -425.10577392578125, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.6129032258064516\n",
      "914, total loss = -140.3242950439453, reconstruct loss = 0.09321261197328568, cluster loss = 0.03162987902760506, calm loss = 10.984853744506836, pilot loss = 145.20541381835938, max interval = -426.3117980957031, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "915, total loss = -140.77220153808594, reconstruct loss = 0.09129314124584198, cluster loss = 0.030087895691394806, calm loss = 11.030912399291992, pilot loss = 145.70510864257812, max interval = -427.72698974609375, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "916, total loss = -141.21295166015625, reconstruct loss = 0.0976259782910347, cluster loss = 0.030498381704092026, calm loss = 11.099790573120117, pilot loss = 146.2674102783203, max interval = -429.2685546875, \n",
      "Train ACC: 0.8, PTA: 0.1123046875, Test ACC: 0.6129032258064516\n",
      "917, total loss = -141.64938354492188, reconstruct loss = 0.09581242501735687, cluster loss = 0.02924732305109501, calm loss = 11.123047828674316, pilot loss = 146.72686767578125, max interval = -430.57781982421875, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "918, total loss = -142.09007263183594, reconstruct loss = 0.09310095757246017, cluster loss = 0.030923884361982346, calm loss = 11.144695281982422, pilot loss = 147.15997314453125, max interval = -431.8561706542969, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "919, total loss = -142.52784729003906, reconstruct loss = 0.09475570172071457, cluster loss = 0.028355693444609642, calm loss = 11.177183151245117, pilot loss = 147.59817504882812, max interval = -433.1532897949219, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "920, total loss = -142.9776153564453, reconstruct loss = 0.09351259469985962, cluster loss = 0.028137417510151863, calm loss = 11.198983192443848, pilot loss = 148.0187530517578, max interval = -434.42633056640625, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "921, total loss = -143.42691040039062, reconstruct loss = 0.08800113201141357, cluster loss = 0.027782265096902847, calm loss = 11.262615203857422, pilot loss = 148.51187133789062, max interval = -435.8557434082031, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "922, total loss = -143.86167907714844, reconstruct loss = 0.09295608848333359, cluster loss = 0.028012381866574287, calm loss = 11.336935043334961, pilot loss = 149.03179931640625, max interval = -437.33380126953125, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "923, total loss = -144.30105590820312, reconstruct loss = 0.09210777282714844, cluster loss = 0.027650397270917892, calm loss = 11.401609420776367, pilot loss = 149.53421020507812, max interval = -438.7705078125, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "924, total loss = -144.75192260742188, reconstruct loss = 0.0942152887582779, cluster loss = 0.028061704710125923, calm loss = 11.417379379272461, pilot loss = 149.9558563232422, max interval = -440.0436706542969, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "925, total loss = -145.20477294921875, reconstruct loss = 0.08706491440534592, cluster loss = 0.028628166764974594, calm loss = 11.430215835571289, pilot loss = 150.3872528076172, max interval = -441.3164367675781, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "926, total loss = -145.65106201171875, reconstruct loss = 0.08742941170930862, cluster loss = 0.02957143448293209, calm loss = 11.466283798217773, pilot loss = 150.86277770996094, max interval = -442.6873474121094, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "927, total loss = -146.08682250976562, reconstruct loss = 0.10042749345302582, cluster loss = 0.027624931186437607, calm loss = 11.530817031860352, pilot loss = 151.38414001464844, max interval = -444.16326904296875, \n",
      "Train ACC: 0.8, PTA: 0.12109375, Test ACC: 0.6129032258064516\n",
      "928, total loss = -146.5278778076172, reconstruct loss = 0.09833390265703201, cluster loss = 0.029351113364100456, calm loss = 11.593452453613281, pilot loss = 151.90379333496094, max interval = -445.6252746582031, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "929, total loss = -146.9933624267578, reconstruct loss = 0.09559673070907593, cluster loss = 0.030638551339507103, calm loss = 11.61392879486084, pilot loss = 152.32211303710938, max interval = -446.9156494140625, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "930, total loss = -147.44313049316406, reconstruct loss = 0.09367691725492477, cluster loss = 0.030275527387857437, calm loss = 11.63664722442627, pilot loss = 152.7343292236328, max interval = -448.1768493652344, \n",
      "Train ACC: 0.8, PTA: 0.1220703125, Test ACC: 0.6129032258064516\n",
      "931, total loss = -147.89859008789062, reconstruct loss = 0.09172902256250381, cluster loss = 0.031494610011577606, calm loss = 11.675556182861328, pilot loss = 153.18174743652344, max interval = -449.5218505859375, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "932, total loss = -148.35577392578125, reconstruct loss = 0.09108798950910568, cluster loss = 0.03142412379384041, calm loss = 11.733864784240723, pilot loss = 153.6761016845703, max interval = -450.964111328125, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "933, total loss = -148.80059814453125, reconstruct loss = 0.09888813644647598, cluster loss = 0.02925693802535534, calm loss = 11.796097755432129, pilot loss = 154.20474243164062, max interval = -452.45233154296875, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "934, total loss = -149.268798828125, reconstruct loss = 0.09459805488586426, cluster loss = 0.030338088050484657, calm loss = 11.834464073181152, pilot loss = 154.68350219726562, max interval = -453.8559265136719, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "935, total loss = -149.72630310058594, reconstruct loss = 0.09457884728908539, cluster loss = 0.027595270425081253, calm loss = 11.88754653930664, pilot loss = 155.18487548828125, max interval = -455.2983093261719, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "936, total loss = -150.184326171875, reconstruct loss = 0.08990322053432465, cluster loss = 0.028931695967912674, calm loss = 11.944879531860352, pilot loss = 155.6768035888672, max interval = -456.7331237792969, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "937, total loss = -150.6281280517578, reconstruct loss = 0.09988293796777725, cluster loss = 0.03147998824715614, calm loss = 11.995965957641602, pilot loss = 156.1797637939453, max interval = -458.1771545410156, \n",
      "Train ACC: 0.8, PTA: 0.1201171875, Test ACC: 0.6129032258064516\n",
      "938, total loss = -151.09376525878906, reconstruct loss = 0.09668774902820587, cluster loss = 0.02699378691613674, calm loss = 11.999934196472168, pilot loss = 156.59829711914062, max interval = -459.435546875, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "939, total loss = -151.56134033203125, reconstruct loss = 0.08921407908201218, cluster loss = 0.029448356479406357, calm loss = 12.042092323303223, pilot loss = 157.10604858398438, max interval = -460.882568359375, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "940, total loss = -152.01654052734375, reconstruct loss = 0.09896227717399597, cluster loss = 0.028250960633158684, calm loss = 12.118657112121582, pilot loss = 157.67356872558594, max interval = -462.4657897949219, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "941, total loss = -152.4692840576172, reconstruct loss = 0.09338704496622086, cluster loss = 0.03063758835196495, calm loss = 12.183709144592285, pilot loss = 158.21633911132812, max interval = -463.9769592285156, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "942, total loss = -152.9432373046875, reconstruct loss = 0.09313167631626129, cluster loss = 0.030630391091108322, calm loss = 12.181360244750977, pilot loss = 158.62631225585938, max interval = -465.2366027832031, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "943, total loss = -153.3992462158203, reconstruct loss = 0.09574921429157257, cluster loss = 0.029934844002127647, calm loss = 12.215070724487305, pilot loss = 159.07847595214844, max interval = -466.58551025390625, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "944, total loss = -153.87222290039062, reconstruct loss = 0.09083107113838196, cluster loss = 0.028750425204634666, calm loss = 12.28619384765625, pilot loss = 159.60887145996094, max interval = -468.1124267578125, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "945, total loss = -154.3275146484375, reconstruct loss = 0.09980886429548264, cluster loss = 0.02765723504126072, calm loss = 12.358023643493652, pilot loss = 160.12545776367188, max interval = -469.6153259277344, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "946, total loss = -154.7930450439453, reconstruct loss = 0.09625120460987091, cluster loss = 0.028959054499864578, calm loss = 12.406289100646973, pilot loss = 160.6045379638672, max interval = -471.0311279296875, \n",
      "Train ACC: 0.8, PTA: 0.119140625, Test ACC: 0.6129032258064516\n",
      "947, total loss = -155.26683044433594, reconstruct loss = 0.09672226756811142, cluster loss = 0.030674640089273453, calm loss = 12.391465187072754, pilot loss = 160.9918975830078, max interval = -472.2438659667969, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "948, total loss = -155.73733520507812, reconstruct loss = 0.08941781520843506, cluster loss = 0.031553965061903, calm loss = 12.417698860168457, pilot loss = 161.47628784179688, max interval = -473.63690185546875, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "949, total loss = -156.20924377441406, reconstruct loss = 0.08930753916501999, cluster loss = 0.028679894283413887, calm loss = 12.48802661895752, pilot loss = 162.0336151123047, max interval = -475.2040710449219, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "950, total loss = -156.6768341064453, reconstruct loss = 0.08857055008411407, cluster loss = 0.03151238337159157, calm loss = 12.559537887573242, pilot loss = 162.59219360351562, max interval = -476.77581787109375, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "951, total loss = -157.14112854003906, reconstruct loss = 0.09396954625844955, cluster loss = 0.028907474130392075, calm loss = 12.602785110473633, pilot loss = 163.10385131835938, max interval = -478.2364501953125, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "952, total loss = -157.60800170898438, reconstruct loss = 0.10014735162258148, cluster loss = 0.027237296104431152, calm loss = 12.600854873657227, pilot loss = 163.50759887695312, max interval = -479.4844665527344, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "953, total loss = -158.08619689941406, reconstruct loss = 0.09357520192861557, cluster loss = 0.029802031815052032, calm loss = 12.640186309814453, pilot loss = 163.99952697753906, max interval = -480.9214782714844, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "954, total loss = -158.5662841796875, reconstruct loss = 0.08832279592752457, cluster loss = 0.03077547624707222, calm loss = 12.732580184936523, pilot loss = 164.58346557617188, max interval = -482.5679626464844, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "955, total loss = -159.04180908203125, reconstruct loss = 0.087831512093544, cluster loss = 0.030233552679419518, calm loss = 12.806890487670898, pilot loss = 165.13067626953125, max interval = -484.13433837890625, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "956, total loss = -159.5171661376953, reconstruct loss = 0.09176596254110336, cluster loss = 0.029416285455226898, calm loss = 12.835350036621094, pilot loss = 165.58628845214844, max interval = -485.5100402832031, \n",
      "Train ACC: 0.8, PTA: 0.091796875, Test ACC: 0.6129032258064516\n",
      "957, total loss = -159.9805908203125, reconstruct loss = 0.09753625094890594, cluster loss = 0.029287289828062057, calm loss = 12.850187301635742, pilot loss = 166.0263214111328, max interval = -486.8305969238281, \n",
      "Train ACC: 0.8, PTA: 0.109375, Test ACC: 0.6129032258064516\n",
      "958, total loss = -160.4666290283203, reconstruct loss = 0.09204769879579544, cluster loss = 0.029230043292045593, calm loss = 12.862797737121582, pilot loss = 166.4612579345703, max interval = -488.1569519042969, \n",
      "Train ACC: 0.8, PTA: 0.1005859375, Test ACC: 0.6129032258064516\n",
      "959, total loss = -160.9401397705078, reconstruct loss = 0.09681075066328049, cluster loss = 0.03191129118204117, calm loss = 12.934202194213867, pilot loss = 167.0133056640625, max interval = -489.7353515625, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "960, total loss = -161.42807006835938, reconstruct loss = 0.09065201133489609, cluster loss = 0.030663717538118362, calm loss = 13.03149700164795, pilot loss = 167.62973022460938, max interval = -491.4420166015625, \n",
      "Train ACC: 0.8, PTA: 0.1171875, Test ACC: 0.6129032258064516\n",
      "961, total loss = -161.89926147460938, reconstruct loss = 0.10093433409929276, cluster loss = 0.029757684096693993, calm loss = 13.096667289733887, pilot loss = 168.17294311523438, max interval = -492.998291015625, \n",
      "Train ACC: 0.8, PTA: 0.107421875, Test ACC: 0.6129032258064516\n",
      "962, total loss = -162.38209533691406, reconstruct loss = 0.09759415686130524, cluster loss = 0.02975388616323471, calm loss = 13.12995719909668, pilot loss = 168.6461944580078, max interval = -494.40753173828125, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "963, total loss = -162.86512756347656, reconstruct loss = 0.09868474304676056, cluster loss = 0.030353616923093796, calm loss = 13.15778636932373, pilot loss = 169.11349487304688, max interval = -495.80792236328125, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "964, total loss = -163.35708618164062, reconstruct loss = 0.09223023056983948, cluster loss = 0.030469024553894997, calm loss = 13.157159805297852, pilot loss = 169.54212951660156, max interval = -497.1137390136719, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "965, total loss = -163.83836364746094, reconstruct loss = 0.09367252141237259, cluster loss = 0.029098594561219215, calm loss = 13.191743850708008, pilot loss = 170.05223083496094, max interval = -498.5801086425781, \n",
      "Train ACC: 0.8, PTA: 0.115234375, Test ACC: 0.6129032258064516\n",
      "966, total loss = -164.3168487548828, reconstruct loss = 0.09174630045890808, cluster loss = 0.03127574548125267, calm loss = 13.274877548217773, pilot loss = 170.65200805664062, max interval = -500.240234375, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "967, total loss = -164.80352783203125, reconstruct loss = 0.09659086912870407, cluster loss = 0.029434112831950188, calm loss = 13.357378959655762, pilot loss = 171.25186157226562, max interval = -501.91522216796875, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "968, total loss = -165.29620361328125, reconstruct loss = 0.09738881140947342, cluster loss = 0.027829144150018692, calm loss = 13.416015625, pilot loss = 171.7792510986328, max interval = -503.4556884765625, \n",
      "Train ACC: 0.8, PTA: 0.091796875, Test ACC: 0.6129032258064516\n",
      "969, total loss = -165.78396606445312, reconstruct loss = 0.08874351531267166, cluster loss = 0.03080824203789234, calm loss = 13.450431823730469, pilot loss = 172.25448608398438, max interval = -504.8730773925781, \n",
      "Train ACC: 0.8, PTA: 0.0859375, Test ACC: 0.6129032258064516\n",
      "970, total loss = -166.271240234375, reconstruct loss = 0.09166792780160904, cluster loss = 0.02973206713795662, calm loss = 13.43694019317627, pilot loss = 172.63026428222656, max interval = -506.09002685546875, \n",
      "Train ACC: 0.8, PTA: 0.1025390625, Test ACC: 0.6129032258064516\n",
      "971, total loss = -166.7582244873047, reconstruct loss = 0.0977448970079422, cluster loss = 0.029402680695056915, calm loss = 13.465375900268555, pilot loss = 173.15048217773438, max interval = -507.578369140625, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "972, total loss = -167.25604248046875, reconstruct loss = 0.09577051550149918, cluster loss = 0.02866487391293049, calm loss = 13.554069519042969, pilot loss = 173.81100463867188, max interval = -509.3565673828125, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "973, total loss = -167.7448272705078, reconstruct loss = 0.09424735605716705, cluster loss = 0.029924176633358, calm loss = 13.636164665222168, pilot loss = 174.44338989257812, max interval = -511.0758056640625, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "974, total loss = -168.2389678955078, reconstruct loss = 0.0935787633061409, cluster loss = 0.028115244582295418, calm loss = 13.67328929901123, pilot loss = 174.94668579101562, max interval = -512.55078125, \n",
      "Train ACC: 0.8, PTA: 0.1298828125, Test ACC: 0.6129032258064516\n",
      "975, total loss = -168.73562622070312, reconstruct loss = 0.09701687842607498, cluster loss = 0.028476282954216003, calm loss = 13.677650451660156, pilot loss = 175.3478240966797, max interval = -513.8456420898438, \n",
      "Train ACC: 0.8, PTA: 0.0986328125, Test ACC: 0.6129032258064516\n",
      "976, total loss = -169.22857666015625, reconstruct loss = 0.0915839821100235, cluster loss = 0.02854815497994423, calm loss = 13.686285018920898, pilot loss = 175.7552490234375, max interval = -515.13720703125, \n",
      "Train ACC: 0.8, PTA: 0.0859375, Test ACC: 0.6129032258064516\n",
      "977, total loss = -169.72605895996094, reconstruct loss = 0.09208562970161438, cluster loss = 0.030598290264606476, calm loss = 13.750905990600586, pilot loss = 176.29299926757812, max interval = -516.7127075195312, \n",
      "Train ACC: 0.8, PTA: 0.1103515625, Test ACC: 0.6129032258064516\n",
      "978, total loss = -170.23129272460938, reconstruct loss = 0.09183526784181595, cluster loss = 0.029772359877824783, calm loss = 13.842931747436523, pilot loss = 176.89329528808594, max interval = -518.422607421875, \n",
      "Train ACC: 0.8, PTA: 0.1162109375, Test ACC: 0.6129032258064516\n",
      "979, total loss = -170.71893310546875, reconstruct loss = 0.09755963087081909, cluster loss = 0.031110428273677826, calm loss = 13.908534049987793, pilot loss = 177.4597930908203, max interval = -520.032958984375, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "980, total loss = -171.2259521484375, reconstruct loss = 0.09505930542945862, cluster loss = 0.02959643118083477, calm loss = 13.9469633102417, pilot loss = 177.98287963867188, max interval = -521.5543212890625, \n",
      "Train ACC: 0.8, PTA: 0.1044921875, Test ACC: 0.6129032258064516\n",
      "981, total loss = -171.73597717285156, reconstruct loss = 0.09303950518369675, cluster loss = 0.02882825955748558, calm loss = 13.968292236328125, pilot loss = 178.46055603027344, max interval = -522.992431640625, \n",
      "Train ACC: 0.8, PTA: 0.0908203125, Test ACC: 0.6129032258064516\n",
      "982, total loss = -172.2337188720703, reconstruct loss = 0.09221574664115906, cluster loss = 0.030645951628684998, calm loss = 13.94665813446045, pilot loss = 178.85728454589844, max interval = -524.2413940429688, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "983, total loss = -172.7357940673828, reconstruct loss = 0.09561154246330261, cluster loss = 0.02948042005300522, calm loss = 14.00703239440918, pilot loss = 179.4153594970703, max interval = -525.845947265625, \n",
      "Train ACC: 0.8, PTA: 0.11328125, Test ACC: 0.6129032258064516\n",
      "984, total loss = -173.23541259765625, reconstruct loss = 0.0956859290599823, cluster loss = 0.03138938546180725, calm loss = 14.139764785766602, pilot loss = 180.10140991210938, max interval = -527.7328491210938, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "985, total loss = -173.7490692138672, reconstruct loss = 0.09399408102035522, cluster loss = 0.0317569375038147, calm loss = 14.2424955368042, pilot loss = 180.7345733642578, max interval = -529.5166625976562, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "986, total loss = -174.26773071289062, reconstruct loss = 0.0944044217467308, cluster loss = 0.029641851782798767, calm loss = 14.291478157043457, pilot loss = 181.25730895996094, max interval = -531.072509765625, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "987, total loss = -174.77169799804688, reconstruct loss = 0.09603609144687653, cluster loss = 0.03047827258706093, calm loss = 14.310224533081055, pilot loss = 181.70066833496094, max interval = -532.456787109375, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "988, total loss = -175.2866973876953, reconstruct loss = 0.08544482290744781, cluster loss = 0.03105730563402176, calm loss = 14.340362548828125, pilot loss = 182.17782592773438, max interval = -533.903564453125, \n",
      "Train ACC: 0.8, PTA: 0.1083984375, Test ACC: 0.6129032258064516\n",
      "989, total loss = -175.79507446289062, reconstruct loss = 0.08785054087638855, cluster loss = 0.03211607411503792, calm loss = 14.395237922668457, pilot loss = 182.73280334472656, max interval = -535.506591796875, \n",
      "Train ACC: 0.8, PTA: 0.111328125, Test ACC: 0.6129032258064516\n",
      "990, total loss = -176.3081512451172, reconstruct loss = 0.09664171934127808, cluster loss = 0.030465751886367798, calm loss = 14.424100875854492, pilot loss = 183.26380920410156, max interval = -537.0502319335938, \n",
      "Train ACC: 0.8, PTA: 0.0966796875, Test ACC: 0.6129032258064516\n",
      "991, total loss = -176.8249053955078, reconstruct loss = 0.09566371887922287, cluster loss = 0.027183983474969864, calm loss = 14.4706392288208, pilot loss = 183.83204650878906, max interval = -538.6612548828125, \n",
      "Train ACC: 0.8, PTA: 0.103515625, Test ACC: 0.6129032258064516\n",
      "992, total loss = -177.33949279785156, reconstruct loss = 0.09877629578113556, cluster loss = 0.028213977813720703, calm loss = 14.526750564575195, pilot loss = 184.41061401367188, max interval = -540.3095703125, \n",
      "Train ACC: 0.8, PTA: 0.09375, Test ACC: 0.6129032258064516\n",
      "993, total loss = -177.86410522460938, reconstruct loss = 0.08949548751115799, cluster loss = 0.027022184804081917, calm loss = 14.598834037780762, pilot loss = 185.00018310546875, max interval = -541.9899291992188, \n",
      "Train ACC: 0.8, PTA: 0.0947265625, Test ACC: 0.6129032258064516\n",
      "994, total loss = -178.38577270507812, reconstruct loss = 0.08458517491817474, cluster loss = 0.032194942235946655, calm loss = 14.657228469848633, pilot loss = 185.53834533691406, max interval = -543.58837890625, \n",
      "Train ACC: 0.8, PTA: 0.099609375, Test ACC: 0.6129032258064516\n",
      "995, total loss = -178.89234924316406, reconstruct loss = 0.09737859666347504, cluster loss = 0.030792146921157837, calm loss = 14.724334716796875, pilot loss = 186.07589721679688, max interval = -545.1928100585938, \n",
      "Train ACC: 0.8, PTA: 0.10546875, Test ACC: 0.6129032258064516\n",
      "996, total loss = -179.41934204101562, reconstruct loss = 0.09199889749288559, cluster loss = 0.029520737007260323, calm loss = 14.764988899230957, pilot loss = 186.56863403320312, max interval = -546.69873046875, \n",
      "Train ACC: 0.8, PTA: 0.1064453125, Test ACC: 0.6129032258064516\n",
      "997, total loss = -179.94219970703125, reconstruct loss = 0.09203749895095825, cluster loss = 0.030006535351276398, calm loss = 14.802385330200195, pilot loss = 187.08633422851562, max interval = -548.2400512695312, \n",
      "Train ACC: 0.8, PTA: 0.1142578125, Test ACC: 0.6129032258064516\n",
      "998, total loss = -180.46630859375, reconstruct loss = 0.09496293216943741, cluster loss = 0.029623668640851974, calm loss = 14.836019515991211, pilot loss = 187.6070556640625, max interval = -549.7849731445312, \n",
      "Train ACC: 0.8, PTA: 0.0869140625, Test ACC: 0.6129032258064516\n",
      "999, total loss = -180.99493408203125, reconstruct loss = 0.08582644909620285, cluster loss = 0.0315132662653923, calm loss = 14.914006233215332, pilot loss = 188.21434020996094, max interval = -551.5093994140625, \n",
      "Train ACC: 0.8, PTA: 0.1015625, Test ACC: 0.6129032258064516\n",
      "INFO:tensorflow:sdec_ckpt\\model_transfer.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:Restoring parameters from sdec_ckpt\\model_transfer.ckpt\n"
     ]
    }
   ],
   "source": [
    "corridor_months_north = []\n",
    "for i in range(12):\n",
    "    corridor_months_north.append(np.vstack((corridor_month_2020_transfer[i],corridor_month_2021_transfer[i])))\n",
    "Data.read_data_for_transfer_learning()\n",
    "clusternn.transfer_learning(Data,Data.pilot_train_transfer,train_steps = 1000, BATCH_SIZE = 1024)\n",
    "hazard_factors_months_north = clusternn.seasonal_statistic_fit_transfer(Data,corridor_months_north,Data.pilot_train_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b216fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "def hazard_factor_ratio_cal(hazard_factors_months_i):\n",
    "    hazard_factors_months = []\n",
    "    for i in range(12):\n",
    "        hazard_factors_months = hazard_factors_months+list(hazard_factors_months_i[i])\n",
    "    hazard_factors_months = np.array(hazard_factors_months)\n",
    "    percentitle_value = (np.quantile(hazard_factors_months,0.90))\n",
    "    print(percentitle_value)\n",
    "    ratio_hazard_factor_extremes = []\n",
    "    for i in range(12):\n",
    "        ratio_hazard_factor_extremes.append(np.sum(hazard_factors_months_i[i]>percentitle_value)/hazard_factors_months_i[i].size)\n",
    "    return ratio_hazard_factor_extremes\n",
    "def correlation_heatmap(train):\n",
    "    correlations = train.corr(method='spearman')\n",
    "    cmap = sns.diverging_palette(220,20, center='light',as_cmap=True)\n",
    "    mask = np.zeros_like(correlations, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = False\n",
    "    sns.heatmap(correlations, mask=mask, cmap=cmap, fmt='.2f',\n",
    "    square=True, linewidths=.2, annot=True, vmax=0.99,cbar_kws={'shrink': .50,'extend':'both','pad':0.02}\n",
    "    )\n",
    "    plt.gca().add_patch(plt.Rectangle(xy=(0, 0),width=3,height=3,edgecolor='k',fill=False,linewidth=3))\n",
    "    plt.gca().add_patch(plt.Rectangle(xy=(3, 3),width=5,height=5,edgecolor='k',fill=False,linewidth=3))\n",
    "    plt.xticks([0.5,1.5],['21 years','2020~2021'])\n",
    "    plt.yticks([0.5,1.5],['21 years','2020~2021'])\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f335d444",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,13),Occurrence_prob_21.normalize(hazard_factor_ratio_cal(hazard_factors_months_2020_transfer)),label='2020',alpha=0.6,color='C2')\n",
    "plt.plot(range(1,13),Occurrence_prob_21.normalize(hazard_factor_ratio_cal(hazard_factors_months_2021_transfer)),label='2021',alpha=0.6,color='C3')\n",
    "plt.vlines([2.5,5.5,8.5,11.5],[-0.5,-0.5,-0.5,-0.5],[1.5,1.5,1.5,1.5],colors='C7',linewidth=0.5,alpha=0.5)\n",
    "plt.plot(range(1,13),Occurrence_prob_21.ratio_pilot_month_21_years_north[0],label='21-years',marker='*',color='#2E94B9',linewidth=2)\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend(frameon=False,ncol=2)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28928d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09916195241917523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD4CAYAAADRlDL+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWfUlEQVR4nO3dfZzVdZ338dd7Bodp5CZEQEEgnPUGS0hLKMLbck22LDclJd1NLpdlXa1W9+rGyrhW99rd9pE96mI3L3MLtcRoXTXFK1MXDMhEhVLEzFJAMQUM5EYGZobP9cf5DRzxzJwzw5zvmTnzfj4ev4e/8z2/m8/Mwfd8fzfn+1NEYGaWSk2lCzCzvsWhY2ZJOXTMLCmHjpkl5dAxs6T6lXsHknx5zKzMIkKVrqFU7umYWVJl7+m0WXL+lFS7sgMwdcEyAE6bM7fClVipFs+5vNIldIp7OmaWlEPHzJJy6JhZUg4dM0vKoWNmSTl0zCwph46ZJeXQMbOkHDpmlpRDx8yScuiYWVIOHTNLyqFjZkk5dMwsKYeOmSXl0DGzpBw6ZpaUQ8fMknLomFlSDh0zS8qhY2ZJOXTMLCmHjpkl5dAxs6QcOmaWlEPHzJJy6JhZUg4dM0vKoWNmSTl0zCwph46ZJeXQMbOkHDpmlpRDx8yScuiYWVIOHTNLqqTQkVQnqVZSf0kfl3RouQszs+pUak/n/wF/AswDPgZcWa6CzKy6lRo6NwHDgMaIuAR4uXwlmVk1KzV0dgAXARdJeg/wvvKVZGbVrF+Jy50DzIqIPdnri8pUj5lVuVJ7Os8Ag9teSPpQecoxs2pXak/nYuAcSW09nVHA0eUpycyqWamh8/GIWNP2QtLo8pRjZtWu1NB5t6QvA7XZ62OAD5SnJDOrZqWGzruA7wJjgSeAaWWryMyqWqknkg8FWoExwETg0rJVZGZVrdTQmUcueL5L7h6db5SrIDOrbqWGTj0wJiK2AouAe8tXkplVs1LP6XwGeDibfwC4C/hoOQrqSQaNn8iY82ay6trPvql94NHvYtAxE6BGbFi0kOatWwq2WXrT3/9uNu/YyYD6Ou5c/tTe9qnHHsnghnoAmppbeOip33JS4xjOnXQ8hwxo4Eu33cvmHTsrVXafUmpP5x7ghWz+ROC95SmnZ9n6zK+pqev/lvZ3zJjN+ntuY9PSBxkz/dJ22yyt48cczqCGeh548lkG1Pdn/KgRe987730TWbhiNQtXrGbaCeMBePX1bVw9fyFLfvM8448Y0d5mrZuVGjrrgVmSHgQWAleUr6SeJVqa3/S6/vDRRGsrALtee5VBx04s2GbpTT5qLGs3bgZg7cbNTD5q7N73nn15A5ecPoljRg7nrsdyPaB1m3LLvrGrmSeefyl9wQktnf6BWDr9A1HpOqD00FkLnA/MAA6LiP/saGFJsyQ9LunxAy2wpzlo4GBadmzb+7rfgIEF2yy9wQ1vY3vTLgB2t7RwyICGve99b9GjjBwymNlnTuHJtfsGSTj1uEYuOvk9nNTo+11TKTV0vgZcBgzN+9JnuyLixoh4b0RU3WFY89Yt1NTV730dzbsLtll6W3bspP9BudOUDf3r2Lqzae97s8+cwvX3LuZHv1jJNeedtbf94dW/58u3L+TPTnxn8npTye/h9ITeTkmhExEzI+LfgLGS7pR0qaQBZa6tZ1ENtfUNNL3yEjV1dQD0Hz6S11evLNhm6T363BoaRwwFYOywITz2u3Uc3D/3ubxj2CHs3N3ML59bS23Nm//Z/2HzVtZs/GPyevuqUocrPUvS54DrgJXkLptfKOniMtZWcQ2jj6R+xCgaRo9jyAnvY/Qn/hKAF++Yx6hzZjD8lLNYM//GdtssrVUvvsLullbOPmE825t2s71pF1d+5DQAFjzyK86dNIGTxx/JPU88DcC/fOqjfHLKCUw99khuefixClZePoV6NpXu7Sii+P4lrSMXOLdERFPWVgesiYiRRdYNgCXnTznwaq3spi5YBsBpc+ZWuBIr1eI5lwOo0HvtBczUBcsKLp9CqffpnJL/LXOAiNgt6cTuL8nMuk1tz3vgS0mhs3/g5LW/0q3VmFm3Uk1t8YUSK7WnY2a9kPodVOkS3sKhY1bFemJPp0sHfJI8gJdZL6B+/QpOldTh3rM7ipuA/LvdBBwBHFXGusysG1Q6YAopVtElEfHU/o2SxpWpHjPrRj3x8KrD0CkUOFn7C4Xazaxn6Yk9naLndCS9R9KovNfDJX26rFWZWbdQTW3BqZKKndOZC3wIeCq7K/maiNiQfSViXvnLM7MD0RN7OsUq+jBwfETszL7gebGku3nziWUz66F64306K9pmImI7cIOkjwFDy1qVmXWLSh9KFVIsdGYCU4CH2hoi4m5JHX7J08x6hl53eJX1bh4q0P6dslVkZt2mN/Z0zKwX63U9HTPr3VTb8/4X73kVmVm3Ua0Pr8wsIdX2vkvmZtaLqbeOHGhmvVNvvDnQzHoxXzI3s6S6eslc0lXABmBwRMzNaz8DaASOBm6OiFVZ+53A+4F7IuKvOtp2zzvgM7Nuo9p+BacO15Gmknua763AEEmTs3YBX4mI7wJfB+Zm7ScBN0TEYcUCBxw6ZlVNtbUFpyKmAc9k86uz1wDDs4mI2Ag0ZkF0OnCTpJslNey/sf05dMyqmPodVHiSZkl6PG+albfaocDmbL4JOCybfw0YKmm0pIOA5sj5OjAO2AR8sVhNPqdjVsXaO5EcETcC7T3/eiPQ1mMZSC5siIgWSTOAzwPrgSV522uR9AXg+8Vqck/HrIp18WkQ9wETsvnjgPslDQaIiEURcQW5hzNcDXvP9UAuoJYW27h7OmZVrCv36UTEMkmnS5oJbMmmG4ALJU0iF0TfjIj12SpLJS0HVgE3Fdu+Q8esinX1Pp2IuG6/pguz9uXA8v2W7dRz8Bw6ZlXMQ1uYWVq+I9nMUqpxT8fMUvLhlZml5cMrM0vJh1dmlpZ7OmaWkgfxMrOkavw0CDNLyk+DMLOUfMnczJLyGMlmlpR7OmaWlHs6ZpaUL5mbWVLFnvxQCT2vIjPrNiU8+SE5h45ZFXNPx8yS6ok9HUVEeXcgBUC592PWx6lQ47bXtxT8H2/g4LcXXD4F93TMqliLel5PJ1nonDZnbvGFrOIWz7kcgKXTOzXAv1XQ1AXL2n2vdc+ehJWUxj0dsyrW0tq10JF0FbABGBwRc/PazwAagaOBmyNilaSjgU8CbwD3RMRvO9q2Q8esirXu6fy5VElTgaER8Q1JX5U0OSIezZ7k+ZWIOEPSMODHwGnAt4DzgWZgPvDnHW3fjxU2q2Ite1oLTkVMA57J5ldnrwGGZxMRsRFolPQ2oDEitkfELmCcpA47Mw4dsyrW0rqn4CRplqTH86ZZeasdCmzO5puAw7L514ChkkZLOohcz2YIsDV/l8Cwjmry4ZVZFWvv8CoibgRubGe1jUBDNj+QXNgQES2SZgCfB9YDS7L36vPWbSD37PN2uadjVsVaWlsLTkXcB0zI5o8D7pc0GCAiFkXEFcARwNXZIdVaSQ2S6oEXI2JnRxt3T8esirV24abciFgm6XRJM8n1WrYANwAXSppELoi+GRHrs1W+QK73swu4stj2HTpmVayrl8wj4rr9mi7M2pcDy/dbdhWwqtRtO3TMqphvDjSzpFocOmaWUlcPr8rJoWNWxXx4ZWZJuadjZkm1hkPHzBJyT8fMknLomFlSPpFsZkn5Ph0zS6org3iVm0PHrIqV8I3y5Bw6ZlXMh1dmlpQPr8wsKR9emVlSvmRuZkn55kAzS6rZoWNmKe3xFz7NLCX3dMwsqT2+ZG5mKflEspkl1dVBvCRdBWwABkfE3Lz2c4Gh2cs3IuK2rP3bwHTgVxHx4Y627Sd8mlWx9p5l3hFJU4GhEXErMETS5Ly3PxsRN0XETcDMbPlRwMqIOKxY4IBDx6yqdSV0gGnAM9n86ux1myck/YOk9wL/nrWdAXxV0r2SDi228S6FjqSxXVnPzNJqjT0FJ0mzJD2eN83KW+1QYHM23wQclvfeV4FG4F+BnwNkPaJG4CHg+mI1dXhOR9J8YMT+zcAo4OhiGzezymqvVxMRNwI3trPaRqAhmx8IvJb33teB2cApwO3Ah7LtBfBNSbcXq6nYieQfA/dERHN+o6RTim3YzCqvi9+9ug84G1gAHAfcL2lwRLwOvDMitgELJX0eQJIiIiTVAY8V23iHoRMR/9VO+887+UOYWQV05ZJ5RCyTdLqkmcCWbLoBuBD4hqQrgPXA/81WWSBpM7AyW65Dnb5kLmk4MCAinu/sumaWVlcH8YqI6/ZrujBrv7fAsud3ZtsdnkiW9GlJmyU9KumSbAcbgPs7sxMzq4zWPXsKTpVU7OrVHGByREwGnpF0uaRact0tM+vhunjJvKyKHV49FxG/BYiIX0paCfwFUFf2yszsgPXE4UqL9XSulHRO24uI2AXczL4bh8ysB2vZ01pwqqRiV6+ekvQ7SaeSu0HoNeCRiLggSXVmdkAqfShVSLGbAz8KfIrcF7+ayN0odIWkeRFxZ4L6zOwA9MTDq2LndA4p1KuRdGmZ6jGzblTpQ6lCioVOo6QPkTuHs5ncrdETgD8pd2FmduB6Y0/nn4Argf9F7ktgG8jdIn1tmesys27Q687pRMRO4B+zCQBJh5S7KDPrHpW+EbCQYncknyXpKUk/k3RG1vw6sKL8pZlZNSp2ePVvwCxy3xydJumSiPi+pK3lL63ypr//3WzesZMB9XXcufypve1Tjz2SwQ31ADQ1t/DQU7/lpMYxnDvpeA4Z0MCXbruXzTt2VqrsPm3Q+ImMOW8mq6797JvaBx79LgYdMwFqxIZFC2neuqVgW7VZPOdynTZnbuzfVql6oPjNgS9HxH9HxLaI+BHwE0kXkxtTp6odP+ZwBjXU88CTzzKgvj/jR+0bVui8901k4YrVLFyxmmknjAfg1de3cfX8hSz5zfOMP2L/IYgsla3P/Jqauv5vaX/HjNmsv+c2Ni19kDHTL223zcqv6HevJH2s7UVEvAbcAWwra1U9wOSjxrJ2Y27wtLUbNzP5qH2DJT778gYuOX0Sx4wczl2P5XpA6zblln1jVzNPPP9S+oJtr2h50/BP1B8+mmjNXTre9dqrDDp2YsG2apXfs6l0LweKhE7Wy7kbQNIkSaMj4g3grI7Wyx8KsRtrTWpww9vY3rQLgN0tLRwyoGHve99b9Cgjhwxm9plTeHLty3vbTz2ukYtOfg8nNY5OXq+176CBg2nZse/vZL8BAwu2WRolj6cTEcslXQ3874jYXWTZvUMhSup5NwqUYMuOnfQ/KPfraehfx9adTXvfm33mFK6/dzETx47kmvPO4qpb7gbg4dW/59XXt/GXp05i6W9eqEjd9lbNW7dQU1e/93U07y7YVs16Qg+nTckDs0t6O1Ddn0yeR59bQ+OI3ON9xg4bwmO/W8fB/XNfrn/HsEPYubuZXz63ltqaN/8K/7B5K2s2/jF5vVaAaqitb6DplZeoqct9dv2Hj+T11SsLtlkanRk58ALg++UqpKdZ9eIrnDDuCM4+YTzbm3azvWkXV37kNK6942cseORXnDtpApu2beeeJ54G4F8+9VFWvPAS25t2ccvDRYeJtTJpGH0k9SNG0TB6HP2HHc7g8RNZ88Pv8OId8xh1zgxq6vqzZn5uPPJCbVZ+yg3iXsKC0hcj4p87vYPs8OrUr/2fzq5qFbB4zuUALJ3+gQpXYqWaumAZ9KIryp157tVdkk4sWyVm1icUG9qiHvgMuSf8HQZskvRT4PrsKpaZWacU6+l8BngE+HPgROATwDLgqjLXZWZVqtiJ5K0RsSTv9RvAq5KOLWNNZlbFioXOK5IWAi+zbzydscAPyl2YmVWnYkNb3CXpAWAKufF0NgLLsiEvzMw6rdjQFv2ADwM7ImJ+RDwIDJT0lSTVmVnVKXYieT7wt8AnJH1H0uHZEz7PLX9pZlaNip3TOR4YHxEhqQa4QNIKoOeN9mxmvUKxns4ScudyiIg9EXEbuft1hpe7MDOrTsVC56+BxvyGiFgMXFGugsysuhW7erVH0hhJs4ER5J7w+VPghymKM7PqU+xrEH8PvAp8m31P+DwO+CK5x9OYmXVKsRPJmyLi1v3aHpU0s1wFmVl1KxY6tZLmAc+x747kd5J7OoSZWacVGyP5P4C5QC0wCNgCfI3cd7DMzDqt2B3Jc4FbyT2/fBgwPyLWAZ8rf2lmVo2KHV59GDg+InZKGgBcLOlu+tBYyWbWvYrdp7P38cERsT0ibgAmAUPLWpWZVa1iPZ2Z5L5h/lBbQ0TcLWlkWasys6pV7ObA7eQFTl77d8pWkZlVtc4MzG5mdsAcOmaWlEPHzJJy6JhZUg4dM0vKoWNmSTl0zCwph46ZJeXQMbOkHDpmlpRDx8yScuiYWVIOHTNLyqFjZkk5dMwsKYeOmSXl0DGzpBw6ZpaUQ8fMknLomFlSDh0zS8qhY2ZJOXTMLCmHjpkl5dAxs6QcOmaWlEPHzJJy6JhZUoqI8u5ACoBy78esj1OlCyhV2UOnmkmaFRE3VroOK40/r57Bh1cHZlalC7BO8efVAzh0zCwph46ZJeXQOTA+P9C7+PPqAXwi2cySck/HzJJy6JhZUg4dM0uqz4aOpIGSfizpeUn/ntc+QdITlaytryv02Ui6VNIlkv6npBpJtZJukvSspDsk1WXLnSvpbyR9UVJDB/v4oKQl2T7OztoaJF2b7eecrG2CpAclrZN0Sd76n5B0e3l/E1UqIvrkBJwJHAw0AM8CJ+W994tK19eXp0KfDXBL9t5fAJ8EpgAjgFpgEXA+MAC4L1vuFOALHezj3Oy/HwSezua/AvxpNv+jrIaPZ6+PAbaw7+JLHbC40r+r3jj12Z5ORDwQETsi4g1gFfBK3tu7919e0jhJL+b9Vfx+1naqpBmS5kuaIukESd+SdE32V3ecpF9nf6G/J+lj2fKLJNUn+nF7lQKfzTTgueztp4FpEfGLiHg1IlqBlcAfyAXRH/KX62Afd2azj+WtMw14JpvfAEyKiLuy5Z8FnosscSLiLf9GrDR9NnTaSBoIrIuIFztaLiJeAP4RGC9JwApgLfAZ4I/Az4HjgcOAHwD3Ax/J1tsKfA/4K3L/sF8ELgNay/EzVYu2zwZoBjZnzU3kfsdty9QCB0fEUuDQ/ZeTdJykL0m6TNKQbJ3JebuZBvxzNv+W9fP2837ghm788fqsfpUuoAe4GLimxGVvBpaS+2v438Aw4O0R8VMASTXAQHLhso5c1x+gNSJey5a5nlwoPQ98mtz/UFZY22dzATAkaxsIvJa3zAXAP2TzG8kdkuUv1xAR/yRpGHCppP7ArQCSDiUXWLfvt/72/P1kPdKTIuLb3f4T9kF9uqcj6ePAXRGxTdKIYstHxE7gJ8DsiHga2ARMlDRJUj/gLODLwAtAeyejBwKTgJ3A2Qf+U1Sn/M8G+Bnwzuyt44C2kD8dWBER67PPbxkwNn+5iHgcICI2RsS/RsR1EbFW0sHkDtP+Q1I/SUOB+4AJ2fqjgEeyntQMoO2EdtF/J9axPhs6ki4Dvgn8RNKTwJ9l7UcCoyWd3M6qPwQWAmTnEy4jF0R3A8vJnYP4Wra9YySNAY6Q9KfZ+n8HXE7uHNLSMvxovV6Bz+aDwGOS/gdwOPDD7OrSPOBWSSuBv87OAf0gW/9k4Pp2tt+f3Gf4OUmPk+u57ga+BZwpaRYwLwu828h9Zr+U9HtyfzSQdCq5z3VcWX4JVcxfg+iE7LLsp4HbI2Jrhcsx65X6bE+nsyQdTu7E8S4HjlnXuadjZkm5p2NmSTl0zCwph46ZJeXQMbOkHDpmltT/BxpDS6L7GasaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = np.vstack((Occurrence_prob_21.ratio_pilot_month_21_years_north[0],\n",
    "                hazard_factor_ratio_cal(hazard_factors_months_north))).T\n",
    "df = pd.DataFrame(df)\n",
    "correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24a6d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09916195241917523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,13),Occurrence_prob_21.normalize(hazard_factor_ratio_cal(hazard_factors_months_north)),label='2020~2021',marker='.',alpha=0.6,linewidth=1.5,color=\"#fa625f\")\n",
    "plt.vlines([2.5,5.5,8.5,11.5],[-0.5,-0.5,-0.5,-0.5],[1.5,1.5,1.5,1.5],colors='C7',linewidth=0.5,alpha=0.5)\n",
    "plt.plot(range(1,13),Occurrence_prob_21.ratio_pilot_month_21_years_north[0],label='21-years',marker='.',color='#2E94B9',linewidth=1.5)\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend(frameon=False,ncol=2)\n",
    "# plt.show(block=True)\n",
    "plt.savefig(f'../figures/seasonal_occurrence_north.png',dpi=600)  #\n",
    "plt.savefig(f'../figures/seasonal_occurrence_north.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9a93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
